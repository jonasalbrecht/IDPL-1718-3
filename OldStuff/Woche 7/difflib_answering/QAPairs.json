{
 "QsACList": [
  {
   "questions": [
    "Modify neural net classify single : custom extension Andrew NG's neural network deep learning course instead producing binary classification 'm attempting classify multiple examples. Both inputs outputs hot encoded. With much training receive accuracy 'train accuracy: 67.51658067499625 %' classify single training instead classifying training examples ? think bug exists implmentation issue network training examples (train_set_x) (train_set_y) both dimensions related dimensionality matrices received. using : returns : ValueError: operands broadcast together shapes ( , ) ( ,4) network :",
    "ValueError: operands broadcast together shapes ( ,) (6,): calculate below similar . manually sized , correct .",
    "numpy matrix multiplication shapes [duplicate]: already answer here: matrix multiplication, assume matrix ( , ) B 4 matrix ( , 4 ), matrix C = * B, C 4 . Why numpy multiplication? When : ValueError: operands broadcast together shapes ( , ) ( ,4) transposing B alwasy answer. Why? matrix multiplication case?",
    "ValueError: operands broadcast together shapes (200,49000) (10,49000) (200,49000): perfectly fine. However, : shows : might reason ?",
    "Function compute 3D gradient unevenly spaced sample locations: experimental observations volume: : ValueError: operands broadcast together shapes (10,10,10) ( ,9) (10,10,10). EDIT: according @jay kominek comments below: np.gradient won't , simply handle unevenly sampled . 've updated . function computation?",
    "Numpy using varying sizes: PIL images RGBA. locations RGB alpha 255. : results operands broadcast together shapes (32,32, ) (32,32). didn't think broadcast together, wanted indeces, guess turn broadcasts statement. , broadcast unequal shapes?",
    "ValueError: operands broadcast together shapes ( , ) (20,100): 'm using emcee mcmc hammer order reconstruct 1D Gaussian 20 samples random standard deviations. relevant part : keep message \"ValueError: operands broadcast together shapes ( , ) (20,100).\" 's deal?",
    "Numpy : operands broadcast together shapes: \"operands broadcast together shapes\" print mse( ,y) Error ValueError:",
    "ValueError: operands broadcast together shapes (224,224) (180,180): writing program cosine similarity vectors. small text files fine datas . gone many examples broadcasting couldn't actual . (Getting p *y)",
    ": ValueError: operands broadcast together shapes (101) ( ): message shown below: 'ValueError: operands broadcast together shapes (101) ( ) ' full message : happens last (ie. plt.show()) plt.show() fine. NB: Machine Learning (Sebastian Raschka, 2015, pg.26)"
   ],
   "code": [
    "train_set_y = np.array([\n    [1,1,1,0], [1,1,0,0], [1,1,1,1], [0,0,0,0]\n])\n",
    "def make2d(lst):\n    return [[i] for i in lst]\n\n>>> scipy.spatial.distance.cdist(make2d([5,3,2.5]), make2d([4,3,2,4,3.5,4]))\narray([[ 1. ,  2. ,  3. ,  1. ,  1.5,  1. ],\n       [ 1. ,  0. ,  1. ,  1. ,  0.5,  1. ],\n       [ 1.5,  0.5,  0.5,  1.5,  1. ,  1.5]])\n\n>>> scipy.spatial.distance.cdist(make2d([5,3,2.5]), make2d([4,3,2,4,3.5,4]), metric='jaccard')\narray([[ 1.,  1.,  1.,  1.,  1.,  1.],\n       [ 1.,  0.,  1.,  1.,  1.,  1.],\n       [ 1.,  1.,  1.,  1.,  1.,  1.]])\n",
    ">>> a\narray([[0],\n       [1],\n       [2]])\n>>> b\narray([0, 1, 2])\n>>> a*b\narray([[0, 0, 0],\n       [0, 1, 2],\n       [0, 2, 4]])\n\n>>> a = np.ones((3,2))\n>>> b = np.ones((2,4))\n>>> np.dot(a,b)\narray([[ 2.,  2.,  2.,  2.],\n       [ 2.,  2.,  2.,  2.],\n       [ 2.,  2.,  2.,  2.]])\n\n>>> a=np.matrix(np.ones((3,2)))\n>>> b=np.matrix(np.ones((2,4)))\n>>> a*b\nmatrix([[ 2.,  2.,  2.,  2.],\n        [ 2.,  2.,  2.,  2.],\n        [ 2.,  2.,  2.,  2.]])\n",
    "b=np.zeros((1,49000))\n\nb=np.zeros((2,49000))\n\n1.they are equal, or\n2.one of them is 1\n",
    "np.gradient(tt, np.diff(x)[0], np.diff(y)[0], np.diff(z)[0])\n\ndistances = [np.diff(x)[0], np.diff(y)[0], np.diff(z)[0]]\nnp.gradient(tt, *distances)\n",
    "np.where((img1[..., :-1] == img2[..., :-1]).all(axis=-1) \n         & (img1[..., 3] == 255)) \n\n(img1[..., :-1] == img2[..., :-1]).all(axis=-1) \n",
    "result = op.minimize(nll, [mupop, sigpop], args=(datapoints))\n\nresult = op.minimize(nll, [mupop, sigpop], args=(datapoints,))\n",
    "from sklearn.datasets import load_boston\nfrom sklearn.linear_model import LinearRegression\nbeantown = load_boston()\nx = beantown.data\ny = beantown.target\ny = y.reshape(y.size, 1)\nmodel = LinearRegression()\nmodel = model.fit(x, y)\n\n\ndef mse(truth, predictions):\n    return ((truth - predictions) ** 2).mean(None)\nprint model.score(x, y)\nprint mse(x, y)\n",
    "x = np.linspace(1,10,num=224)\ny = np.linspace(1,10,num=180)\np = x*y\n\nTraceback (most recent call last):\n  File \"<pyshell#3>\", line 1, in <module>\n    p = x*y\nValueError: operands could not be broadcast together with shapes (224,) (180,) \n\n x = np.linspace(1,10,num=224)\n y = np.linspace(1,10,num=224)\n p = x*y\n",
    "for xi, target in zip(X, y):\n\nfor xi, target in zip(X.T, y):\n"
   ]
  },
  {
   "questions": [
    "MSE pixel images dimension: images identical dimensions. images numpy itterating pixels aquiring r g b pixel : acquire MSE pixels : ridiculously slow. efficient ? looking pixels certain \"thresholded\" similarity, images, black. pixels larger difference pixel img2.",
    "Efficient count greater operation itself: numpy vector containing real . vector count greater itself. : idea : 's slow. efficient ?",
    "Numpy range less : current . requires copy range, range less , copy back. copying slow. syntax ?",
    "Intersect numpy index : Suppose images thresholded differently, intersection indexes both threshold, words indexes both lists. Assume dimensions equal, nothing worry . easy understand efficient?",
    "numpy input : reading lines : .txt : throws : However, assign , fine. take input numpy array?",
    "Finding overlap numpy images [duplicate]: already answer here: numpy : 'overlap' , : , quicker ?",
    "joining numpy matrices: numpy matrices, join together ? They joined horizontally, , matrices: hstack :",
    "Avoid looping products numpy: 'm currently converting old fortran looking numpy style operations much , speed. calls finding products , : instead vectorized : remove generate whole \"nx ny\" array , presumably faster?",
    "Round numpy Nearest Step: round numpy upper lower threshold function predefined step . Hopefully stated clearer , 123 step equal 50, round 123 closest either 150 100, case 100. came function below wonder better, succint, . advance, Paolo",
    "numpy greater threshold: numpy array greater threshold . , case, threshold .4, , ."
   ],
   "code": [
    "mse = np.linalg.norm(img1-img2,axis=2)\n\nd = (img1-img2).astype(float)\nmse = np.sqrt(np.einsum('...i,...i->...',d,d))\n\nIn [46]: np.random.seed(0)\n    ...: m,n = 1024,1024\n    ...: img1 = np.random.randint(0,255,(m,n,3)).astype(np.uint8)\n    ...: img2 = np.random.randint(0,255,(m,n,3)).astype(np.uint8)\n\nIn [47]: %timeit np.linalg.norm(img1-img2,axis=2)\n10 loops, best of 3: 26.6 ms per loop\n\nIn [49]: %%timeit\n    ...: d = (img1-img2).astype(float)\n    ...: mse = np.sqrt(np.einsum('...i,...i->...',d,d))\n100 loops, best of 3: 13 ms per loop\n\nmask = mse >= mse_thresh\nout = np.where(mask[...,None], img2, 0)\n\nd = (img1-img2).astype(float)\nmse = np.einsum('...i,...i->...',d,d)\nimg2[mse < mse_thresh**2] = 0\n",
    "import bisect\narray = [1.,2.,3.,1.,1.,0.,10.]\nn = len(array)\nsorted_array = sorted(array)\nprint [n - bisect.bisect(sorted_array, val) for val in array]\n\noutput = array.size - np.searchsorted(np.sort(array), array, side='right')\n",
    "maps = depthmap[0:580,p1[0]:p2[0]]\n\nmaps[maps < value] = value\n\ndepthmap[0:580,p1[0]:p2[0]] = maps\n\ndef updatemap(depthmap, p1, p2, value):\n    maps = depthmap[0:580,p1[0]:p2[0]]\n    maps[maps < value] = value\n",
    "out = np.nonzero((img1!=0) & (img2!=0))\n\nl_intsct = np.intersect1d(np.nonzero(img1.ravel())[0],np.nonzero(img2.ravel())[0])\nout = np.unravel_index(l_intsct,img1.shape)\n\nIn [127]: img1\nOut[127]: \narray([[3, 2, 3, 1, 0],\n       [3, 1, 1, 2, 2],\n       [0, 2, 3, 2, 1],\n       [0, 0, 0, 4, 2]])\n\nIn [128]: img2\nOut[128]: \narray([[1, 1, 4, 0, 0],\n       [0, 0, 0, 0, 2],\n       [4, 1, 0, 3, 1],\n       [1, 0, 4, 1, 4]])\n\nIn [129]: np.nonzero(img1)\nOut[129]: \n(array([0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3]),\n array([0, 1, 2, 3, 0, 1, 2, 3, 4, 1, 2, 3, 4, 3, 4]))\n\nIn [130]: np.nonzero(img2)\nOut[130]: \n(array([0, 0, 0, 1, 2, 2, 2, 2, 3, 3, 3, 3]),\n array([0, 1, 2, 4, 0, 1, 3, 4, 0, 2, 3, 4]))\n\nIn [131]: np.nonzero((img1!=0) & (img2!=0))\nOut[131]: (array([0, 0, 0, 1, 2, 2, 2, 3, 3]), array([0, 1, 2, 4, 1, 3, 4, 3, 4]))\n\nIn [132]: l_intsct = np.intersect1d(np.nonzero(img1.ravel())[0],np.nonzero(img2.ravel())[0])\n\nIn [133]: np.unravel_index(l_intsct,img1.shape)\nOut[133]: (array([0, 0, 0, 1, 2, 2, 2, 3, 3]), array([0, 1, 2, 4, 1, 3, 4, 3, 4]))\n",
    "lines = open('values.txt', 'r')\nx = np.array( [  map(float, (l[l.find(\"[\")+1 : l.find(\"]\")].split(\",\")))\n     for l in lines ] )\nprint x\n",
    "In [3]: a\nOut[3]: \narray([[0, 1, 1],\n       [0, 1, 0],\n       [0, 0, 0]])\n\nIn [4]: b\nOut[4]: \narray([[0, 1, 1],\n       [0, 0, 1],\n       [0, 0, 0]])\n\nIn [5]: c = a & b\n\nIn [6]: c\nOut[6]: \narray([[0, 1, 1],\n       [0, 0, 0],\n       [0, 0, 0]])\n",
    ">>> X = np.matrix([[0, 1, 4, 0]]).T\n>>> Y = np.matrix([[1, 0, 1, 1]]).T\n>>> np.hstack([X, Y])\nmatrix([[0, 1],\n        [1, 0],\n        [4, 1],\n        [0, 1]])\n",
    ">>> nx = np.array([1,2,3,4])\n>>> ny = np.array([2,3,4,5])\n>>> np.outer(nx, ny)\narray([[ 2,  3,  4,  5],\n       [ 4,  6,  8, 10],\n       [ 6,  9, 12, 15],\n       [ 8, 12, 16, 20]])\n",
    "def getRoundedThresholdv1(a, MinClip):\n    return round(float(a) / MinClip) * MinClip\n",
    "large = np.where(X.min(0) >= 0.4)[0]\n"
   ]
  },
  {
   "questions": [
    "Optimize function call index [ hold]: function prototype: end : vectorize fo lambda function since understanding vectorize uses . looking function numpy family achieve . luck: passes entire array passing current index.",
    "vectorize numpy append : vectorize append multiple empty array. vectorize using numpy? welcome!",
    "vectorize order faster: portion vectorize rid nested . wasn't vectorize portion below. figure",
    "Dividing : 'm defining function : script (even everything ) : solve ?",
    "Different results map numpy vectorize: understanding ( ) numpy's vectorize allows send array function normally takes scalars, instead using built map function ( combination lambda function ). However, under scenario results map vs numpy.vectorize 't seem figure why.",
    "create multidimensional lambda function ?: using shown below ... , put",
    "initialize matrix vectors : initialize Matrix vectors. special part vectors matrix. Now here vectors form matrix. fix ?",
    "index non zero numpy quickly?: Now writing function index non zero rules: Do idea? Thank advance!",
    "vectorize loops mentioned below numpy?: vectorise ? already looked broadcasting figure vectorize : b ( , ,4) array c ( , ) array m fixed integer??",
    "vectorize ?: vectorize segment pseudocode:"
   ],
   "code": [
    "def fun(signal,const):\n    n = len(signal);\n    index = np.arange(n);\n    F = np.sum(signal*np.exp((-2*np.pi*np.complex(1j)*const*index)/n),axis=-1);\n    return F;\n\nIn [126]: signal = np.arange(10)*.1    \nIn [139]: for i in range(4):\n     ...:     print(fun(signal,i))     \n(4.5+0j)\n(-0.5+1.53884176859j)\n(-0.5+0.688190960236j)\n(-0.5+0.363271264003j)\n\nIn [142]: fun(signal, np.arange(4)[:,None])\nOut[142]: \narray([ 4.5+0.j        , -0.5+1.53884177j, -0.5+0.68819096j,\n       -0.5+0.36327126j])\n\nIn [143]: np.arange(4)[:,None]*np.arange(10)\nOut[143]: \narray([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n       [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n       [ 0,  2,  4,  6,  8, 10, 12, 14, 16, 18],\n       [ 0,  3,  6,  9, 12, 15, 18, 21, 24, 27]])\n",
    "ff[:10,:,:]\n\nnumpy.squeeze(ff[:10,:,:])\n",
    " def EMalgofast(obsdata, beta, pjt):\n     n = np.shape(obsdata)[0]\n     g = np.shape(pjt)[0]\n     zijtpo = np.zeros(shape=(n,g))\n     for j in range(g):\n         zijtpo[:,j] = pjt[j]*stats.expon.pdf(obsdata,scale=beta[j])\n\n     zijdenom = np.sum(zijtpo, axis=1)\n     zijtpo = zijtpo/np.reshape(zijdenom, (n,1))\n\n     pjtpo = np.mean(zijtpo, axis=0)\n     betajtpo_1 = []\n\n     #manipulating an array of numerator and denominator instead of creating objects each iteration\n     num=np.zeros(shape=(g,1))\n     denom=np.zeros(shape=(g,1))\n     #generating the num and denom real value for the end result\n     for (x,y), value in numpy.ndenumerate(zijtpo):\n         num[x],denom[x] = num[x] + value *obsdata[y],denom[x] + value \n\n     #dividing all at once after instead of inside the loop\n     betajtpo_1= np.true_divide(num/denom)\n\n     betajtpo = np.asarray(betajtpo_1)\n\n     return(pjtpo,betajtpo)\n",
    "def calculate(y1, y2, y):\n    if not isinstance(y, np.ndarray):\n        y = np.array(y)\n\n    if not np.isfinite(y):\n        print 'bad y array values'\n        return\n\n    elif np.sum(y == 0) > 0:\n        print 'zero values in y'\n        return\n\n    # the rest of your code\n",
    "func2 = np.vectorize(basis2, otypes=\"d\")\n",
    "X=[2,2,2]\nS=lambda X:sum(X**2+np.ones(3))\nprint S(2*np.ones(3))\n\n15.0\n",
    "V = np.column_stack([Vx, Vy, Vz])\n",
    "# Store non-zero element indices\nidx = np.where(arr)[0]\n\n# Get indices where the shifts occur, i.e. positions where groups of identical \n# elements are separated. For this we perform differnetiation and look for \n# non-zero values and then get those positions. Finally, add 1 to compensate \n# for differentiation that would have decreased those shift indices by 1.\nshift_idx = np.where(np.diff(arr[idx])!=0)[0]+1\n\n# Split the non-zero indices at those shifts for final output\nout = np.split(idx,shift_idx)\n\nIn [35]: arr\nOut[35]: array([0, 0, 1, 1, 1, 2, 2, 1, 1, 0, 2, 2, 4, 3, 3, 3, 0])\n\nIn [36]: out\nOut[36]: \n[array([2, 3, 4]),\n array([5, 6]),\n array([7, 8]),\n array([10, 11]),\n array([12]),\n array([13, 14, 15])]\n",
    "b += c[:,None,None]\n\nb += c.T[:,None]\n",
    "y[i] = alpha*x[i] + (1-alpha)*y[i-1]\n\nY(z) = alpha*X(z) + (1-alpha)*Y(z^-1)\n\nY(z)/X(z) = alpha/(1 + (alpha-1)*z^-1)\n\nimport scipy.signal as sig\ny = sig.lfilter([alpha], [1, alpha-1], x)\n"
   ]
  },
  {
   "questions": [
    "-hot encode numpy?: Suppose dataset np.loadtxt np.genfromtxt converter assign categorical sex . instead create -hot during loading process? , look accomplish ?",
    "Use np.loadtxt split while reading: np.loadtxt converters argument split ? lines text : : quite reading too slow. : !",
    "Plot Numpy Array: Suppose we RGB we converted Numpy array : we interested visualizing red channel, .e. arr[:,:, ], we Numpy array?",
    "combining numpy masking: . numpy datafiles genfromtext. select records mask( dictionary). combination instead reading those disk? ?",
    "Pycuda messing numpy matrix transpose: Why transposed matrix look differently, converted pycuda.gpuarray? Can reproduce ? cause ? Am using wrong approach? Example Output",
    "Fast slicing numpy multiple times: np.arange([100000]) retrieve indexes multiple times. Currently running slow Both ways slow. fast. looking .",
    "Passing array: Suppose index= np.array([4, , , ]). dimensional blah extract blah using blah[index,:]. R, /numpy?",
    "Sum indexed numpy : Suppose array : array : create X using vectorized numpy expressions produced follows: X=[w0+w0, w1, w2, w3+w3]",
    "csv numpy via : csv format normalise. numbers represent counts associated strings. contains close 100K entries. create dictionary using Result Instead converting csv numpy array, : There may ways normalising processing via .",
    "Converting Numpy array 1D : best converting numpy array 1D ? instance, array: : : wondering better using pure Numpy functions?"
   ],
   "code": [
    "In [11]: df = pd.read_csv(\"my_file.csv\", dtype={\"sex\": \"category\"})\n\nIn [12]: df\nOut[12]:\n      sex  age  hours\n0  female   23    900\n1    male   19    304\n2  female   42    222\n\nIn [13]: df.dtypes\nOut[13]:\nsex      category\nage         int64\nhours       int64\ndtype: object\n\nIn [21]: pd.get_dummies(df.sex)\nOut[21]:\n   female  male\n0       1     0\n1       0     1\n2       1     0\n\nIn [22]: pd.get_dummies(df.sex.cat.codes)\nOut[22]:\n   0  1\n0  1  0\n1  0  1\n2  1  0\n",
    "import re\n\nimport numpy as np\n\ndef parser(s):\n    for i in re.findall('[a-zA-Z]+', s):\n        s = s.replace(i, '')\n    return s.replace('=', '').replace(';',' ')\n\ngen = (parser(line) for line in open('demo.txt'))\nnp.genfromtxt(gen, comments='#', usecols=(0, 1, 2, 3))\n",
    "import matplotlib.pyplot as plt\nimgplot = plt.imshow(arr[:, :, 0])\n\nt = np.array([[0, 1, 2], [1, 2, 3], [3, 2, 1]])\nimport matplotlib.pyplot as plt\nplt.imshow(t)\nplt.show()\nplt.imshow(t, interpolation='nearest')\nplt.show()\n",
    ">>> x = range(0, 4)\n>>> y = range(4, 8)\n>>> ov = range(8, 12)\n>>> aa = range(12, 16)\n>>> numpy.array([x, y, ov, aa])\narray([[ 0,  1,  2,  3],\n       [ 4,  5,  6,  7],\n       [ 8,  9, 10, 11],\n       [12, 13, 14, 15]])\n\n>>> numpy.array(zip(x, y, ov, aa))\narray([[ 0,  4,  8, 12],\n       [ 1,  5,  9, 13],\n       [ 2,  6, 10, 14],\n       [ 3,  7, 11, 15]])\n\n>>> a = numpy.array(zip(x, y, ov, aa))\n>>> a[a == 1]\narray([ 1,  5,  9, 13,  3,  7, 11, 15])\n",
    "data_gpu = gpuarray.to_gpu(data.T.copy())\n",
    "In [360]: timeit np.take(data, [idx for iin, iout in slices for idx in range(iin,iout)])\n10000 loops, best of 3: 92.5 us per loop\n\nIn [359]: timeit data[[idx for iin, iout in slices for idx in range(iin,iout)]]\n10000 loops, best of 3: 92.2 us per loop\n\nIn [361]: timeit np.concatenate([data[iin:iout] for iin,iout in slices])\n100000 loops, best of 3: 15.8 us per loop\n\nIn [362]: timeit data[np.r_[tuple([slice(i[0],i[1]) for i in slices])]]\n10000 loops, best of 3: 79 us per loop\nIn [363]: timeit np.r_[tuple([slice(i[0],i[1]) for i in slices])]\n10000 loops, best of 3: 67.5 us per loop\n",
    "In [24]: index = np.array([4,2,3,1])\n\nIn [25]: blah = np.array([[1], [2], [3], [4], [5]])\n\nIn [26]: blah[index]\nOut[26]:\narray([[5],\n       [3],\n       [4],\n       [2]])\n",
    ">>> I = np.r_[0, 1, 2, 3, 0, 3]\n>>> W = np.r_[60, 50, 40, 30, 20, 10]\n>>> M = W[I]\n\n>>> W[I]\narray([60, 50, 40, 30, 60, 30])\n>>> W[W[I]==W]\narray([60, 50, 40, 30])\n>>> np.unique(W[I], return_counts=True)[1]\narray([2, 1, 1, 2])\n\n>>> W[M==W]*np.unique(M, return_counts=True)[1] #  X\narray([120, 50, 40, 60])\n\n>>> W = np.array(['w0', 'w1', 'w2', 'w3', 'w4', 'w5'])\n>>> M = W[I]\n>>> M\narray(['w0', 'w1', 'w2', 'w3', 'w0', 'w3'], dtype='|S2')\n>>> W[M==W]\narray(['w0', 'w1', 'w2', 'w3'], dtype='|S2')\n>>> np.unique(W[I], return_counts=True)[1]\narray([2, 1, 1, 2])\n\n>>> [2*'w0', 'w1', 'w2', 2*'w3']   \n",
    "import numpy as np\n\narr = np.loadtxt('data.csv', dtype=str, delimiter=\",\")\n\nb = dict([(y, x) for (x, y) in arr])\n",
    "[array([0, 1, 2, 3, 4]), array([5, 6, 7, 8, 9]), array([10, 11, 12, 13, 14])]\n\narray([[0, 1, 2, 3, 4], [5, 6, 7, 8, 9], [10, 11, 12, 13, 14]])\n"
   ]
  },
  {
   "questions": [
    "Deleting Pandas DataFrame based , specific range : feel been asked 't exact answer. dataset dozens . delete dataset greater 5, search (those greater 5). understand specific named eg.( df.colname > 5), range ? : df = df[df. [ :34] > 5]",
    "Get Pandas DataFrame readable datatypes: types dataframe. types : , : ideally : ['datetime', 'float'] settle : ['datetime64[ns]', 'float'] easy having df.types.to_string() parsing?",
    "merge based specific : add together. add 255. ?",
    "Pandas dataframe divide based dates: daily level, weekly level. divide daily weekly week day falls, corresponding company group. 'm figure , feel numpy, 't figure . ! , frames: df1 = df2 = :",
    "Pandas remap range : DataFrame colum id s, contain duplicates: remap user id's goes arbitrary , incrementally according original ? , starting :",
    "/Pandas - Merging dataframe numpy array peculiar : Dataframe: numpy.ndarray, called coef: insert those , repeating lines, gets look : best ?",
    "difference Pandas DataFrames: 'd check difference DataFrame . using command: results empty array: However, dataframes : means DataFrame obviously . wrong here?",
    "Selecting specific array: select specific numpy array. , : select element , element , element third . : produces : clearly looking . easy using loops?",
    "select specific range numpy 2d array : numpy array , =([ , , ,4,5], [100,200,300,400,500]) = [ ] y= [ ] xy < < 4 ?",
    "fast substitute specific array [duplicate]: already answer here: Say numpy obtain , substitute array whose contained sequence b. Fastest cleanest ? ( substitute( ,b, ))"
   ],
   "code": [
    "df[~(df.iloc[:,2:]>5).any(1)]\nOut[403]: \n     a    b    c    d    e\n0  0.0  0.0  0.0  0.0  0.0\n2  0.0  0.0  0.0  0.0  0.0\n3  0.0  0.0  0.0  0.0  0.0\n",
    "> [d.name for d in df.dtypes]\n['datetime64[ns]', 'float64']\n",
    "mask = (array2 != 255)\nresult = array1.copy()\nresult[mask] += array2[mask]\nprint(result)\n",
    "In [152]: df1['Week'] = df1['Date'].values.astype('datetime64[W]'); df1\nOut[152]: \n  Company       Date Group  People       Week\n0       A 2015-01-07     X       5 2015-01-01\n1       A 2015-01-14     X      10 2015-01-08\n2       A 2015-01-07    XX       6 2015-01-01\n3       A 2015-01-14    XX      12 2015-01-08\n4       B 2015-01-07     Y       4 2015-01-01\n5       B 2015-01-14     Y       8 2015-01-08\n6       B 2015-01-07    YY       5 2015-01-01\n7       B 2015-01-14    YY       4 2015-01-08\n\nimport pandas as pd\ndf1 = pd.DataFrame({'Company': ['A', 'A', 'A', 'A', 'B', 'B', 'B', 'B'], 'Date': ['01/07/2015', '01/14/2015', '01/07/2015', '01/14/2015', '01/07/2015', '01/14/2015', '01/07/2015', '01/14/2015'], 'Group': ['X', 'X', 'XX', 'XX', 'Y', 'Y', 'YY', 'YY'], 'People': [5, 10, 6, 12, 4, 8, 5, 4]})\n\ndf2 = pd.DataFrame({'Company': ['A', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'B', 'B', 'B', 'B', 'B', 'B'], 'Date': ['01/04/2015', '01/06/2015', '01/13/2015', '01/05/2015', '01/06/2015', '01/11/2015', '01/14/2015', '01/05/2015', '01/07/2015', '01/13/2015', '01/14/2015', '01/03/2015', '01/11/2015', '01/14/2015'], 'Group': ['X', 'X', 'X', 'XX', 'XX', 'XX', 'XX', 'Y', 'Y', 'Y', 'Y', 'YY', 'YY', 'YY'], 'Value': [5, 10, 15, 6, 9, 9, 12, 4, 6, 16, 24, 10, 10, 12]})\n\nfor df in [df1, df2]:\n    df['Date'] = pd.to_datetime(df['Date'])\n    df['Week'] = df['Date'].values.astype('datetime64[W]')\n\nresult = pd.merge(df2, df1, how='left', on=['Week', 'Group', 'Company'], suffixes=['', '_1'])\nresult['Value/People'] = result['Value']/result['People']\nresult = result[['Company', 'Group', 'Date', 'Value/People']]\nprint(result)\n\n   Company Group       Date  Value/People\n0        A     X 2015-01-04          1.00\n1        A     X 2015-01-06          2.00\n2        A     X 2015-01-13          1.50\n3        A    XX 2015-01-05          1.00\n4        A    XX 2015-01-06          1.50\n5        A    XX 2015-01-11          0.75\n6        A    XX 2015-01-14          1.00\n7        B     Y 2015-01-05          1.00\n8        B     Y 2015-01-07          1.50\n9        B     Y 2015-01-13          2.00\n10       B     Y 2015-01-14          3.00\n11       B    YY 2015-01-03          2.00\n12       B    YY 2015-01-11          2.50\n13       B    YY 2015-01-14          3.00\n\n(df['Date'].values + np.timedelta64(1, 'D')).astype('datetime64[W]')\n",
    "In [29]:\ndf1 = df.reindex(df['user_id'].sort_values().index)\ndf1\n\nOut[29]:\n       user_id\nindex         \n1         1234\n4         1234\n0         2134\n2         4323\n3        25434\n\nIn [30]:    \ndf1['new_id'] = pd.factorize(df1['user_id'])[0] + 2\ndf1\n\nOut[30]:\n       user_id  new_id\nindex                 \n1         1234       2\n4         1234       2\n0         2134       3\n2         4323       4\n3        25434       5\n\nIn [31]:\ndf1 = df1.sort_index()\ndf1\n\nOut[31]:\n       user_id  new_id\nindex                 \n0         2134       3\n1         1234       2\n2         4323       4\n3        25434       5\n4         1234       2\n",
    "pd.DataFrame(np.tile(coef, (len(df.index), 1)), columns=['Coef']*5)\n",
    "import numpy\n\ncolsA = ['a', 'b', 'c', 'd']\ncolsB = ['b','c']\n\nc = numpy.setxor1d(colsA, colsB)\n\n//columns in train.columns that are not in train_1.columns\nc1 = np.setdiff1d(train.columns, train_1.columns)\n\n//columns in train_1.columns that are not in train.columns\nc2 = np.setdiff1d(train_1.columns, train.columns)\n",
    "a[np.arange(3), (0,1,0)]\n",
    "import numpy as np\n\nx = np.array([1,2,3,4,5])\ny = np.array([100,200,300,400,500])\n\n# b contains true when corresponding value of x is outside 2 < x < 4\nb = np.ma.masked_outside(x, 2, 4).mask\n\n# x2 originates from x, but values 2 < x < 4 are stripped (according to the boolean variables contained in b), the same is done with y2\nx2 = x[~b]\ny2 = y[~b]\n\nprint 'x2', x2\nprint 'y2', y2\n\nimport matplotlib.pyplot as plt\n\nplt.plot(x,y)\nplt.axis((2,4,None,None)) \nplt.show()\n",
    "c = a.copy()\nc[np.in1d(a.ravel(), b).reshape(a.shape)] = 0\n"
   ]
  },
  {
   "questions": [
    "passing numpy array tensorflow queue: tensorflow model fine, using feed_dict 'm change queuing operations increase performance. old Above old pass numpy object - (1024,1024, ) predictions worked fine. With Im simulate passing numpy array . New :-",
    "Deque rotate returns None type: rotate numpy object right left distance. : , rotate array, called myarray, right . array, None. Could someone ?",
    "beginner \u2014 change matrix: img object img (480,640) ( .e. lose , )?",
    "Return int specific frame: frame DF called ' ' its integer . However retrieve specific using returns object ( ,) int int . int index entry numpy array. retrieve 's int ?",
    "List np array: 'm turn 2d numpy 2d numpy array. , array (50, 10). However, , (10,5,10) array. Thoughts?",
    "List np array: 'm turn 2d numpy 2d numpy array. , array (50, 10). However, , (10,5,10) array. Thoughts?",
    "mean square tensors?: tensors (10, 100, ) mean square loss (10, 100)? : tf.sqrt(tf.square(tf.subtract(targets, logits))/n) returns (10, 100, )",
    "numpy.asarray( Image.open ( \u2026) ) : believe numpy.asarray recommended create numpy images. installations machine. One locally installed home directory. installed /usr. Anyways, local installation . numpy creates array JPEG object . installation numpy array . Anyone knows fix?",
    "Write array text : 'm write 5x3 array text found here using . results : savetxt outfile object. 'm savetxt specify actual outfile name. , : last gets save ' .txt'.",
    "function numpy string?: numpy array strings done See its giving desired whole numpy array . ?"
   ],
   "code": [
    "sess = tf.Session()\nop = sess.graph.get_operations()\nprint [m.values() for m in op][1]\n",
    "deque(myarray)\nmyarray.rotate(1)\n\nroll(myarray, 1)\n",
    "newimg = img[..., 0]\n\nimg = img[..., 0].copy()\n",
    "DF.someCondition = condition\n\nDF[DF.someCondition=condition].A\n\nDF[DF.someCondition=condition].A.item()\n\nDF.loc[DF.someCondition=condition, 'A'].item()\n\nimport numpy as np\nimport pandas as pd\n\ndf = pd.DataFrame(np.arange(6).reshape(3,2), columns=list('AB'))\ndf[df['B']==3].A\n# 1    2\n# Name: A, dtype: int64\n\ndf.loc[df['B']==3, 'A'].item()\n# 2\n",
    "np.vstack(dat_list)\n",
    "np.vstack(dat_list)\n",
    "x = tf.reduce_mean(tf.sqrt(tf.subtract(targets, logits)), axis=2)\n",
    "from scipy.misc import imread, imsave\nimage = imread(\"filename.jpg\")\n\nfrom skimage.io import imread, imsave\n",
    "import numpy as np\ndata = np.loadtxt('array_float.txt')\nwith open('out.txt', 'ab') as outfile:\n    for data_slice in data:\n        np.savetxt(outfile, data_slice, fmt='%4.1f')\n",
    ">>> set(\"\".join(x.flatten()))\n{'r', ' ', 'g', 'y', 'h', 'I', 'd', '-', 'a', 'i', 'n', 'Z', 's', 'o', 't', 'b', 'v', 'c', 'e', 'Y', 'X', 'u', 'L'}\n\n>>> data = set()\n>>> for row in x.flatten():\n...     data.update(row)\n...\n>>> \n# {'r', ' ', 'g', 'y', 'h', 'I', 'd', '-', 'a', 'i', 'n', 'Z', 's', 'o', 't', 'b', 'v', 'c', 'e', 'Y', 'X', 'u', 'L'}\n"
   ]
  },
  {
   "questions": [
    "colormap interactive animations : below creates animation 600k scatter plotting 30k per frame. animation flawlessly, except fact include colormap (Heatintensity) animation. Xs Ys changing color blue.",
    "colormap interactive animations : below creates animation 600k scatter plotting 30k per frame. animation flawlessly, except fact include colormap (Heatintensity) animation. Xs Ys changing color blue.",
    "reflect matrix matplotlib?: created matrix matplotlib. As covers half matrix. anyway reflect onto side matrix fill whole matrix? generated using imshow",
    "Sigmoidal curve fit, y .5: solve function after fitting, y .5. function: please explain carry using ! !",
    "show positive correlations correlations: dataset correlation matrix correlation matrix show best positive correlations instead correlations .+correlations shown numbers)",
    "sum complicated condition dataframe: dataframe below; conditional summing dataframe shown below; shows conditional sum df. instance,( inconfident expression) dataframe ?",
    "Code optimization : wrote below function estimate orientation axes accelerometer signal (X,Y,Z) Executing function signal 180000 samples takes quite while (~ . seconds)... written \"pythonic \"... Could optimize execution ? !",
    "Find index positions 3D meets MULTIPLE conditions: 3D consisting several numbers within band. function returns index positions meets MULTIPLE conditions? : returns :",
    "color information matplotlib?: using class matplotlib.patches.Polygon draw polygons map. fact, information coordinates corners polygons floating point \"polygon\" . Now 'd (ranging 3e15) color information visualize nicely. best practice ? snippet :",
    "color information matplotlib?: using class matplotlib.patches.Polygon draw polygons map. fact, information coordinates corners polygons floating point \"polygon\" . Now 'd (ranging 3e15) color information visualize nicely. best practice ? snippet :"
   ],
   "code": [
    "sc.set_array(Heatintensity[(i*30000):(i*30000)+30000])\n\nnorm = plt.Normalize(Heatintensity.min(), Heatintensity.max())\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nHeatintensity=np.random.rand(600000) #Values controlling scatter colormap\nXs=np.random.rand(600000)\nYs=np.random.rand(600000)\n\nplt.ion()\nfig, ax = plt.subplots()\n\nnorm = plt.Normalize(Heatintensity.min(), Heatintensity.max())\nsc = ax.scatter(Xs, Ys, c=Heatintensity, s=5, cmap=plt.cm.jet, norm=norm)\n\nplt.draw()\nfor i in range(20):\n    # set coordinates\n    sc.set_offsets(np.c_[Xs[(i*30000):(i*30000)+30000],\\\n                        Ys[(i*30000):(i*30000)+30000]])\n    # set colors\n    sc.set_array(Heatintensity[(i*30000):(i*30000)+30000])\n    # draw and make pause\n    plt.pause(0.1)\n\nplt.ioff()\nplt.show()\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\n\nHeatintensity=np.random.rand(600000) #Values controlling scatter colormap\nXs=np.random.rand(600000)\nYs=np.random.rand(600000)\n\nfig, ax = plt.subplots()\n\nnorm = plt.Normalize(Heatintensity.min(), Heatintensity.max())\nsc = ax.scatter(Xs, Ys, c=Heatintensity, s=5, cmap=plt.cm.jet, norm=norm)\n\n\ndef update(i):\n    # set coordinates\n    sc.set_offsets(np.c_[Xs[(i*30000):(i*30000)+30000],\\\n                        Ys[(i*30000):(i*30000)+30000]])\n    # set colors\n    sc.set_array(Heatintensity[(i*30000):(i*30000)+30000])\n\n\nani = animation.FuncAnimation(fig, update, frames=range(20), interval=100)\n\nplt.show()\n",
    "sc.set_array(Heatintensity[(i*30000):(i*30000)+30000])\n\nnorm = plt.Normalize(Heatintensity.min(), Heatintensity.max())\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nHeatintensity=np.random.rand(600000) #Values controlling scatter colormap\nXs=np.random.rand(600000)\nYs=np.random.rand(600000)\n\nplt.ion()\nfig, ax = plt.subplots()\n\nnorm = plt.Normalize(Heatintensity.min(), Heatintensity.max())\nsc = ax.scatter(Xs, Ys, c=Heatintensity, s=5, cmap=plt.cm.jet, norm=norm)\n\nplt.draw()\nfor i in range(20):\n    # set coordinates\n    sc.set_offsets(np.c_[Xs[(i*30000):(i*30000)+30000],\\\n                        Ys[(i*30000):(i*30000)+30000]])\n    # set colors\n    sc.set_array(Heatintensity[(i*30000):(i*30000)+30000])\n    # draw and make pause\n    plt.pause(0.1)\n\nplt.ioff()\nplt.show()\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\n\nHeatintensity=np.random.rand(600000) #Values controlling scatter colormap\nXs=np.random.rand(600000)\nYs=np.random.rand(600000)\n\nfig, ax = plt.subplots()\n\nnorm = plt.Normalize(Heatintensity.min(), Heatintensity.max())\nsc = ax.scatter(Xs, Ys, c=Heatintensity, s=5, cmap=plt.cm.jet, norm=norm)\n\n\ndef update(i):\n    # set coordinates\n    sc.set_offsets(np.c_[Xs[(i*30000):(i*30000)+30000],\\\n                        Ys[(i*30000):(i*30000)+30000]])\n    # set colors\n    sc.set_array(Heatintensity[(i*30000):(i*30000)+30000])\n\n\nani = animation.FuncAnimation(fig, update, frames=range(20), interval=100)\n\nplt.show()\n",
    "import numpy as np\nimport pylab as plt\n\n# Create a sample matrix like your image\nA = np.random.random((100,100)) * .52\nA = np.rint(A)\nfor idx in np.ndindex(A.shape):\n    if idx[0]>idx[1]: A[idx] = 0\n\nplt.subplot(1,2,1)\nplt.imshow(A,interpolation='none')\n\n# Make a new matrix B = A + A.T - diagonal(A)\nB = A + A.T - np.diag(np.diag(A))\nplt.subplot(1,2,2)\nplt.imshow(B,interpolation='none')\nplt.tight_layout()\nplt.show()\n",
    "from matplotlib import pyplot as plt\n\nx = np.linspace(4, 10, 1000)\ny = sigmoid(x, *popt)\n\nfig, ax = plt.subplots(1, 1)\nax.hold(True)\nax.scatter(x_data, y_data, s=50, zorder=20)\nax.plot(x, y, '-k', lw=2)\n\npopt2, pcov2 = curve_fit(sigmoid, x_data, y_data, (-0.5, 0.1))\ny2 = sigmoid(x, *popt2)\n\nax.plot(x, y2, '-r', lw=2)\n\ndef objective(x, b, c):\n    return (0.5 - sigmoid(x, b, c)) ** 2\n\nfrom scipy.optimize import minimize_scalar\n\nres = minimize_scalar(objective, bracket=(4, 10), args=tuple(popt2))\nax.annotate(\"$y = 0.5$\", (res.x, 0.5), (30, 30), textcoords='offset points',\n            arrowprops=dict(facecolor='black', shrink=0.05), fontsize='x-large')\n",
    "# Set the diagonal to -np.inf\ncorr[np.diag_indices_from(corr)] = -np.inf\n# Find the value of the k-largest correlation\nk = 3\nthreshold = np.sort(corr)[-k]\n# Mask all values that are below the threshold\ncorr[corr < threshold] = np.nan\n# Do your plotting as before\n",
    "df.groupby(df.index).sum()\n\n#    A   B   C\n#a  11  13  15\n#b  20  22  24\n#c  20  22  24\n",
    "np.arccos(sigIn/np.linalg.norm(sigIn,axis=1,keepdims=1))*180/np.pi\n\nnp.linalg.norm(sigIn,axis=1,keepdims=1)\n\nnp.sqrt(np.einsum('ij,ij->i',sigIn,sigIn))[:,None]\n\nimport numexpr as ne\n\npi_val = np.pi\ns = np.sqrt(np.einsum('ij,ij->i',signIn,signIn))[:,None]\nout = ne.evaluate('arccos(signIn/s)*180/pi_val')\n\ndef original_app(sigIn):\n    N=len(sigIn)\n    sigOut=np.empty(shape=(N,3))\n    sigOut[sigOut==0]=None\n    i=0\n    while i<N:\n        sigOut[i,:] = np.arccos(sigIn[i,:]/np.linalg.norm(sigIn[i,:]))*180/math.pi\n        i=i+1\n    return sigOut\n\ndef broadcasting_app(signIn):\n    s = np.linalg.norm(signIn,axis=1,keepdims=1)\n    return np.arccos(signIn/s)*180/np.pi\n\ndef einsum_app(signIn):\n    s = np.sqrt(np.einsum('ij,ij->i',signIn,signIn))[:,None]\n    return np.arccos(signIn/s)*180/np.pi\n\ndef numexpr_app(signIn):\n    pi_val = np.pi\n    s = np.sqrt(np.einsum('ij,ij->i',signIn,signIn))[:,None]\n    return ne.evaluate('arccos(signIn/s)*180/pi_val')\n\nIn [115]: a = np.random.rand(180000,3)\n\nIn [116]: %timeit original_app(a)\n     ...: %timeit broadcasting_app(a)\n     ...: %timeit einsum_app(a)\n     ...: %timeit numexpr_app(a)\n     ...: \n1 loops, best of 3: 1.38 s per loop\n100 loops, best of 3: 15.4 ms per loop\n100 loops, best of 3: 13.3 ms per loop\n100 loops, best of 3: 4.85 ms per loop\n\nIn [117]: 1380/4.85 # Speedup number\nOut[117]: 284.5360824742268\n",
    ">>> arr\narray([[[ 6,  9,  4],\n        [ 5,  2,  1],\n        [10, 15, 30]],\n\n       [[ 9,  0,  1],\n        [ 4,  6,  4],\n        [ 8,  3,  9]],\n\n       [[ 6,  7,  4],\n        [ 0,  1,  6],\n        [ 4,  0,  1]]])\n\n>>> index_pos = np.where((arr[:,:,0]==10) & (arr[:,:,1]==15) & (arr[:,:,2]==30))\n>>> index_pos\n(array([0]), array([2]))\n\n>>> arr == np.array([10,15,30])\narray([[[False, False, False],\n        [False, False, False],\n        [ True,  True,  True]],\n\n       [[False, False, False],\n        [False, False, False],\n        [False, False, False]],\n\n       [[False, False, False],\n        [False, False, False],\n        [False, False, False]]], dtype=bool)\n\n>>> np.where( np.all(arr == np.array([10,15,30]), axis=-1) )\n(array([0]), array([2]))\n\nind_vals = np.array([0,2])\nwhere_mask = (arr[:,:,ind_vals] == values)\n\narr = np.random.randint(0,100,(5000,5000,3))\n\n%timeit np.all(arr == np.array([10,15,30]), axis=-1)\n1 loops, best of 3: 614 ms per loop\n\n%timeit ((arr[:,:,0]==10) & (arr[:,:,1]==15) & (arr[:,:,2]==30))\n1 loops, best of 3: 217 ms per loop\n\n%timeit tmp = (arr == np.array([10,15,30])); (tmp[:,:,0] & tmp[:,:,1] & tmp[:,:,2])\n1 loops, best of 3: 368 ms per loop\n\n%timeit (arr[:,:,0]==10)\n10 loops, best of 3: 51.2 ms per loop\n\n%timeit (arr == np.array([10,15,30]))\n1 loops, best of 3: 300 ms per loop\n\ntmp = (arr == np.array([10,15,30]))\n\nmethod1 = np.all(tmp,axis=-1)\nmethod2 = (tmp[:,:,0] & tmp[:,:,1] & tmp[:,:,2])\nmethod3 = np.einsum('ij,ij,ij->ij',tmp[:,:,0] , tmp[:,:,1] , tmp[:,:,2])\n\nnp.allclose(method1,method2)\nTrue\nnp.allclose(method1,method3)\nTrue\n\n%timeit np.all(tmp,axis=-1)\n1 loops, best of 3: 318 ms per loop\n\n%timeit (tmp[:,:,0] & tmp[:,:,1] & tmp[:,:,2])\n10 loops, best of 3: 68.2 ms per loop\n\n%timeit np.einsum('ij,ij,ij->ij',tmp[:,:,0] , tmp[:,:,1] , tmp[:,:,2])\n10 loops, best of 3: 38 ms per loop\n",
    ">>> import matplotlib.pyplot as plt\n\n>>> Blues = plt.get_cmap('Blues')\n>>> print Blues(0)\n(0.9686274528503418, 0.9843137264251709, 1.0, 1.0)\n>>> print Blues(0.5)\n(0.41708574119736169, 0.68063054575639614, 0.83823145908467911, 1.0)\n>>> print Blues(1.0)\n(0.96555171293370867, 0.9823452528785257, 0.9990157632266774, 1.0)\n",
    ">>> import matplotlib.pyplot as plt\n\n>>> Blues = plt.get_cmap('Blues')\n>>> print Blues(0)\n(0.9686274528503418, 0.9843137264251709, 1.0, 1.0)\n>>> print Blues(0.5)\n(0.41708574119736169, 0.68063054575639614, 0.83823145908467911, 1.0)\n>>> print Blues(1.0)\n(0.96555171293370867, 0.9823452528785257, 0.9990157632266774, 1.0)\n"
   ]
  },
  {
   "questions": [
    "Understanding Numpy datatypes: While reading PyCUDA documentation, found did understand theory pointer float, while receives self. pointer array floats. sure , after looking information numpy.intp books did anything .",
    "Understanding numpy. : reading numpy. (condition[, , y]) documentation, understand small : Can explain comes?",
    "meaning '*' numpy?: 't numpy's documentation. appreciated.",
    "Understanding weird boolean 2d indexing behavior numpy: Why : :",
    "Numpy dtype mixed types: , my_list, mixed types numpy array. However, TypeError: expected readable buffer object. See below. 've base NumPy documentation.",
    "Indexing NumPy array array: target _ix Simplfy AND extraction, numpy, did wanted. p.s. Please change title think precise .",
    "numpy. () ?: playing numpy digging documentation come across magic. Namely talking numpy. (): they achieve internally pass > 5 ? guess __gt__ looking detailed explanation.",
    "Numpy sum wraparound condition: Given numpy array floats 'm looking elegant sum contained rules: : Because 'm dealing rather , 'm looking elegant numpy centric .",
    "merge numpy ?: feel documentation missing, 't anything specific - everything concatenating stacking . array y both ( , ) = [[ , , ],[4,5,6]] y = [[7,8,9],[10,11,12]] z ( , , ) z = [[[ ,7],[ ,8],[ ,9]],[[4,10],[5,11],[6,12]]] basically joins y element position.",
    "Numpy cumsum considering NaNs: looking succinct go : : best currently : shorter accomplish ? cumsum along axis array?"
   ],
   "code": [
    "class DoubleOpStruct:\n    mem_size = 8 + numpy.intp(0).nbytes\n    def __init__(self, array, struct_arr_ptr):\n        self.data = cuda.to_device(array)\n        self.shape, self.dtype = array.shape, array.dtype\n        cuda.memcpy_htod(int(struct_arr_ptr), numpy.getbuffer(numpy.int32(array.size)))\n        cuda.memcpy_htod(int(struct_arr_ptr) + 8, numpy.getbuffer(numpy.intp(int(self.data))))\n    def __str__(self):\n        return str(cuda.from_device(self.data, self.shape, self.dtype))\n\narray1 = DoubleOpStruct(numpy.array([1, 2, 3], dtype=numpy.float32), struct_arr)\narray2 = DoubleOpStruct(numpy.array([0, 4], dtype=numpy.float32), do2_ptr)\nprint(\"original arrays\", array1, array2)\n\n>>> np.intp(2432353)\n2432353\n>>> np.getbuffer(np.intp(2432353))\n<read-only buffer for 0xb74d1150, size -1, offset 0 at 0xb71dfba0>\n\n>>> np.arange(4.).data\n<read-write buffer for 0xb71dda98, size 32, offset 0 at 0xb71df1c0>\n\n>>> np.arange(4.).__array_interface__['data']\n(148454560, False)\n>>> np.arange(4.).__array_interface__['data'][0]\n148454560\n>>> np.getbuffer(np.intp(int(_)))\n<read-only buffer for 0xb74d1150, size -1, offset 0 at 0xb3a0c800>\n",
    ">>> zip(*np.where( x > 5 ))\n[(2, 0), (2, 1), (2, 2)]\n\n>>> np.dstack(np.where( x > 5 ))\narray([[[2, 0],\n        [2, 1],\n        [2, 2]]])\n",
    ">>> np.random.randn(2, 2)\n",
    "a[m1, m2] == a[m1.nonzero(), m2.nonzero()]\n\n[a[i, i] for i in range(a.shape[0]) if m1[i] and m2[i]]\n\na[np.ix_(m1, m2)]\n\n[[a[i,j] for j in range(a.shape[1]) if m2[j]] for i in range(a.shape[0]) if m1[i]]\n",
    "In [1]: my_list = [['User_0', '2012-2', 1, 6, 0, 1.0], ['User_0', '2012-2', 5,\n6, 0, 1.0], ['User_0', '2012-3', 0, 0, 4, 1.0]]\nIn [2]: my_np_array = np.array(my_list, dtype=object)\nIn [3]: my_np_array\nOut[3]:\narray([['User_0', '2012-2', 1, 6, 0, 1.0],\n       ['User_0', '2012-2', 5, 6, 0, 1.0],\n       ['User_0', '2012-3', 0, 0, 4, 1.0]], dtype=object)\n",
    "m = array([[1, 2],\n           [4, 5],\n           [7, 8],\n           [6, 2]])\nselect = array([0,1,0,0])\n\nresult = np.choose(select, m.T)\n\nresult = m[np.arange(len(select)), select]\n\nresult = m.take(select+np.arange(0, len(select) * m.shape[1], m.shape[1]))\n",
    "x = np.arange(9).reshape(3,3)\nprint x > 5\n\narray([[False, False, False],\n       [False, False, False],\n       [ True,  True,  True]], dtype=bool)\n",
    "# store all cumulative sums (adding 0 at the start for the empty sum)\ncs = np.insert(np.cumsum(values), 0, 0) \n\n# then for each indexing get the result in constant time (linear in index0/1 size):\nresult = np.where(index0 < index1, 0, cs[-1]) + cs[index1+1]-cs[index0]\n",
    "import numpy as np\n\nx = np.asarray([[1,2,3],[4,5,6]])\ny = np.asarray([[7,8,9],[10,11,12]])\nz = np.stack((x, y), 2)\n",
    "In [15]: a = arange(10000.0)\n\nIn [16]: a[1] = np.nan\n\nIn [17]: %timeit a*0 + np.nan_to_num(a).cumsum()\n1000 loops, best of 3: 465 us per loop\n\nIn [18] s = pd.Series(a)\n\nIn [19]: s.cumsum()\nOut[19]: \n0       0\n1     NaN\n2       2\n3       5\n...\n9996    49965005\n9997    49975002\n9998    49985000\n9999    49994999\nLength: 10000\n\nIn [20]: %timeit s.cumsum()\n10000 loops, best of 3: 175 us per loop\n"
   ]
  },
  {
   "questions": [
    "Slicing NumPy 2d array, extract mxm submatrix nxn array (n>m)?: slice NumPy nxn array. extract arbitrary selection m array ( .e. pattern numbers / ), making , mxm array. let us say array 4x4 extract 2x2 array . our array: remove . easiest case extract 2x2 submatrix beginning end, .e. : remove mixture / ? remove third lines/ , thus extracting submatrix [[5,7],[13,15]]? There composition /lines. somewhere index using /lists both , seem : found , : First issue hardly readable, although live . someone better , 'd certainly hear . Other thing forum indexing forces NumPy copy desired array, thus treating become . Why / mechanism ?",
    "Slicing NumPy 2d array, extract mxm submatrix nxn array (n>m)?: slice NumPy nxn array. extract arbitrary selection m array ( .e. pattern numbers / ), making , mxm array. let us say array 4x4 extract 2x2 array . our array: remove . easiest case extract 2x2 submatrix beginning end, .e. : remove mixture / ? remove third lines/ , thus extracting submatrix [[5,7],[13,15]]? There composition /lines. somewhere index using /lists both , seem : found , : First issue hardly readable, although live . someone better , 'd certainly hear . Other thing forum indexing forces NumPy copy desired array, thus treating become . Why / mechanism ?",
    "Slicing scipy.sparse.lil_matrix : extract specific scipy sparse matrix - probably lil_matrix best choice here. fine here: returns 4x3 sparse matrix. block matrix though, rather single . 'd expect : returns 1x3 sparse matrix. numpy , numpy.ix_, described Slicing NumPy 2d array, extract mxm submatrix nxn array (n>m)?. accomplish behaviour lil_matrix? partly answered slicing sparse (scipy) matrix, couldn't lil_matrix."
   ],
   "code": [
    "x.strides\n(16, 4)\n\ny.shape\n(2,2)\ny.strides\n(16, 4)\n\nx[[[1],[3]],[1,3]]\n\nx[1::2, 1::2]\n",
    "x.strides\n(16, 4)\n\ny.shape\n(2,2)\ny.strides\n(16, 4)\n\nx[[[1],[3]],[1,3]]\n\nx[1::2, 1::2]\n",
    ">>> a = np.arange(100).reshape(10, 10)\n>>> a\narray([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n       [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n       [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n       [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n       [40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n       [50, 51, 52, 53, 54, 55, 56, 57, 58, 59],\n       [60, 61, 62, 63, 64, 65, 66, 67, 68, 69],\n       [70, 71, 72, 73, 74, 75, 76, 77, 78, 79],\n       [80, 81, 82, 83, 84, 85, 86, 87, 88, 89],\n       [90, 91, 92, 93, 94, 95, 96, 97, 98, 99]])\n\n>>> lilm = scipy.sparse.lil_matrix(a)\n\n>>> lilm[[1, 2, 3], :].toarray() # extract the rows first...\narray([[10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n       [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n       [30, 31, 32, 33, 34, 35, 36, 37, 38, 39]])\n\n>>> lilm[[1, 2, 3], :][:, [4, 5, 6]].toarray() # ...then the columns\narray([[14, 15, 16],\n       [24, 25, 26],\n       [34, 35, 36]])\n"
   ]
  },
  {
   "questions": [
    "average several readings ?: sensor generates reading five seconds. function np.mean calculate average five sensor readings ( .e., sensor1_t1 sensor1_t5), however . Can please ? .",
    "Average Date Array Calculation: mean dates. thought converting seconds averaging . probably better . Nasty :",
    "Inserting average tensorflow tensor: function numpy: basically takes average below inserts , n intervals. idea Tensorflow? Specifically instead np.insert, since seem equivalent function.",
    "Preallocating ndarrays: preallocate appending bit efficiently. Matlab function called cell(required_length) preallocates 'cells' store . array currently : However wish append 1000s array 'b' shown varying .",
    "generate PWM using : using codes generate PWM signal using vectorization . still facing issues.Could anyone .",
    "Numpy ValueError: setting element sequence reading : reads numbers meant calculate std %rms using numpy However keep : idea fix ? /numpy. print :",
    ": Calculate average speed standard deviation timestep: . . array speed cell. Now calculate average speed timestep cells. Some cells move specific disappear length. Some 60 timesteps, 20 . calculate ?",
    "create -dim using numpy.fromfunction function parameters: create ( ,y) array 5d function, say kernel KMID: : : SyntaxError: invalid syntax .e. array iterating . most elegant ?",
    "Moving average running mean: scipy function numpy function module calculates running mean 1D specific window? /M",
    "Plot using : event times exponentially weighted moving average . using . clearly horrible however. 's right ? making extra sparse ? look ."
   ],
   "code": [
    "import numpy as np\n\nN = 5\nsensor1 = np.zeros((N,), dtype=float)\n\nfor i in range(N):\n    sensor1[i] = BridgeValue(0) * 274.0 - 2.1\n    sleep(1)\n\naverage = np.mean(sensor1)\n",
    "import numpy as np\n\ndate = ['2016-02-23 09:36:26', '2016-02-24 10:00:32', '2016-02-24 11:28:22', '2016-02-24 11:27:20', '2016-02-24 11:24:15', '2016-02-24 11:20:25', '2016-02-24 11:17:43', '2016-02-24 11:12:03', '2016-02-24 11:09:11', '2016-02-24 11:08:44', '2016-02-24 11:05:28', '2016-02-24 11:03:23', '2016-02-24 10:58:08', '2016-02-24 10:53:59', '2016-02-24 10:49:34', '2016-02-24 10:43:33', '2016-02-24 10:35:27', '2016-02-24 10:31:50', '2016-02-24 10:31:17', '2016-02-24 10:30:05', '2016-02-24 10:29:21']\n\nmean = (np.array(date, dtype='datetime64[s]')\n        .view('i8')\n        .mean()\n        .astype('datetime64[s]'))\n\nprint(mean)\n\n2016-02-24T09:43:40-0500\n",
    "def insert_row_averages_iniitalization_based(A, n=1):\n\n    # Slice and compute averages   \n    slice2 = A[n::n]\n    v = (A[n-1::n][:slice2.shape[0]] + slice2)/2.0\n\n    # Compute number of rows for o/p array\n    nv = v.shape[0]\n    nrows = A.shape[0] + nv\n\n    # Row indices where the v values are the inserted in o/p array\n    v_rows = (n+1)*np.arange(nv)+n\n\n    # Initialize o/p array\n    out = np.zeros((nrows,A.shape[1]))\n\n    # Insert/assign v in output array\n    out[v_rows] = v  # Assign v\n\n    # Create 1D mask of length equal to no. of rows in o/p array, such that its\n    # TRUE at places where A is to be assigned and FALSE at places where values\n    # from v were assigned in previous step.\n    mask = np.ones(nrows,dtype=bool)\n    mask[v_rows] = 0\n\n    # Use the mask to assign A.\n    out[mask] = A\n    return out\n",
    "A = np.empty((10,),dtype=object)\n\n A[0] = [1,2,3]\n A[1] = [2,3]\n ...\n\ndef witharray(n):\n    result=np.empty((n,),dtype=object)\n    for i in range(n):\n        result[i]=list(range(i))\n    return result\n\ndef withlist(n):\n    result=[]                         \n    for i in range(n):\n        result.append(list(range(i)))\n    return result\n\nIn [111]: withlist(4)\nOut[111]: [[], [0], [0, 1], [0, 1, 2]]\n\nIn [112]: witharray(4)\nOut[112]: array([[], [0], [0, 1], [0, 1, 2]], dtype=object)\n\nIn [113]: np.array(withlist(4))\nOut[113]: array([[], [0], [0, 1], [0, 1, 2]], dtype=object)\n\nIn [108]: timeit withlist(400)\n1000 loops, best of 3: 1.87 ms per loop\n\nIn [109]: timeit witharray(400)\n100 loops, best of 3: 2.13 ms per loop\n\nIn [110]: timeit np.array(withlist(400))\n100 loops, best of 3: 8.95 ms per loop\n",
    "percent=30.0\nTimePeriod=1.0\nCycles=10\ndt=0.01 \n\nt=np.arange(0,Cycles*TimePeriod,dt); \npwm= t%TimePeriod<TimePeriod*percent/100 \nplot(t,pwm)\n",
    "values = np.array([], dtype=float)\n\nvalues = np.append(values, [variables], axis=0)\n# or\nvariables = np.array(lines[line_number].split(), dtype=float)\nvalues = np.concatenate((values, variables), axis=0)\n\nimport pandas as pd\n# Replace `read_csv` with your appropriate file reader\n\na = pd.concat([pd.read_csv(pbpfile)\n               for pbpfile in glob.glob(os.path.join(road, 'pbpfile*'))]).values\n# or\na = np.concatenate([pd.read_csv(pbpfile).values\n                    for pbpfile in glob.glob(os.path.join(road, 'pbpfile*'))], axis=0)\n",
    "np.mean(stepwiseSpeed, axis=1)\n",
    "import numpy as np\n\ndef KMID(x, y, mumid, delta, cmid):\n    rsq = (x-len(x)/2.+0.5)**2+(y-len(y)/2.+0.5)**2\n    return cmid*np.exp(-mumid*np.sqrt(rsq))/(rsq+delta**2)\n\nlenx, leny = 256, 256\nmidscatterkernel = KMID(\n    np.arange(lenx),\n    np.arange(leny)[:, np.newaxis],\n    0.1, 0.2, 0.3)\n\nimport functools\ndef KMID(x, y, mumid, delta, cmid):\n    rsq = (x-len(x)/2.+0.5)**2+(y-len(y)/2.+0.5)**2\n    return cmid*np.exp(-mumid*np.sqrt(rsq))/(rsq+delta**2)\n\nshape = 256, 256\nmidscatterkernel = np.fromfunction(functools.partial(KMID,mumid=0.1,delta=0.2,cmid=0.3),shape)\n",
    "np.convolve(x, np.ones((N,))/N, mode='valid')\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nmodes = ['full', 'same', 'valid']\nfor m in modes:\n    plt.plot(np.convolve(np.ones((200,)), np.ones((50,))/50, mode=m));\nplt.axis([-10, 251, -.1, 1.1]);\nplt.legend(modes, loc='lower center');\nplt.show()\n",
    "import pandas as pd\n\nl = [3.0,7.0,10.0,20.0,200.0]\ns = pd.Series(np.ones_like(l), index=l)\ny = s.reindex(range(1000), fill_value=0)\npd.ewma(y, 199).plot()\n"
   ]
  },
  {
   "questions": [
    "Matplotlib: Time axes limits: matplotlib Pandas DateTimeIndex. user zoom -axis using scroll wheel. limits recalculated : zooms -axis point scroll event happened. Now 'm recalculate y axis limits zoom displayed 't figure -axis -limits relate : fails message TypeError: Invalid type promotion. As far , - being stored numpy.datetime64 matplotlib returns limits float represents days since 0001 01 01 00 00 plus . form compare array datetime64?",
    "Defining numpy array - TypeError: invalid type promotion: defining array look However append entry TypeError. Traceback wrong?",
    "Not write dates axis, Matplotlib: Take look : writes dates -axis , picture below. dates clogged , seen picture. matplotlib write fifth tenth coordinate?",
    "`TypeError: invalid type promotion` appending heterogeneous numpy array: created array : append : Where OpenDT CloseDT were created np.datetime64(DTstring, 'm') : Edit: outputs Outputs resolve ?",
    "Create matplotlib legend figure: added legend : legend appears inside . tell matplotlib put right right?",
    "Show rgb numpy array matplotlib: numpy array: corresponds 5x5 RGB . When plt.imshow( [ ]) TypeError: Invalid dimensions . properly show ?",
    "Does anyone understand ?: ValueError: Error parsing datetime string \"2015 01 31 00 00\" position 10 call np.datetime64('2015 01 31 00 00').",
    "To Compare Date From Two Numpy.datetime64: proper compare date portion numpy.datetime64's? false comparing ( == B)",
    "formatting timeseries -axis /matplotlib: show month abbreviation, well year year. quite close. issue currently having years incorrect. figured issue numpy.datetime64 ( datetime index format), datetime used 1970 epoch. years shown chart 2017 2018 they show 48 49. show right years here?",
    "matplotlib 2d numpy array: created 2d numpy array : Which results : Now, $ :$ $ :-$ using matplotlib, axis, : , yaxis, : define xaxis yaxis numpy array?"
   ],
   "code": [
    "from matplotlib.dates import num2date\n\nlimits = (np.datetime64(num2date(limits[0])), np.datetime64(num2date(limits[1])))\n",
    "In [75]: npdtype\nOut[75]: [('word', 'S35'), ('year', numpy.int16), ('wordcount', numpy.int16)]\nIn [76]: column = np.array( [b'word1', np.int16(year), np.int16(word_count)], dtype=npdtype)\nIn [77]: column\nOut[77]: \narray([(b'word1', 0, 0), \n       (b'\\xd1\\x07', 0, 0), \n       (b'\\x15', 0, 0)], \n      dtype=[('word', 'S35'), ('year', '<i2'), ('wordcount', '<i2')])\n\nIn [78]: column = np.array( [(b'word1', np.int16(year), np.int16(word_count))], dtype=npdtype)\nIn [79]: column\nOut[79]: \narray([(b'word1', 2001, 21)], \n      dtype=[('word', 'S35'), ('year', '<i2'), ('wordcount', '<i2')])\nIn [80]: column.shape\nOut[80]: (1,)\n\nIn [81]: column0 = np.array( (b'word1', np.int16(year), np.int16(word_count)), dtype=npdtype)\nIn [82]: column0.shape\nOut[82]: ()\nIn [83]: column0\nOut[83]: \narray((b'word1', 2001, 21), \n      dtype=[('word', 'S35'), ('year', '<i2'), ('wordcount', '<i2')])\n\nIn [85]: np.concatenate([column,column,column])\nOut[85]: \narray([(b'word1', 2001, 21), \n       (b'word1', 2001, 21), \n       (b'word1', 2001, 21)], \n      dtype=[('word', 'S35'), ('year', '<i2'), ('wordcount', '<i2')])\nIn [86]: _.shape\nOut[86]: (3,)\nIn [87]: __['year']   # access the 2nd field (not column)\nOut[87]: array([2001, 2001, 2001], dtype=int16)\n\nIn [88]: np.empty((1,3),dtype=npdtype)\nOut[88]: \narray([[(b'', 0, 0), (b'', 0, 0), (b'', 0, 0)]], \n      dtype=[('word', 'S35'), ('year', '<i2'), ('wordcount', '<i2')])\n\n arr = np.empty((0,3))\n for i in range(10):\n     arr = np.append(arr, [i,i+1,i+2])\n\n ll = []\n for i in range(10):\n     ll.append([i,i+1,i+2])\n arr = np.array(ll)\n\n arr = np.empty((10,3))\n for i in range(10):\n     arr[i,:]=[i,i+1,i+2]\n",
    "import datetime as dt\nfrom matplotlib import pyplot as plt \nimport matplotlib.dates as mdates\nx = []\nd = dt.datetime(2013, 7, 4)\nfor i in range(30):\n        d = d+dt.timedelta(days=1)\n        x.append(d)\n\ny = range(len(x))\nplt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%d-%m-%Y'))\nplt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=5))\nplt.bar(x, y, align='center') # center the bars on their x-values\nplt.title('DateLocator with interval=5')\nplt.gcf().autofmt_xdate()\nplt.show()\n",
    "Ticket_data = np.empty((0,),\n                       dtype='str,datetime64[m],datetime64[m],str,str,str,str')\n\nlineitem = ['foo', np.datetime64('1979-03-22T19:00', 'm'),\n            np.datetime64('1979-03-22T19:00', 'm'), 'bar', 'baz', 'a', 'b']\n\nnp.array(lineitem)\n# array(['21539', '2015-06-30T10:46-0700', '2015-06-30T10:55-0700',\n#        'Testtext', 'Testtext2', 'Testtext3', 'Testtext5'], \n#       dtype='|S21')\n\nnp.array([tuple(lineitem)], dtype=Ticket_data.dtype)\n\nnp.array([tuple(lineitem)], dtype=Ticket_data.dtype).shape\n# (1,)\n",
    "fig.legend((plot1,plot2), (lab1,lab2), 'right')\n",
    "from numpy.random import rand\nfrom matplotlib.pyplot import imshow\n\nimg = rand(5, 5)  # Creating a 5x5 matrix of random numbers.\n\n# Use bilinear interpolation (or it is displayed as bicubic by default).\nimshow(img, interpolation=\"nearest\")  \nshow()\n",
    "In [74]: np.datetime64('2015-01-31','ms')\nOut[74]: numpy.datetime64('2015-01-31T00:00:00.000')\n\nIn [79]: np.datetime64('2015-01-31 00:00:00','ms')\nOut[79]: numpy.datetime64('2015-01-31T00:00:00.000')\n",
    ">>> a = numpy.datetime64('2011-01-10')\n>>> b = numpy.datetime64('2011-01-10T09:00:00.000000-0700')\n>>> a == b\nFalse\n>>> a.astype('datetime64[D]') == b.astype('datetime64[D]')\nTrue\n\n>>> b = numpy.array(['2011-01-10T09:00:00.000000-0700'], dtype='datetime64[D]')\nTypeError: Cannot parse \"2011-01-10T09:00:00.000000-0700\" as unit 'D' using casting rule 'same_kind'\n",
    "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom matplotlib.dates import MonthLocator, WeekdayLocator, DateFormatter, YearLocator\n\nindx = pd.date_range('2017-04-01', '2019-01-01')\ns = pd.Series(np.random.randn(len(indx)), index=indx)\n\ndf = pd.DataFrame(s)\n\nfig, ax = plt.subplots(1)\nax.plot(df)\n\nmonths = MonthLocator(range(1, 13), bymonthday=1, interval=1)\nmonthsFmt = DateFormatter(\"%b\")\nyears = YearLocator(1, month=4, day=1)\nyrsFmt = DateFormatter(\"\\n %Y\")\n\nax.xaxis.set_major_locator(years)\nax.xaxis.set_major_formatter(yrsFmt)\n\n\nax.xaxis.set_minor_locator(months)\nax.xaxis.set_minor_formatter(monthsFmt)\n\nfig.show()\n",
    "import matplotlib.pyplot as plt\nimport numpy as np\n\nX, Y = np.meshgrid(range(100), range(100))\nZ = X**2+Y**2\n\nplt.imshow(Z,origin='lower',interpolation='nearest')\nplt.show()\n\nplt.pcolormesh(X,Y,Z)\nplt.show()\n\nplt.imshow(Z[20:40,30:70],origin='lower',interpolation='nearest')\nplt.show()\n\nplt.pcolormesh(X[20:40,30:70],Y[20:40,30:70],Z[20:40,30:70])\nplt.show()\n"
   ]
  },
  {
   "questions": [
    "Indices n largest lower triangular region NumPy array: numpy cosine similarity matrix. n largest , exclude . 's diagonals lower triangular region . case, highest , [ , ] [ , ]. using argpartition 'm looking n highest excluding diagonal 's exclude upper triangular ?",
    "Flip non zero along lower triangular numpy array: lower triangular array, B: flip look : That , take positive , reverse within positive , leaving trailing zeros place. fliplr : tips? Also, actual array working B. = (200,20,4,4) instead (4,4). Each (4,4) block ( numbers across 200, 20 entries).",
    "fast lower triangular matrix dimensional : Given ( ) , n, square matrix, index pairs lower triangular matrix dimensional . far thought : Considering loops, far better efficient calculating maybe using numpy. Does anyone suggestion?",
    "Finding matches array array: numpy , B. conatains unique B sub array . Now looking index B's within . :",
    "Find multi dimensional numpy array: numpy array: [( , ), ] ( ) np. working well Does anyone efficient ?",
    "Running Cumulative sum 1d NumPy Array: numpy array np.array([ , , ,4]) create numpy y cumulative sum , y np.array([ , ,6,10]) good num Pythonic ?",
    "Find Indices Of Columns Having Some Nonzero Element 2d array: numpy array dim (157,1944). Nonzero element . : [[ , , ,4], [ , , , ]] ----> [ , ] look , Non Zero element [ , ] [[ , , ,4], [ , , , ]] [ , , ] index Nonzero .",
    "split/reshape numpy array: numpy called 'results' defined look : 'results' array ? array end still needs numpy array.",
    "Simultaneously flipping Numpy Array: numpy : 'd simultaneously flip 0s 2s ( [ , , , , ]), best ?",
    "Indices intersecting Numpy 2d Array: intersecting main numpy 2d , B. Where [ , - , ] based . Thank !"
   ],
   "code": [
    "def n_largest_indices_tril(a, n=2):\n    m = a.shape[0]\n    r,c = np.tril_indices(m,-1)\n    idx = a[r,c].argpartition(-n)[-n:]\n    return zip(r[idx], c[idx])\n\nIn [39]: a\nOut[39]: \narray([[ 1.  ,  0.4 ,  0.59,  0.15,  0.29],\n       [ 0.4 ,  1.  ,  0.03,  0.57,  0.57],\n       [ 0.59,  0.03,  1.  ,  0.9 ,  0.52],\n       [ 0.15,  0.57,  0.9 ,  1.  ,  0.37],\n       [ 0.29,  0.57,  0.52,  0.37,  1.  ]])\n\nIn [40]: n_largest_indices_tril(a, n=2)\nOut[40]: [(2, 0), (3, 2)]\n\nIn [41]: n_largest_indices_tril(a, n=3)\nOut[41]: [(4, 1), (2, 0), (3, 2)]\n\ndef n_largest_indices_tril_v2(a, n=2):\n    m = a.shape[0]\n    r = np.arange(m)\n    mask = r[:,None] > r\n    idx = a[mask].argpartition(-n)[-n:]\n\n    clens = np.arange(m).cumsum()    \n    grp_start = clens[:-1]\n    grp_stop = clens[1:]-1    \n\n    rows = np.searchsorted(grp_stop, idx)+1    \n    cols  = idx - grp_start[rows-1]\n    return zip(rows, cols)\n\nIn [143]: # Setup symmetric array \n     ...: N = 1000\n     ...: a = np.random.rand(N,N)*0.9\n     ...: np.fill_diagonal(a,1)\n     ...: m = a.shape[0]\n     ...: r,c = np.tril_indices(m,-1)\n     ...: a[r,c] = a[c,r]\n\nIn [144]: %timeit n_largest_indices_tril(a, n=2)\n100 loops, best of 3: 12.5 ms per loop\n\nIn [145]: %timeit n_largest_indices_tril_v2(a, n=2)\n100 loops, best of 3: 7.85 ms per loop\n",
    "# row, column indices of the lower triangle of B\nr, c = np.tril_indices_from(B)\n\n# flip the column indices by subtracting them from r, which is equal to the number\n# of nonzero elements in each row minus one\nB[r, c] = B[r, r - c]\n\nprint(repr(B))\n# array([[ 1.  ,  0.  ,  0.  ,  0.  ],\n#        [ 0.75,  0.25,  0.  ,  0.  ],\n#        [ 0.7 ,  0.2 ,  0.1 ,  0.  ],\n#        [ 0.1 ,  0.4 ,  0.3 ,  0.2 ]])\n\n# creates a (200, 20, 4, 4) array consisting of tiled copies of B\nB2 = np.tile(B[None, None, ...], (200, 20, 1, 1))\n\nprint(repr(B2[100, 10]))\n# array([[ 1.  ,  0.  ,  0.  ,  0.  ],\n#        [ 0.25,  0.75,  0.  ,  0.  ],\n#        [ 0.1 ,  0.2 ,  0.7 ,  0.  ],\n#        [ 0.2 ,  0.3 ,  0.4 ,  0.1 ]])\n\nr, c = np.tril_indices_from(B2[0, 0])\nB2[:, :, r, c] = B2[:, :, r, r - c]\n\nprint(repr(B2[100, 10]))\n# array([[ 1.  ,  0.  ,  0.  ,  0.  ],\n#        [ 0.75,  0.25,  0.  ,  0.  ],\n#        [ 0.7 ,  0.2 ,  0.1 ,  0.  ],\n#        [ 0.1 ,  0.4 ,  0.3 ,  0.2 ]])\n\nr, c = np.triu_indices_from(B.T)\nB.T[r, c] = B.T[c - r, c]\n",
    "import numpy as np\n\n# create your matrix. If it's not yet a numpy array, make it one\nar = np.array(matrix)\nindices = np.tril_indices_from(ar)\n\nindices = [list(x) for x in np.tril_indices_from(ar)]\n\ndef getLowerTriangularIndices(n):\n    return [list(x) for x in np.tril_indices(n)]\n\ndef getLowerTriangularIndices(n):\n    return zip(*np.tril_indices(n)]\n",
    "np.nonzero(np.in1d(A,B))[0]\n\nnp.searchsorted(A,B)\n\nsort_idx = A.argsort()\nout = sort_idx[np.searchsorted(A,B,sorter = sort_idx)]\n\nnp.nonzero(B[:,None] == A)[1]\n\nIn [125]: A\nOut[125]: array([ 7,  5,  1,  6, 10,  9,  8])\n\nIn [126]: B\nOut[126]: array([ 1, 10,  7])\n\nIn [127]: sort_idx = A.argsort()\n\nIn [128]: sort_idx[np.searchsorted(A,B,sorter = sort_idx)]\nOut[128]: array([2, 4, 0])\n\nIn [129]: np.nonzero(B[:,None] == A)[1]\nOut[129]: array([2, 4, 0])\n",
    "np.where(np.all(ar == [(1,2),2], axis=1))\n",
    "y = np.cumsum(x)\n",
    "import numpy as np\na = np.array([[0,0,3,4], [0,0,1,1]])\n\n>>> np.nonzero(np.all(a != 0, axis=0))[0]\narray([2, 3])\n\n>>> np.nonzero(np.any(a != 0, axis=0))[0]\narray([2, 3])\n",
    "In [1]: import numpy as np\n\nIn [2]: arr = np.array([1, 2, 3, 4, 5, 6])\n\nIn [3]: reshaped = arr.reshape((3, 2))\n\nIn [4]: reshaped\nOut[4]: \narray([[1, 2],\n       [3, 4],\n       [5, 6]])\n\nIn [5]: reshaped[0][0] = 7\n\nIn [6]: reshaped\nOut[6]: \narray([[7, 2],\n       [3, 4],\n       [5, 6]])\n\nIn [7]: arr\nOut[7]: array([7, 2, 3, 4, 5, 6])\n\nIn [8]: copy = np.copy(reshaped)\n\nIn [9]: copy[0][0] = 9\n\nIn [10]: copy\nOut[10]: \narray([[9, 2],\n       [3, 4],\n       [5, 6]])\n\nIn [11]: reshaped\nOut[11]: \narray([[7, 2],\n       [3, 4],\n       [5, 6]])\n",
    "def switchvals(arr, val1, val2):\n    mask1 = arr == val1\n    mask2 = arr == val2\n    arr[mask1] = val2\n    arr[mask2] = val1\n",
    "import numpy as np\nA = np.array([[1,2],\n           [1,3],\n           [2,3],\n           [2,4],\n           [2,5],\n           [3,4],\n           [4,5]])\n\nB = np.array([[1,2],\n           [3,2],\n           [2,4]])\n\nresult=[]\n\nfor i in range(0, len(A)):\n    for j in range(0, len(B)):\n        if A[i].tolist() == B[j].tolist():\n            result.append(i)\n        if A[i].tolist()[::-1] == B[j].tolist():\n            result.append(-i)\nprint(result)\n\n[0, -2, 3]\n"
   ]
  },
  {
   "questions": [
    "adding complex Dimensional Array: type numpy.complex128 added matrix 3D ( Dimensional Array). write script below. script warning \"ComplexWarning: Casting complex real discards imaginary part\", 3D matrix real , include imaginary . fix add both real imaginary matrix 3D?",
    "Complex troubles numpy: 'm attempting translate matlab again 've pickle. itself , 's demonstration 4 node twiddle factor. attempt: images. (almost) identical matlab , . lines 24 27 \"ComplexWarning: Casting complex real discards imaginary part\". Now 'm used working complex numbers . adding complex component variables, gave graph 's off matlab . Thoughts? post matlab well, let .",
    "Numpy Array View Garbage Collection: Suppose function : f returns y, view . Will still using memory background?",
    "Numpy Indexing Dimensional Array: 'm old Codger having understanding index dimensional even though many tutorials they seem integers perhaps missing . VB write cannot equivalent . achieve desired results?",
    "numpy.array( ) being slow: 5,000,000 integers. cover numpy array. : slow. benchmarked operation 100 times 100 times. There much difference. good idea faster?",
    "Multidimensional Array - Adding additional beginning end : add 's beginning end multidimensional array? function apply . using both apply_along_axis(zero, , ) Neither commands .",
    "index integer: numpy array ( ) below, index positions non integer numbers 4.5 6.7? Since dealing array, faster processing speed considered.",
    "numpy.tile 3d array: 3D demension (4, , ) (60, 80) below expected array?",
    "complex64 numpy.fft?: : type float32, Ga comes complex128 effectively doubling . complex64 ? Certainly isn't default functionality fftw?",
    "Deep copy np.array np.array: numpy array numpy deep copy . found : d best ? deep copy function missed? best interact element array sized ?"
   ],
   "code": [
    "x = np.zeros((nl, 2, 2), dtype=np.complex128)\n",
    "x = zeros((4),dtype=complex)\n\nplt.plot(X.real,X.imag)\nplt.plot(fx.real,fx.imag, 'ro')\n",
    ">>> y = f()\n>>> y.base\narray([ 0,  1,  2,  3,  4,  5,  6, ...., 99])\n",
    "mymatrix=np.zeros((10,10),int)\n\nfor i in range(10):\n   for j in range(10):\n      mymatrix[i,j]=i*j        \n\nIn [637]: print(mymatrix)\n[[ 0  0  0  0  0  0  0  0  0  0]\n [ 0  1  2  3  4  5  6  7  8  9]\n [ 0  2  4  6  8 10 12 14 16 18]\n ...\n [ 0  8 16 24 32 40 48 56 64 72]\n [ 0  9 18 27 36 45 54 63 72 81]]\n\n mymatrix[i,j]=(i+1)*(j+1)\n\narray([[  1,   2,   3,   4,   5,   6,   7,   8,   9,  10],\n       [  2,   4,   6,   8,  10,  12,  14,  16,  18,  20],\n       ...\n       [  9,  18,  27,  36,  45,  54,  63,  72,  81,  90],\n       [ 10,  20,  30,  40,  50,  60,  70,  80,  90, 100]])\n\nnp.arange(1,11)[:,None]*np.arange(1,11)[None,:]\n",
    "%load_ext cython\n\n%%cython\n\ncimport cython\nimport numpy as np\n\n@cython.boundscheck(False)\ncpdef to_array(list inp):\n    cdef long[:] arr = np.zeros(len(inp), dtype=long)\n    cdef Py_ssize_t idx\n    for idx in range(len(inp)):\n        arr[idx] = inp[idx]\n    return np.asarray(arr)\n\nimport numpy as np\n\ndef other(your_list):  # the approach from @Damian Lattenero in the other answer\n    ret = np.zeros(shape=(len(your_list)), dtype=int)\n    np.copyto(ret, your_list)\n    return ret\n\ninp = list(range(1000000))\n%timeit np.array(inp)\n# 315 ms \u00b1 5.42 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n%timeit np.array(inp, dtype=int)\n# 311 ms \u00b1 2.28 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n%timeit other(inp)\n# 316 ms \u00b1 3.97 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n%timeit to_array(inp)\n# 23.4 ms \u00b1 1.15 ms per loop (mean \u00b1 std. dev. of 7 runs, 10 loops each)\n",
    "a = numpy.array([[  0.,   1.,   2.,   3.],\n                 [  4.,   5.,   6.,   7.],\n                 [  8.,   9.,  10.,  11.]])\nnumpy.hstack((numpy.zeros((a.shape[0], 2)), a, numpy.zeros((a.shape[0], 1))))\n# array([[  0.,   0.,   0.,   1.,   2.,   3.,   0.],\n#        [  0.,   0.,   4.,   5.,   6.,   7.,   0.],\n#        [  0.,   0.,   8.,   9.,  10.,  11.,   0.]])\n",
    "np.where(data != data.round())\n(array([2, 3]),)\n\n(data - data.round()).nonzero()\n(array([2, 3]),)\n",
    "a = np.array([[[ 60.]],\n       [[ 80.]]])\nnp.repeat(np.tile(a, (1,2,1)), 2, axis=0)\n\n#array([[[ 60.],\n#        [ 60.]],\n\n#       [[ 60.],\n#        [ 60.]],\n\n#       [[ 80.],\n#        [ 80.]],\n\n#       [[ 80.],\n#        [ 80.]]])\n\nnp.repeat(a, 4).reshape(4,2,1)\n#array([[[ 60.],\n#        [ 60.]],\n\n#       [[ 60.],\n#        [ 60.]],\n\n#       [[ 80.],\n#        [ 80.]],\n\n#       [[ 80.],\n#        [ 80.]]])\n",
    "[y(0),Re(y(1)),Im(y(1)),...,Re(y(n/2))]              if n is even\n[y(0),Re(y(1)),Im(y(1)),...,Re(y(n/2)),Im(y(n/2))]   if n is odd\n",
    "import numpy as np\nimport copy\n\npairs = [(2, 3), (3, 4), (4, 5)]\narray_of_arrays = np.array([np.arange(a*b).reshape(a,b) for (a, b) in pairs])\n\na = copy.deepcopy(array_of_arrays)\n\na[0][0,0]\nprint a[0][0,0], array_of_arrays[0][0,0]\n"
   ]
  },
  {
   "questions": [
    "structure similar matlab: Good morning thoroughly looked around figuring create matlab struct array . input .csv header less matlab : implement logic structure .",
    "Iterate numpy array: Given array: Based array create array skip unit >5. : hints ( fast) ? Thank much your !",
    "Create numpy array (10x1) zeros fives: 'm having trouble figuring create 10x1 numpy array 5 7 . thoughts efficiently?",
    "Arrays Tuples: 'm write create array tuples look C array numbers. ( matlab) ValueError: setting element sequence. Could anyone ?",
    "Struggling implementing loops using oriented programming: having trouble wrapping head around loops /numpy. take implement logic says",
    "Creating numpy based condition: numpy : create array both aa bb exceed .5?",
    "create similarity matrix numpy ?: form: , matrix form : missing replaced . create both user user similarity matrix item item similarity matrix? ?",
    "Obtaining occurrences variable using : learning phase analyzing using , stumbled upon doubt. Consider : maximum jobs particular state using . eg:",
    "Scikit learn dataset maker accepting command arguments: 'm working tutorial Scikit learn, section creates dataset. : Makes completely normal chart. However, change accept command inputs: Even inputs : : been before. fix ?",
    "access scipy matrix dense format: building graph using networks follows: compressed matrix scipy matrix using csr format: recovered matrix its dense form: access element matrix? S.todense()[ ][ ]. ? Anyone ?"
   ],
   "code": [
    ">> data = struct('A',{}, 'B', {});\n>> for s=1:1;5\n       data(s).A = s\n       for t=1:1:3\n           data(s).B(t) = s+t\n       end;\n   end;\n\n>> data.A\nans =  1\nans =  2\nans =  3\nans =  4\nans =  5\n>> data.B\nans =\n   2   3   4\nans =\n   3   4   5\nans =\n   4   5   6\nans =\n   5   6   7\nans =\n   6   7   8\n>> save -7 stack47277436.mat data\n\nIn [17]: res = loadmat('stack47277436.mat')\nIn [18]: res\nOut[18]: \n{'__globals__': [],\n '__header__': b'MATLAB 5.0 MAT-file, written by Octave 4.0.0, 2017-11-14 04:48:21 UTC',\n '__version__': '1.0',\n 'data': array([[(array([[ 1.]]), array([[ 2.,  3.,  4.]])),\n         (array([[ 2.]]), array([[ 3.,  4.,  5.]])),\n         (array([[ 3.]]), array([[ 4.,  5.,  6.]])),\n         (array([[ 4.]]), array([[ 5.,  6.,  7.]])),\n         (array([[ 5.]]), array([[ 6.,  7.,  8.]]))]],\n       dtype=[('A', 'O'), ('B', 'O')])}\n\nIn [22]: res = loadmat('stack47277436.mat',squeeze_me=True)\nIn [24]: res['data']\nOut[24]: \narray([(1.0, array([ 2.,  3.,  4.])), (2.0, array([ 3.,  4.,  5.])),\n       (3.0, array([ 4.,  5.,  6.])), (4.0, array([ 5.,  6.,  7.])),\n       (5.0, array([ 6.,  7.,  8.]))],\n      dtype=[('A', 'O'), ('B', 'O')])\nIn [25]: _.shape\nOut[25]: (5,)\n\nIn [26]: res['data']['A']\nOut[26]: array([1.0, 2.0, 3.0, 4.0, 5.0], dtype=object)\nIn [27]: res['data']['B']\nOut[27]: \narray([array([ 2.,  3.,  4.]), array([ 3.,  4.,  5.]),\n       array([ 4.,  5.,  6.]), array([ 5.,  6.,  7.]),\n       array([ 6.,  7.,  8.])], dtype=object)\n\nIn [28]: import pandas as pd\nIn [29]: df = pd.DataFrame(res['data'])\nIn [30]: df\nOut[30]: \n   A                B\n0  1  [2.0, 3.0, 4.0]\n1  2  [3.0, 4.0, 5.0]\n2  3  [4.0, 5.0, 6.0]\n3  4  [5.0, 6.0, 7.0]\n4  5  [6.0, 7.0, 8.0]\nIn [31]: df.dtypes\nOut[31]: \nA    object\nB    object\ndtype: object\n\nIn [37]: A = res['data']['A'].astype(int)\nIn [38]: B = np.stack(res['data']['B'])\nIn [39]: A\nOut[39]: array([1, 2, 3, 4, 5])\nIn [40]: B\nOut[40]: \narray([[ 2.,  3.,  4.],\n       [ 3.,  4.,  5.],\n       [ 4.,  5.,  6.],\n       [ 5.,  6.,  7.],\n       [ 6.,  7.,  8.]])\n\nIn [48]: C = np.empty((5,), [('A',int), ('B', int, (3,))])\nIn [49]: C['A'] = A\nIn [50]: C['B'] = B\nIn [51]: C\nOut[51]: \narray([(1, [2, 3, 4]), (2, [3, 4, 5]), (3, [4, 5, 6]), (4, [5, 6, 7]),\n       (5, [6, 7, 8])],\n      dtype=[('A', '<i4'), ('B', '<i4', (3,))])\n",
    ">>> x[:, x[0] > 5]\narray([[ 5.5,  6. ,  7. ],\n       [ 2. ,  3. ,  4. ]])\n\n>>> numpy.array([2, 4, 6, 8])[numpy.array([True, False, False, True])]\narray([2, 8])\n",
    "import numpy as np\n\nthe_array = np.array([5]*3 + [0]*7)\n\nthe_array = np.zeros((10,))\nthe_array[:3] = 5\n",
    "numpy.array([(0.0, C[x]) for x in range(n)])\n",
    "import pandas.io.data as web\n\ndf = web.DataReader(['F', 'AAPL', 'IBM'], 'yahoo', '2015-01-02', '2016-01-01')['Adj Close']\n\ndf = pd.concat([df, \n                pd.rolling_mean(df, window=100).rename(\n                    columns={col: col + \"_100\" for col in df})], \n               axis=1)\n\ndf['condition'] = False\ndf.loc[(df.F < df.F_100) & \n       (df.AAPL < df.AAPL_100) & \n       (df.IBM > df.IBM_100), 'condition'] = True\n\n>>> df.tail()\n                  AAPL          F         IBM    AAPL_100      F_100     IBM_100 condition\nDate                                                                                      \n2015-12-24  106.796739  13.692101  135.544053  112.421986  13.616413  140.126056     False\n2015-12-28  105.600553  13.567714  134.916580  112.347147  13.611907  139.954141     False\n2015-12-29  107.498633  13.615554  137.044105  112.288827  13.607596  139.806220     False\n2015-12-30  106.094845  13.558146  136.612715  112.212631  13.602994  139.665642     False\n2015-12-31  104.058365  13.481600  134.926379  112.074727  13.595828  139.492368     False\n\n>>> df.condition.sum()\n8\n",
    "out1 = ((aa>0.5) & (bb>0.5)).astype(int)\nout2 = np.logical_and(aa>0.5, bb>0.5).astype(int)\nout3 = np.where((aa>0.5) & (bb>0.5),1,0)\nout4 = np.where(np.logical_and(aa>0.5, bb>0.5), 1, 0)\n\nout5 = ((aa>0.5) & (bb>0.5)).astype('int8')\nout6 = np.logical_and(aa>0.5, bb>0.5).astype('int8')\nout7 = ((aa>0.5) & (bb>0.5)).astype('uint8')\nout8 = np.logical_and(aa>0.5, bb>0.5).astype('uint8')\n\nout9 = ((aa>0.5) & (bb>0.5)).astype(np.int8)\nout10 = np.logical_and(aa>0.5, bb>0.5).astype(np.int8)\nout11 = ((aa>0.5) & (bb>0.5)).astype(np.uint8)\nout12 = np.logical_and(aa>0.5, bb>0.5).astype(np.uint8)\n\nIn [17]: # Input arrays\n    ...: aa = np.random.rand(1000,1000)\n    ...: bb = np.random.rand(1000,1000)\n    ...: \n\nIn [18]: %timeit ((aa>0.5) & (bb>0.5)).astype(int)\n    ...: %timeit np.logical_and(aa>0.5, bb>0.5).astype(int)\n    ...: %timeit np.where((aa>0.5) & (bb>0.5),1,0)\n    ...: %timeit np.where(np.logical_and(aa>0.5, bb>0.5), 1, 0)\n    ...: \n100 loops, best of 3: 9.13 ms per loop\n100 loops, best of 3: 9.16 ms per loop\n100 loops, best of 3: 10.4 ms per loop\n100 loops, best of 3: 10.4 ms per loop\n\nIn [19]: %timeit ((aa>0.5) & (bb>0.5)).astype('int8')\n    ...: %timeit np.logical_and(aa>0.5, bb>0.5).astype('int8')\n    ...: %timeit ((aa>0.5) & (bb>0.5)).astype('uint8')\n    ...: %timeit np.logical_and(aa>0.5, bb>0.5).astype('uint8')\n    ...: \n    ...: %timeit ((aa>0.5) & (bb>0.5)).astype(np.int8)\n    ...: %timeit np.logical_and(aa>0.5, bb>0.5).astype(np.int8)\n    ...: %timeit ((aa>0.5) & (bb>0.5)).astype(np.uint8)\n    ...: %timeit np.logical_and(aa>0.5, bb>0.5).astype(np.uint8)\n    ...: \n100 loops, best of 3: 5.6 ms per loop\n100 loops, best of 3: 5.61 ms per loop\n100 loops, best of 3: 5.63 ms per loop\n100 loops, best of 3: 5.63 ms per loop\n100 loops, best of 3: 5.62 ms per loop\n100 loops, best of 3: 5.62 ms per loop\n100 loops, best of 3: 5.62 ms per loop\n100 loops, best of 3: 5.61 ms per loop\n\nIn [20]: %timeit 1 * ((aa > 0.5) & (bb > 0.5)) #@BPL's vectorized soln\n100 loops, best of 3: 10.2 ms per loop\n",
    ">>> x\narray([[5, 3, 0],\n       [3, 0, 5],\n       [5, 5, 0],\n       [1, 1, 7]])\n\n>>> x\narray([[5, 300, 0],\n       [3, 0, 5],\n       [5, 500, 0],\n       [1, 100, 7]])\n\n>>> np.cov(x)\narray([[  6.33333333,  -3.16666667,   6.66666667,  -8.        ],\n       [ -3.16666667,   6.33333333,  -5.83333333,   7.        ],\n       [  6.66666667,  -5.83333333,   8.33333333, -10.        ],\n       [ -8.        ,   7.        , -10.        ,  12.        ]])\n\n>>> np.corrcoef(x)\narray([[ 1.        , -0.5       ,  0.91766294, -0.91766294],\n       [-0.5       ,  1.        , -0.80295507,  0.80295507],\n       [ 0.91766294, -0.80295507,  1.        , -1.        ],\n       [-0.91766294,  0.80295507, -1.        ,  1.        ]])\n",
    "from collections import Counter\n\ndf1 = df.groupby('CITY').OCCUPATION\n        .apply(lambda x: Counter(x).most_common(1)[0][0])\n        .reset_index()\nprint (df1)\n        CITY                 OCCUPATION\n0  BANGALORE  COMPUTER SCIENCE ENGINEER\n1    CHENNAI        MECHANICAL ENGINEER\n2      DELHI                  PHYSICIAN\n3     MUMBAI                      ACTOR\n4       PUNE                    MANAGER\n\ndf1 = df.groupby(['CITY', 'OCCUPATION'])\n        .size()\n        .groupby(level=0)\n        .nlargest(1)\n        .reset_index(level=0,drop=True)\n        .reset_index(name='a')\n        .drop('a', axis=1)\nprint (df1)\n        CITY                 OCCUPATION\n0  BANGALORE  COMPUTER SCIENCE ENGINEER\n1    CHENNAI        MECHANICAL ENGINEER\n2      DELHI                 JOURNALIST\n3     MUMBAI                      ACTOR\n4       PUNE                    MANAGER\n\nfrom collections import Counter\n\ndef f(x):\n    #print Series  \n    print (x)\n    #count values by Counter\n    print (Counter(x).most_common())\n    #get first top value - list ogf tuple\n    print (Counter(x).most_common(1))\n    #select list by indexing [0] - output is tuple\n    print (Counter(x).most_common(1)[0])\n    #select first value of tuple by another [0]\n    #for selecting count use [1] instead [0]\n    print (Counter(x).most_common(1)[0][0])\n    return Counter(x).most_common(1)[0][0]\n\ndf1 = df.groupby('CITY').OCCUPATION.apply(f).reset_index()\nprint (df1)\n        CITY                 OCCUPATION\n0  BANGALORE  COMPUTER SCIENCE ENGINEER\n1    CHENNAI        MECHANICAL ENGINEER\n2      DELHI                 JOURNALIST\n3     MUMBAI                      ACTOR\n4       PUNE                    MANAGER\n",
    "in1 = int(sys.argv[1])\nin2 = int(sys.argv[2])\nin3 = float(sys.argv[3])\nin4 = float(sys.argv[4])\n",
    "S.todense()[0, 0]\n\nS.A[0][0]\n\nS.A[0,0]\n"
   ]
  },
  {
   "questions": [
    "difference array (N, ) (N)? ?: newbie here coming MATLAB background. array move array. With MATLAB background : However \" \" (150, ) \" \" B (150, ). apparently command [:, ] results \" \" (150). Now, difference (150, ) (150)? Aren't they thing: vector? why isn't \"smart enough\" figure put vector, B, ? easy - vector (N, ) - vector (N)? really silly thing MATLAB much better...",
    "Translating MATLAB numpy: defining array 's, 's either end. MATLAB acheived , however, numpy quite : most efficient perform MATLAB command ?",
    "Matlab numpy indexing multiplication issue: MATLAB numpy: , : beta 256 array. MATLAB, , , found multiplying beta array producing difference . write original , pred 1389 , MATLAB multiply beta array?",
    "One liner matrix wise operations numpy (coming MATLAB environment): Each matrix sum . MATLAB write matrix mat hope appropriate site. .",
    "Matlab conversion: Matrices aligned: Below sample MATLAB its eqv using Numpy package. MATLAB fine giving issues: MATLAB/OCTAVE below : fix rather port Matlab successfully ?",
    "eig nobalance option MATLAB?: MATLAB issue command: order compute eigenvalues balance option. equivalent command NumPy? When NumPy version eig, produce MATLAB nobalance turned .",
    "Matlab migration: t below MATLAB using Numpy package: When details ASE_lamda variable OCTAVE below : Below eqv Code: prints below : Why array 52 while MATLAB / OCTAVE 51 - far understand MATLAB / OCTAVE indexes starts rather ?",
    "Numpy / Scipy : why throwing : MATLAB . MATLAB Code: Below eqv. : below : sure - means much expertise / Numpy / Scipy.",
    "Converting MATLAB function : MATLAB . appreciate converting . These developed till now,",
    "install numpy 're superuser?: 've downloaded binary opened home folder using great. However import numpy, apparently included. 've downloaded numpy binary opened home directory still . somewhere special put numpy folder ?"
   ],
   "code": [
    "In [1]: A = np.zeros([5,3])\nIn [2]: A[:,0].shape   \nOut[2]: (5,)\n\nIn [3]: A[:,0] = np.ones(5)\nIn [4]: A[:,0] = np.ones([1,5])\nIn [5]: A[:,0] = np.ones([5,1])\n...\nValueError: could not broadcast input array from shape (5,1) into shape (5)\n\nIn [6]: A[:,0] + np.ones(5);\nIn [7]: A[:,0] + np.ones([1,5]);\nIn [8]: A[:,0] + np.ones([5,1]);\n\nIn [9]: (A[:,0] + np.ones([5,1])).shape\nOut[9]: (5, 5)\n\n>> x = ones(2,3,4);\n>> size(x(1,:,:))\nans =\n   1   3   4\n>> size(x(:,:,1))\nans =\n   2   3\n>> size(x(:,1,1) )\nans =\n   2   1\n>> size(x(1,1,:) )\nans =\n   1   1   4\n\nIn [11]: A[:,[0]].shape    \nOut[11]: (5, 1)\nIn [12]: A[:,[0]] = np.ones([5,1])\n\nIn [13]: A[:,0] = np.ones([5,1]).T\n\nIn [14]: A[:,0] = np.ones([5,1]).flat\nIn [15]: A[:,0] = np.ones([5,1])[:,0]\n",
    "In [33]: import numpy as np\n\nIn [34]: np.r_[1, 2*np.ones(3), 1]\nOut[34]: array([ 1.,  2.,  2.,  2.,  1.])\n\nIn [42]: np.hstack(([1], 2*np.ones(3), [1]))\nOut[42]: array([ 1.,  2.,  2.,  2.,  1.])\n\nIn [45]: %timeit np.r_[1, 2*np.ones(300), 1]\n10000 loops, best of 3: 27.5 us per loop\n\nIn [46]: %timeit np.hstack(([1], 2*np.ones(300), [1]))\n10000 loops, best of 3: 26.4 us per loop\n\nIn [48]: %timeit np.append([1],np.append(2*np.ones(300)[:],[1]))\n10000 loops, best of 3: 28.2 us per loop\n\nIn [49]: %timeit a = 2*np.ones(300+2); a[0] = 1; a[-1] = 1\n100000 loops, best of 3: 6.79 us per loop\n\nIn [50]: %timeit a = np.empty(300+2); a.fill(2); a[0] = 1; a[-1] = 1\n1000000 loops, best of 3: 1.73 us per loop\n",
    "import numpy as np # Just in case\n\npred = np.dot(traindata[:, 1:257], beta[:,None])\n\npred = np.dot(traindata[:, 1:257], beta)\n",
    "import numpy as np\n\nmat = np.random.rand(5, 5)\nmat /= mat.sum(0)\nmat.sum(0) # will be array([ 1.,  1.,  1.,  1.,  1.])\n",
    "In [14]: YDFA_P0 = np.array([[1],[2],[3],[4],[5]])\nIn [15]: np.dot(YDFA_P0, np.ones((1,5)) )\nOut[15]: \narray([[ 1.,  1.,  1.,  1.,  1.],\n       [ 2.,  2.,  2.,  2.,  2.],\n       [ 3.,  3.,  3.,  3.,  3.],\n       [ 4.,  4.,  4.,  4.,  4.],\n       [ 5.,  5.,  5.,  5.,  5.]])\n",
    "from oct2py import octave\n...\n[X,L] = octave.eig(A)\n\nfrom oct2py import octave\n...\nA = octave.balance(A)\n[X,L] = octave.eig(A)\n",
    ">>> np.arange(ASE_lamda1, ASE_lamda2, del_lamda).shape\n(51,)\n",
    "np.arange[ASE_lamda1:del_lamda:ASE_lamda2]\n\nnp.arange(ASE_lamda1, ASE_lamda2, del_lamda)\n\narray([  1.00000000e-06,   1.00200000e-06,   1.00400000e-06,\n         1.00600000e-06,   1.00800000e-06,   1.01000000e-06,\n         ...\n         1.09000000e-06,   1.09200000e-06,   1.09400000e-06,\n         1.09600000e-06,   1.09800000e-06,   1.10000000e-06])\n\nIn [54]: ASE_lamda[:, np.newaxis]\nOut[54]: \narray([[  1.00000000e-06],\n       [  1.00200000e-06],\n       ...\n       [  1.09800000e-06],\n       [  1.10000000e-06]])\n\nIn [55]: ASE_lamda[np.newaxis, :]\nOut[55]: \narray([[  1.00000000e-06,   1.00200000e-06,   1.00400000e-06,\n          1.00600000e-06,   1.00800000e-06,   1.01000000e-06,\n          ...\n          1.09000000e-06,   1.09200000e-06,   1.09400000e-06,\n          1.09600000e-06,   1.09800000e-06,   1.10000000e-06]])\n",
    "centered_matrix = numpy.subtract(y, numpy.mean(y, axis=0)) \n",
    "$ pythonbrew install 2.7.2\n\n$ pythonbrew use 2.7.2\n\n$ pip install numpy\n"
   ]
  },
  {
   "questions": [
    "Queued model restarts , despite being trained: model started feed_dict model been converted using queues. feed_dict model expected, reason queued model won't resume feed_dict version. 't explain why few runs? ( 's implementing 4 dimension classifier, diff difference training , who inversely correlate) thing think Queue capacity? Console log: [restart] [restart]",
    "Cant Element List Numpy: calculate sum 1d matrices ( below), 't element array. cant explain reason why? Code: :",
    "Extract array : : extract 2nd array array, follows: res , didn't Can anyone explain why? found explicitly indicate index (arr[ ][ ]...), didn't .",
    "Assigning NumPy array: Can someone explain why attempt # ? Attempt # : [([[ . .]])] (why ' ' copied ?) Attempt # : [([[ . 4.]])] ( worked)",
    "\u201cTypeError: length converted scalars\u201d printing array : understand why \" length converted scalars\" . though occurred numpy array, . Please !",
    "TypeError: length converted scalars issue: script: issues here: When script, : Omitting beginning, why ? solve ? .",
    "Adding numpy array heap queue: Can someone please explain why results ValueError? message : Running adding .copy() heap fine, /subsequent reason . understand unknown truth aspect array [True, False, True] 's determine single True False , why heapq ? Especially case?",
    "Maintain strings converting numpy structured array: structure : structured using numpy. However, , keep floats lose string information: Resulting : Could anyone explain why happens, might keep string information?",
    "mpf mpmath mean?: : Everything fine occurs, says: 't multiply sequence non int type 'float'. change . says : y must dimension. Finally, found np.array array, trouble gone. Can anyone explain , represents, mpf. why codes behave ? numerical array, why used ? array, why 't multiply ? confused!",
    "TypeError: length converted scalars ( ): analytical dam break rectangular channel. idea water side dam 4m water downstream side dam, dam removed water evolves . im having issues \" range ( ):\" . paste . Can anyone explain why solutions? Thank When : Traceback (most recent call last): File \"D:\\Work\\NetBeansProjects\\Ritter_test_2\\src\\ritter_test_2.py\", 29, range( ): TypeError: length converted scalars half text fine. believe its statements issues may wrong. ."
   ],
   "code": [
    "(_, results, error, w1_computed, b1_computed, w2_computed, b2_computed) = sess.run([train_op, y, loss_op, w1, b1, w2, b2])\n",
    "import numpy as np\n\nmatrix = np.array([[1,2,3], [2,3,4], [1,1,1]])\nmy_sum_matrix = np.sum(matrix, axis=0)\nprint(my_sum_matrix)\n\n[4 6 8]\n",
    "arr[:,1,:]\n\narr[:,1]\n\nIn [360]: arr\nOut[360]: \narray([[[ -1. ,  -1. ,  -1. ,   0. ,   0. ,   0. ],\n        [  0.1,   0.1,   0.1,   2. ,   3. ,   4. ]],\n\n       [[ -1. ,  -1. ,  -1. ,   0. ,   0. ,  -1. ],\n        [  0.1,   0.1,   0.1,  16. ,  17. ,   0.1]],\n\n       [[ -1. ,  -1. ,  -1. ,   0. ,   0. ,   0. ],\n        [  0.1,   0.1,   0.1,   4. ,   5. ,   6. ]],\n\n       [[  0. ,   0. ,   0. ,  -1. ,   0. ,   0. ],\n        [  1. ,   2. ,   3. ,   0.1,   1. ,   2. ]],\n\n       [[ -1. ,  -1. ,   0. ,   0. ,   0. ,   0. ],\n        [  0.1,   0.1,   1. ,   9. ,  10. ,  11. ]]])\n\nIn [361]: arr[:,1]\nOut[361]: \narray([[  0.1,   0.1,   0.1,   2. ,   3. ,   4. ],\n       [  0.1,   0.1,   0.1,  16. ,  17. ,   0.1],\n       [  0.1,   0.1,   0.1,   4. ,   5. ,   6. ],\n       [  1. ,   2. ,   3. ,   0.1,   1. ,   2. ],\n       [  0.1,   0.1,   1. ,   9. ,  10. ,  11. ]])\n",
    "In [1]: import numpy as np\n\nIn [2]: x = np.zeros(1, dtype=np.dtype([('field', '<f8', (1, 2))]))\n\nIn [3]: y = x[0]['field'].copy()\n\nIn [4]: y[0] = 3\n\nIn [5]: y[1] = 4\n---------------------------------------------------------------------------\nIndexError                                Traceback (most recent call last)\n<ipython-input-5-cba72439f97c> in <module>()\n----> 1 y[1] = 4\n\nIndexError: index 1 is out of bounds for axis 0 with size 1\n\nIn [6]: y[0][1] = 4\n\nIn [7]: x\nOut[7]:\narray([([[0.0, 0.0]],)],\n      dtype=[('field', '<f8', (1, 2))])\n\nIn [8]: y\nOut[8]: array([[ 3.,  4.]])\n\nIn [9]: x[0]['field'] = y\n\nIn [10]: x\nOut[10]:\narray([([[3.0, 0.0]],)],\n      dtype=[('field', '<f8', (1, 2))])\n\nIn [1]: import numpy as np\n\nIn [2]: x = np.zeros(1, dtype=np.dtype([('field', '<f8', 2)]))\n\nIn [3]: y = x[0]['field'].copy()\n\nIn [4]: y[0] = 3\n\nIn [5]: y[1] = 4\n\nIn [6]: x[0]['field'] = y\n\nIn [7]: x\nOut[7]:\narray([([3.0, 0.0],)],\n      dtype=[('field', '<f8', (2,))])\n\nIn [8]: y\nOut[8]: array([ 3.,  4.])\n\nIn [9]: x['field'][0] = y\n\nIn [10]: x\nOut[10]:\narray([([3.0, 4.0],)],\n      dtype=[('field', '<f8', (2,))])\n\nIn [11]: x['field'] = y * 2\n\nIn [12]: x\nOut[12]:\narray([([6.0, 8.0],)],\n      dtype=[('field', '<f8', (2,))])\n\nIn [13]: x['field'][:] = y\n\nIn [14]: x\nOut[14]:\narray([([3.0, 4.0],)],\n      dtype=[('field', '<f8', (2,))])\n\nIn [15]: x[0]['field'][:] = y * 2\n\nIn [16]: x\nOut[16]:\narray([([6.0, 8.0],)],\n      dtype=[('field', '<f8', (2,))])\n",
    "print(\"x: %5.2f y: %5.4f\" %(x_list[i], y_list[i]))\n",
    "import numpy as np\n\ndef func(scores):\n    y = 0.5 * scores + 0.2\n    return scores / np.sum(np.exp(y))\n\nscores = np.array([3.0, 1.0, 0.2])\n\nfor res in func(scores):\n    print(res)\n\n0.339460254992\n0.113153418331\n0.0226306836661\n\nfrom matplotlib import pyplot as plt\nplt.plot(func(scores).T, linewidth=2)\n",
    ">>> arr = np.array([1,2,3])\n>>> bool(arr)\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n\n>>> if arr: pass\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n\n>>> arr > arr\narray([False, False], dtype=bool)\n>>> arr == arr\narray([ True,  True], dtype=bool)\n\n>>> if arr == arr: pass\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n\n>>> arr is arr\nTrue\n>>> arr is arr.copy()\nFalse\n",
    ">>> numpy.array(data, dtype=[('label', str), ('x', float), ('y', float)])\narray([('', 1.0, 2.0), ('', 2.0, 4.0), ('', 3.0, 6.0)], \n      dtype=[('label', '|S0'), ('x', '<f8'), ('y', '<f8')])\n\n>>> numpy.array(data, dtype=[('label', 'S2'), ('x', float), ('y', float)])\narray([('a', 1.0, 2.0), ('b', 2.0, 4.0), ('c', 3.0, 6.0)], \n      dtype=[('label', '|S2'), ('x', '<f8'), ('y', '<f8')])\n\n>>> numpy.array(data, dtype=[('label', (str, 2)), ('x', float), ('y', float)])\narray([('a', 1.0, 2.0), ('b', 2.0, 4.0), ('c', 3.0, 6.0)], \n      dtype=[('label', '|S2'), ('x', '<f8'), ('y', '<f8')])\n",
    ">>> x = mp.arange(0, 1, 0.1)\n>>> type(x)\nlist\n\n>>> x * 2.0\nTypeError: can't multiply sequence by non-int of type 'float'\n>>> y = [e * 2.0 for e in x]\n\n>>> np.array(x).dtype\ndtype('O')\n\n>>> np.array(x) * 2000.0\narray([mpf('0.0'), mpf('200.0'), mpf('400.0'), mpf('600.00000000000011'),\n       mpf('800.0'), mpf('1000.0'), mpf('1200.0000000000002'),\n       mpf('1400.0000000000002'), mpf('1600.0'), mpf('1800.0')], d\n",
    "for value in x:\n    if value <= xa:\n        h = h0\n    elif xa <= value <= xb:\n        h = (4.0/(9.0*g))*(((math.sqrt(g*h0))-(value/(2.0*t)))**2.0)\n    else:\n        h = 0\n"
   ]
  },
  {
   "questions": [
    "Convert string bytes float array [ hold]: string socket contains float array bytes. Now string float (4bit) numpy array. : :",
    "strings load string numpy ndarray: strings load strings numpy ndarray?",
    "put string array: put string location : ValueError: string float :",
    "Convert string based NaN's numpy NaN's: dataframe part shown below: contains NaN strings/objects. numpy nan instead. Best csv .",
    "Conversion array float array str: There array float prepared follows: necessary array 256 str.",
    "object array normal array : object array , actual much bigger. , normal floating numpy array.",
    "Converting \u201cstring\u201d \u201cfloat\u201d?: .txt lines form: \" string float: V113573.txt\". Does anyone syntax numpy, resolve issue?",
    "Converting \u201cstring\u201d \u201cfloat\u201d?: .txt lines form: \" string float: V113573.txt\". Does anyone syntax numpy, resolve issue?",
    ": Extracting float array lists: during processing create looking : created manner: extract float single 1D numpy array? : advance!",
    "Sorting recarray : fairly sort entire recarray . , array: sort :"
   ],
   "code": [
    "np.fromstring( \"\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\", np.float32 )\n\nValueError: string size must be a multiple of element size\n",
    "import numpy as np\n\nwith open(\"file.ext\") as f:\n    a = np.array(f.readlines())\n\nimport numpy as np\n\nwith open(\"file.ext\") as f:\n    a = np.array([map(float, line.split()) for line in f])\n",
    "rs = np.zeros((int(k), 10), dtype='object')\n",
    "converter = lambda x: pd.to_numeric(x, 'coerce')\ndf = pd.read_csv(StringIO(txt), delim_whitespace=True, converters={1: converter}, header=None)\ndf\n\ndf.dtypes\n\n0     object\n1    float64\ndtype: object\n",
    "result256str = []\nfor num in result256: result256str.append(str(num))\n",
    ">>> arr = array([array([[2.4567]],dtype=object),array([[3.4567]],dtype=object),array([[4.4567]],dtype=object),array([[5.4567]],dtype=object),array([[6.4567]], dtype=object)])\n>>> np.concatenate(arr).astype(None)\narray([[ 2.4567],\n       [ 3.4567],\n       [ 4.4567],\n       [ 5.4567],\n       [ 6.4567]])\n",
    "import numpy as np\nimport matplotlib.pyplot as plt\n\nconv = {0: lambda x: x.replace('.txt', \".lc\")}\nx, y = np.loadtxt(\"condensed.txt\", usecols=(0, 1),  delimiter=\"   \", \n                  unpack=True, converters=conv, dtype=(str, str), skiprows=1 )\n\nfor ii in range (len(x)):\n    jd, npmag = np.loadtxt(\"/net/jovan/export/jovan/oelkerrj/Vela/rotation/Vela/\"+x[ii], usecols=(0, 1), unpack=True)\n    plt.scatter (jd, npmag)\n    plt.xlabel ('Time')\n    plt.ylabel ('Mag')\n    plt.ylim ([max (npmag), min (npmag)])\n    plt.show() # aftertest comment this out\n    fileName = x[ii][:-3] + \".png\"\n    plt.savefig(fileName)\n\nprint \"done\"\n",
    "import numpy as np\nimport matplotlib.pyplot as plt\n\nconv = {0: lambda x: x.replace('.txt', \".lc\")}\nx, y = np.loadtxt(\"condensed.txt\", usecols=(0, 1),  delimiter=\"   \", \n                  unpack=True, converters=conv, dtype=(str, str), skiprows=1 )\n\nfor ii in range (len(x)):\n    jd, npmag = np.loadtxt(\"/net/jovan/export/jovan/oelkerrj/Vela/rotation/Vela/\"+x[ii], usecols=(0, 1), unpack=True)\n    plt.scatter (jd, npmag)\n    plt.xlabel ('Time')\n    plt.ylabel ('Mag')\n    plt.ylim ([max (npmag), min (npmag)])\n    plt.show() # aftertest comment this out\n    fileName = x[ii][:-3] + \".png\"\n    plt.savefig(fileName)\n\nprint \"done\"\n",
    "peakpositions=np.concatenate(peakpositions)\n\n>>> l= [[array([ 0.08606408]), array([ 0.26071976]),\n       array([ 0.181566  ,  0.94154611]),\n       array([ 0.1734347 ,  0.94160601]),\n       array([ 0.17859844,  0.94167483]),\n       array([ 0.16880761,  0.94156277]),\n       array([ 0.17624151,  0.94149038]),\n       array([ 0.18770433,  0.94181287]),\n       array([ 0.16707977,  0.94227733]), array([ 0.94162233]),\n       array([ 0.9426902,  0.9615621]), array([ 0.94195127,  0.96174422]),\n       array([ 0.94237795,  0.96195226,  0.98059446]),\n       array([ 0.94249657,  0.96219391,  0.98095329]),\n       array([ 0.94280697,  0.96286183,  0.98109352]),\n       array([ 0.94267473,  0.96304417,  0.98252799])]\n>>> np.concatenate(l)\narray([ 0.08606408,  0.26071976,  0.181566  ,  0.94154611,  0.1734347 ,\n        0.94160601,  0.17859844,  0.94167483,  0.16880761,  0.94156277,\n        0.17624151,  0.94149038,  0.18770433,  0.94181287,  0.16707977,\n        0.94227733,  0.94162233,  0.9426902 ,  0.9615621 ,  0.94195127,\n        0.96174422,  0.94237795,  0.96195226,  0.98059446,  0.94249657,\n        0.96219391,  0.98095329,  0.94280697,  0.96286183,  0.98109352,\n        0.94267473,  0.96304417,  0.98252799])\n>>> \n",
    "In [27]: import numpy as np\n\nIn [28]: data = np.array([[5,2], [4,1], [3,6]])\n\nIn [29]: col = 0\n\nIn [30]: data=data[np.argsort(data[:,col])]\nOut[30]: \narray([[3, 6],\n       [4, 1],\n       [5, 2]])\n"
   ]
  },
  {
   "questions": [
    "Need Tensorflow/Keras equivalent scipy signal.fftconvolve: apply scipy fftconvolve / convolve RGB images Keras Custom Loss Function scipy recognizes Tensors. couldn't tensors numpy . ? Actually, implement Keras Custom Loss Function didn't succeed yet. found link valid grayscale images. Right now, using : window = np.tile(window, ( , , , )) tf.nn.conv2d(img1, window, strides=[ , , , ],padding='VALID') Are lines equivalent : signal.fftconvolve(img1, window, mode='valid') ? whereas window = np.reshape(_FSpecialGauss( , sigma), ( , , , )) One thing, did notice limit window color channels .e. fftconvolve, .",
    "Tensorflow equivalent Numpy indexed assignment: pseudo(*)-equivalent Tensorflow ? guess : (*) pretend keep mutable neither executed moment tensor. Maybe ask : applying array conditional tensors tf.cond() depending tf.less() array numbers?"
   ],
   "code": [
    "import keras.backend as K\ndef myLoss(y_true, y_pred):\n\n    #where y_true is the true training data and y_pred is the model's output\n    convResult = K.conv2d(y_pred, kernel = window, padding = 'same')\n\ndef customLoss(yTrue,yPred):\n    tf.anyFunction(yTrue)\n    tf.anyFunction(yPred)\n\nmodel.compile(loss=myLoss, optimizer =....)\n",
    "tf.select(array < 50, tf.zeros_like(array), array)\n"
   ]
  },
  {
   "questions": [
    "Sort numpy array numpy lengths internal : numpy array element being numpy array varying lengths ( ndarray ), sort outer array descending lengths inner array? : sorted :",
    "Convert numpy array hex bytearray: numpy array bytestring .7. Lets say numpy array 2x2 array, looking : , array string bytes bytearray looking : equally well:",
    "float numpy array int numpy array?: real numpy array int numpy array? Tried using map directly array did .",
    "Split numpy array numpy : numpy array : split numpy : To give details numpy array dictionnary 've numpy array, below:",
    "concatenate single numpy array four numpy array?: numpy array vector. numpy array 4 vectors length single vector. combined array [ ,5]?",
    "pd numpy array back: numpy array dataframe. After tokenizing df converted df numpy array analysis KMeans numpy array Question back df .e comparing index array index",
    "flatten 2d numpy array, length axis?: numpy array : flatten , change array length axis, flatten . Question : Can thing myArray.flatten() regardless dimension array length its , : array([ , , ])?",
    "create numpy array minimum array: Starting Numpy array create 1D array corresponds minimum array. create array easy , 'm far.",
    "add numpy array numpy array: existing numpy array : 'd numpy array numpy : .e.",
    "numpy array raw input ?: write array using numpy, array raw input array. coming inarray = np. inlist), returning array. entire :"
   ],
   "code": [
    "np.array(sorted(b, key=len, reverse=True))\n",
    ">>> a.tobytes()\nb'\\x01\\n\\x10\\xff'\n\n>>> a.tobytes()[::8]\nb'\\x01\\n\\x10\\xff\n\n>>> a.view('S8')\narray([[b'\\x01', b'\\n'],\n       [b'\\x10', b'\\xff']], dtype='|S8')\n",
    ">>> x = np.array([[1.0, 2.3], [1.3, 2.9]])\n>>> x\narray([[ 1. ,  2.3],\n       [ 1.3,  2.9]])\n>>> x.astype(int)\narray([[1, 2],\n       [1, 2]])\n",
    "A=np.array([(datetime.datetime(2016, 6, 8, 12, 37, 27, 826000), 3.0),\n   (datetime.datetime(2016, 6, 8, 12, 37, 27, 827000), nan),\n   (datetime.datetime(2016, 6, 8, 12, 37, 27, 832000), nan),\n   (datetime.datetime(2016, 6, 8, 12, 37, 27, 833000), nan),\n   (datetime.datetime(2016, 6, 8, 12, 37, 27, 837000), 3.0),\n   (datetime.datetime(2016, 6, 8, 12, 37, 27, 837000), 35.0)])\n\nprint(A.dtype)\n\ntimes = np.array([x[0] for x in A])\nvalues = np.array([x[1] for x in A])\n\nprint(times)\nprint(values)\n\nimport numpy as np\nfrom numpy import nan\nimport datetime\n\nA=np.array([(datetime.datetime(2016, 6, 8, 12, 37, 27, 826000), 3.0),\n   (datetime.datetime(2016, 6, 8, 12, 37, 27, 827000), nan),\n   (datetime.datetime(2016, 6, 8, 12, 37, 27, 832000), nan),\n   (datetime.datetime(2016, 6, 8, 12, 37, 27, 833000), nan),\n   (datetime.datetime(2016, 6, 8, 12, 37, 27, 837000), 3.0),\n   (datetime.datetime(2016, 6, 8, 12, 37, 27, 837000), 35.0)],\n   dtype=[('time', object), ('value', float)])\n\nprint(A.dtype)\n\nprint(A['time'])\nprint(A['value'])\n",
    "import numpy\n\na = numpy.arange(12).reshape(3,4)\n#[[ 0  1  2  3]\n# [ 4  5  6  7]\n# [ 8  9 10 11]]\n\nb = numpy.arange(3).reshape(3,1)\n#[[0]\n# [1]\n# [2]]\n\nnumpy.hstack((a,b))\n#[[ 0  1  2  3  0]\n# [ 4  5  6  7  1]\n# [ 8  9 10 11  2]]\n",
    "arr = df.values\nprint (arr)\n[[34  1  2  3]\n [23  2  4  1]]\n\nprint (pd.DataFrame(arr))\n    0  1  2  3\n0  34  1  2  3\n1  23  2  4  1\nprint (pd.DataFrame(arr, index=df.index, columns=df.columns))\n    A  B  C  D\n0  34  1  2  3\n1  23  2  4  1\n",
    ">>> myArray.shape\n(2,)\n>>> myArray.dtype\ndtype('O')    # stands for Object\n>>> myArray[0]\n[1, 2]\n",
    "In [54]: dog=[[1,2],[4,3],[6,7]]\n\nIn [55]: np.min(dog, axis=1)\nOut[55]: array([1, 3, 6])\n\nIn [57]: dog = np.array([[1,2],[4,3],[6,7]])\n\nIn [58]: dog.min(axis=1)\nOut[58]: array([1, 3, 6])\n",
    "boxes = np.array([(59, 119, 175, 14), (147, 107, 66, 11)])\nnp.column_stack([boxes[:,0], boxes[:,1], boxes[:,2]+boxes[:,0], boxes[:,3]+boxes[:,1]])\n\narray([[ 59, 119, 234, 133], [147, 107, 213, 118]])\n",
    "In [17]: np.array('foo')\nOut[17]: \narray('foo', \n      dtype='|S3')\n\nIn [18]: np.array('abl').shape\nOut[18]: ()\n\nIn [19]: np.array('abl').dtype\nOut[19]: dtype('|S3')\n\nimport ast\ninarray = np.array(ast.literal_eval(inlist))\n"
   ]
  },
  {
   "questions": [
    "Numpy: non zero numpy array?: Suppose numpy array form: index ( ) non zero. instance, returned: go ?",
    "combinations numpy array?: numpy array combinations : .. we ?",
    "Apply function masked numpy array: 've got numpy array mask . apply function masked ?",
    "add extra numpy array: Lets say numpy array : add zeros b: easily numpy?",
    "add extra numpy array: Lets say numpy array : add zeros b: easily numpy?",
    "add extra numpy array: Lets say numpy array : add zeros b: easily numpy?",
    "element selection numpy array: subset required array original array( ) converting element np.nan? required must follows:",
    "add % numpy array?: numpy array: moment returning: + % , returns desired :",
    "fastest insert diagonally numpy array?: Suppose we numpy array : insert say diagonally becomes: fastest ?",
    "modify N numpy array ?: modify N numpy array?? , numpy array follows: change , forth P?"
   ],
   "code": [
    "(arr!=0).argmax(axis=0)\n\ndef first_nonzero(arr, axis, invalid_val=-1):\n    mask = arr!=0\n    return np.where(mask.any(axis=axis), mask.argmax(axis=axis), invalid_val)\n\nIn [296]: arr    # Different from given sample for variety\nOut[296]: \narray([[1, 0, 0],\n       [1, 1, 0],\n       [0, 1, 0],\n       [0, 0, 0]])\n\nIn [297]: first_nonzero(arr, axis=0, invalid_val=-1)\nOut[297]: array([ 0,  1, -1])\n\nIn [298]: first_nonzero(arr, axis=1, invalid_val=-1)\nOut[298]: array([ 0,  0,  1, -1])\n\ndef last_nonzero(arr, axis, invalid_val=-1):\n    mask = arr!=0\n    val = arr.shape[axis] - np.flip(mask, axis=axis).argmax(axis=axis) - 1\n    return np.where(mask.any(axis=axis), val, invalid_val)\n\nIn [320]: arr\nOut[320]: \narray([[1, 0, 0],\n       [1, 1, 0],\n       [0, 1, 0],\n       [0, 0, 0]])\n\nIn [321]: last_nonzero(arr, axis=0, invalid_val=-1)\nOut[321]: array([ 1,  2, -1])\n\nIn [322]: last_nonzero(arr, axis=1, invalid_val=-1)\nOut[322]: array([ 0,  1,  1, -1])\n",
    "import numpy as np\nfrom itertools import combinations\n\nt = np.random.rand(4,3) # dummy example np.array\nn_cols = t.shape[1] # number of columns\n\n# all the combinations in a tuple:\ncombs = tuple( t[:, comb] for n in range(n_cols+1) for comb in combinations(range(n_cols), n) )\n",
    "img[mask] = (img[mask]*0.5).astype(int)\n\nimg_out = np.where(mask,(img*0.5).astype(int),img)\n\nnp.putmask(img, mask, (img*0.5).astype('uint8'))\n",
    ": import numpy as np\n: N = 3\n: A = np.eye(N)\n\n: np.c_[ A, np.ones(N) ]              # add a column\narray([[ 1.,  0.,  0.,  1.],\n       [ 0.,  1.,  0.,  1.],\n       [ 0.,  0.,  1.,  1.]])\n\n: np.c_[ np.ones(N), A, np.ones(N) ]  # or two\narray([[ 1.,  1.,  0.,  0.,  1.],\n       [ 1.,  0.,  1.,  0.,  1.],\n       [ 1.,  0.,  0.,  1.,  1.]])\n\n: np.r_[ A, [A[1]] ]              # add a row\narray([[ 1.,  0.,  0.],\n       [ 0.,  1.,  0.],\n       [ 0.,  0.,  1.],\n       [ 0.,  1.,  0.]])\n: # not np.r_[ A, A[1] ]\n\n: np.r_[ A[0], 1, 2, 3, A[1] ]    # mix vecs and scalars\n  array([ 1.,  0.,  0.,  1.,  2.,  3.,  0.,  1.,  0.])\n\n: np.r_[ A[0], [1, 2, 3], A[1] ]  # lists\n  array([ 1.,  0.,  0.,  1.,  2.,  3.,  0.,  1.,  0.])\n\n: np.r_[ A[0], (1, 2, 3), A[1] ]  # tuples\n  array([ 1.,  0.,  0.,  1.,  2.,  3.,  0.,  1.,  0.])\n\n: np.r_[ A[0], 1:4, A[1] ]        # same, 1:4 == arange(1,4) == 1,2,3\n  array([ 1.,  0.,  0.,  1.,  2.,  3.,  0.,  1.,  0.])\n",
    ": import numpy as np\n: N = 3\n: A = np.eye(N)\n\n: np.c_[ A, np.ones(N) ]              # add a column\narray([[ 1.,  0.,  0.,  1.],\n       [ 0.,  1.,  0.,  1.],\n       [ 0.,  0.,  1.,  1.]])\n\n: np.c_[ np.ones(N), A, np.ones(N) ]  # or two\narray([[ 1.,  1.,  0.,  0.,  1.],\n       [ 1.,  0.,  1.,  0.,  1.],\n       [ 1.,  0.,  0.,  1.,  1.]])\n\n: np.r_[ A, [A[1]] ]              # add a row\narray([[ 1.,  0.,  0.],\n       [ 0.,  1.,  0.],\n       [ 0.,  0.,  1.],\n       [ 0.,  1.,  0.]])\n: # not np.r_[ A, A[1] ]\n\n: np.r_[ A[0], 1, 2, 3, A[1] ]    # mix vecs and scalars\n  array([ 1.,  0.,  0.,  1.,  2.,  3.,  0.,  1.,  0.])\n\n: np.r_[ A[0], [1, 2, 3], A[1] ]  # lists\n  array([ 1.,  0.,  0.,  1.,  2.,  3.,  0.,  1.,  0.])\n\n: np.r_[ A[0], (1, 2, 3), A[1] ]  # tuples\n  array([ 1.,  0.,  0.,  1.,  2.,  3.,  0.,  1.,  0.])\n\n: np.r_[ A[0], 1:4, A[1] ]        # same, 1:4 == arange(1,4) == 1,2,3\n  array([ 1.,  0.,  0.,  1.,  2.,  3.,  0.,  1.,  0.])\n",
    ": import numpy as np\n: N = 3\n: A = np.eye(N)\n\n: np.c_[ A, np.ones(N) ]              # add a column\narray([[ 1.,  0.,  0.,  1.],\n       [ 0.,  1.,  0.,  1.],\n       [ 0.,  0.,  1.,  1.]])\n\n: np.c_[ np.ones(N), A, np.ones(N) ]  # or two\narray([[ 1.,  1.,  0.,  0.,  1.],\n       [ 1.,  0.,  1.,  0.,  1.],\n       [ 1.,  0.,  0.,  1.,  1.]])\n\n: np.r_[ A, [A[1]] ]              # add a row\narray([[ 1.,  0.,  0.],\n       [ 0.,  1.,  0.],\n       [ 0.,  0.,  1.],\n       [ 0.,  1.,  0.]])\n: # not np.r_[ A, A[1] ]\n\n: np.r_[ A[0], 1, 2, 3, A[1] ]    # mix vecs and scalars\n  array([ 1.,  0.,  0.,  1.,  2.,  3.,  0.,  1.,  0.])\n\n: np.r_[ A[0], [1, 2, 3], A[1] ]  # lists\n  array([ 1.,  0.,  0.,  1.,  2.,  3.,  0.,  1.,  0.])\n\n: np.r_[ A[0], (1, 2, 3), A[1] ]  # tuples\n  array([ 1.,  0.,  0.,  1.,  2.,  3.,  0.,  1.,  0.])\n\n: np.r_[ A[0], 1:4, A[1] ]        # same, 1:4 == arange(1,4) == 1,2,3\n  array([ 1.,  0.,  0.,  1.,  2.,  3.,  0.,  1.,  0.])\n",
    ">>> import numpy as np\n>>> data = np.array([1,1,1,2,2,2,3,3,3,4,4,4,5,5,5])\n>>> required = np.where((data <= 2) | (data >= 4),data,np.nan)\n>>> required\narray([  1.,   1.,   1.,   2.,   2.,   2.,  nan,  nan,  nan,   4.,   4.,\n         4.,   5.,   5.,   5.])\n",
    "import numpy as np\nimport pandas as pd\n\n# Reproduce your numpy array\narr= np.array([[  0.0, 0.1046225518, 0.0, 0.8953774482, 0.0]])\n\n# Convert to 1-Column DataFrame of % Strings \n# (use pd.Series() instead if you'd prefer this as a Pandas Series)\nas_strings = pd.DataFrame([\"{0:.2f}%\".format(val * 100) for val in arr[0]])\n\n# Assign column name\nas_strings.columns = ['Numbers as Strings'] \n\nprint(as_strings)\n\n  Numbers as Strings\n0              0.00%\n1             10.46%\n2              0.00%\n3             89.54%\n4              0.00%\n",
    "matrix = numpy.array([[1, 2, 3],\n          [4, 5, 6],\n          [7, 8, 9],\n          [10, 11, 12]])\n\nmatrix_new = numpy.zeros((4,5))\nmatrix_new[:-1,1:] = matrix.reshape(3,4)\nmatrix_new = matrix_new.reshape(-1)[:-4].reshape(4,4)\n\nmatrix = numpy.array([[1, 2, 3],\n          [4, 5, 6],\n          [7, 8, 9],\n          [10, 11, 12]])\n\nd = matrix.shape[0]\nassert matrix.shape[1] == d - 1\nmatrix_new = numpy.ndarray((d, d+1), dtype=matrix.dtype)\nmatrix_new[:,0] = 0\nmatrix_new[:-1,1:] = matrix.reshape((d-1, d))\nmatrix_new = matrix_new.reshape(-1)[:-d].reshape(d,d)\n",
    ">>> P[:, [0, 1, 3]] += 10\n>>> \n>>> P\narray([[11, 12,  3, 18,  6],\n       [14, 15,  6, 14,  5],\n       [10,  8,  5, 13,  0]])\n"
   ]
  },
  {
   "questions": [
    "Can NumPy take care array (nonstrictly) increasing along axis?: function numpy guarantee rather fix (nonstrictly) increasing along particular axis? , array: np.foobar(X) Does foobar exist manually using np.diff smart indexing?",
    "plotting trigonometrical func: function * *arcctg( ) - , : 's smthg : wolfram : wrong?",
    "Can cumsum function NumPy decay while adding?: array = ( , , , ,4, ) cumsum numpy apply .95 decay before adding next ?",
    "rotate numbers numpy array (n,) (n, )?: Say numpy array: \"rotate\" : best ? been converting deque back ( below) better ?",
    "Numpy array (Rows Cols) array XYZ coordinates?: input array camera (greyscale ) : actual = 434x512 XYZ coordinates: .e. [[ ,y,z],[ ,y,z],...] Are efficient ways using Numpy?",
    "numpy () evaluating incorrectly: stop array greater 100. using np. () evaluate condition. condition met, np. () incorrectly evaluating. missing? .7.8 OS 10.8.5.",
    "slice matrix Numpy ( Theano): optimal slice matrix Numpy ( Theano) stride N, start index ? , matrix below, starting slice index , , [ , [ ]: [ ]+stride] below: got :",
    "Numpy array?: triyng NumPy (RGB) array: R, G B Could ? Thank Hugo",
    "numpy group function?: function numpy group down below ? couldn't good answer internet.. Wanted :",
    "generalized cumulative functions NumPy/SciPy?: function numpy scipy ( library) generalizes idea cumsum cumprod arbitrary function. , consider (theoretical) function func function accepts floats, returns float. Particular cases cumsum cumprod respectively. , apply :"
   ],
   "code": [
    "np.maximum.accumulate(X,axis=1)\n\nIn [233]: X\nOut[233]: \narray([[1, 2, 1, 4, 5],\n       [0, 3, 1, 5, 4]])\n\nIn [234]: np.maximum.accumulate(X,axis=1)\nOut[234]: \narray([[1, 2, 2, 4, 5],\n       [0, 3, 3, 5, 5]])\n\nIn [254]: X = np.random.rand(1000,1000)\n\nIn [255]: %timeit np.maximum.accumulate(X,axis=1)\n1000 loops, best of 3: 1.69 ms per loop\n\n# @c\u1d0f\u029f\u1d05s\u1d18\u1d07\u1d07\u1d05's pandas soln using df.cummax\nIn [256]: %timeit pd.DataFrame(X).cummax(axis=1).values\n100 loops, best of 3: 4.81 ms per loop\n\nIn [257]: df = pd.DataFrame(np.random.rand(1000,1000))\n\nIn [258]: %timeit np.maximum.accumulate(df.values,axis=1)\n1000 loops, best of 3: 1.68 ms per loop\n\n# @c\u1d0f\u029f\u1d05s\u1d18\u1d07\u1d07\u1d05's pandas soln using df.cummax\nIn [259]: %timeit df.cummax(axis=1)\n100 loops, best of 3: 4.68 ms per loop\n",
    "2*x*arcctg(x) - 1\n\nimport matplotlib.pyplot as plt \nimport numpy as np \n\nx = np.linspace(0, np.pi / 2)\ny = 2 * x * np.arctan(1/x) - 1\nplt.plot(x, y)\nplt.axis('tight')\nplt.show()\nimport matplotlib.pyplot as plt \nimport numpy as np \n\nx = np.linspace(-np.pi / 2, np.pi / 2, 1000)\ny = 2 * x * np.arctan(1/x) - 1\nplt.plot(x, y)\nplt.axis('tight')\nplt.show()",
    "import numpy as np\nfrom scipy.signal import lfilter\n\ndata = np.array([2, 3, 0, 0, 4, 3], dtype=float)  # lfilter wants floats\n\n# Conventional approach:\nresult_conv = []\nlast_value = 0\nfor elmt in data:\n    last_value = (last_value + elmt)*.95\n    result_conv.append(last_value)\n\n# IIR Filter:\nresult_IIR = lfilter([.95], [1, -.95], data)\n\nif np.allclose(result_IIR, result_conv, 1e-12):\n    print(\"Values are equal.\")\n",
    "a = np.array([0,1,2,3,4])\nb = np.roll(a,1)\nprint(b)\n>>> [4 0 1 2 3]\n",
    "m,n = a.shape\nR,C = np.mgrid[:m,:n]\nout = np.column_stack((C.ravel(),R.ravel(), a.ravel()))\n\nIn [45]: a\nOut[45]: \narray([[ 0.5 ,  0.75,  0.1 ,  0.6 ],\n       [ 0.3 ,  0.75,  1.  ,  0.9 ]])\n\nIn [46]: m,n = a.shape\n    ...: R,C = np.mgrid[:m,:n]\n    ...: out = np.column_stack((C.ravel(),R.ravel(), a.ravel()))\n    ...: \n\nIn [47]: out\nOut[47]: \narray([[ 0.  ,  0.  ,  0.5 ],\n       [ 1.  ,  0.  ,  0.75],\n       [ 2.  ,  0.  ,  0.1 ],\n       [ 3.  ,  0.  ,  0.6 ],\n       [ 0.  ,  1.  ,  0.3 ],\n       [ 1.  ,  1.  ,  0.75],\n       [ 2.  ,  1.  ,  1.  ],\n       [ 3.  ,  1.  ,  0.9 ]])\n\nIn [48]: out.tolist() # Convert to list of lists if needed\nOut[48]: \n[[0.0, 0.0, 0.5],\n [1.0, 0.0, 0.75],\n [2.0, 0.0, 0.1],\n [3.0, 0.0, 0.6],\n [0.0, 1.0, 0.3],\n [1.0, 1.0, 0.75],\n [2.0, 1.0, 1.0],\n [3.0, 1.0, 0.9]]\n",
    "In [5]: import numpy as np\n\nIn [6]: ratio_J_a = np.array([ 250.44244741,  186.92848637,  202.67726408,  143.01112845,\n   ...:                 132.95878384,  176.49130164,  178.9892571 ,  118.07516559,\n   ...:                     205.59639112,  183.64142204])\n\nIn [7]: print(np.all(ratio_J_a > 100.))\nTrue\n\nIn [8]: print(np.all(ratio_J_a < 100.))\nFalse\n\n(Pdb) np.all(ratio_J_a) > 100.\nFalse \n(Pdb) np.all(ratio_J_a) < 100.\nTrue\n\nIn [17]: \"{}\".format(np.all(ratio_J_a))\nOut[17]: 'True'\n\nIn [18]: \"{:d}\".format(np.all(ratio_J_a))\nOut[18]: '1'\n\n(Pdb) 1 > 100.\nFalse \n(Pdb) 1 < 100.\nTrue\n",
    "idx = A[:,0,None] + np.arange(stride+1)\nout = A[np.arange(idx.shape[0])[:,None], idx]\n\nIn [273]: A\nOut[273]: \narray([[ 1,  1,  2,  3,  4,  5,  6],\n       [ 1, 11, 12, 13, 14, 15, 16],\n       [ 3, 22, 23, 24, 25, 26, 27]])\n\nIn [274]: idx = A[:,0,None] + np.arange(stride+1)\n\nIn [275]: idx\nOut[275]: \narray([[1, 2, 3],\n       [1, 2, 3],\n       [3, 4, 5]])\n\nIn [276]: A[np.arange(idx.shape[0])[:,None], idx]\nOut[276]: \narray([[ 1,  2,  3],\n       [11, 12, 13],\n       [24, 25, 26]])\n",
    ">>> print px[:,:,0]\n[[  0 255 255   0   0]]\n\n>>> print px[:,:,1]\n[[  0 255   0 255   0]]\n\n>>> print px[:,:,2]\n[[  0 255   0   0 255]]\n",
    "import numpy_indexed as npi\nnpi.group_by(a[:, 0]).split(a[:, 1])\n",
    "In [22]: np.multiply.accumulate([[1, 2, 3], [4, 5, 6]], axis=1)\nOut[22]: \narray([[  1,   2,   6],\n       [  4,  20, 120]])\n\nIn [32]: uadd = np.frompyfunc(lambda x, y: x + y, 2, 1)\n\nIn [33]: uadd.accumulate([1, 2, 3])\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n\nValueError: could not find a matching type for <lambda> (vectorized).accumulate, \n            requested type has type code 'l'\n"
   ]
  },
  {
   "questions": [
    "TensorFlow : node Tensorflow trained model?: quite using Tensorflow, sample found while googling. freeze graph said input correct node. Since , having hard understand . node freeze whole graph? import tensorflow tf import numpy np import sys class Seq2Seq(object):",
    "print last : \u00b4m quite using numpy, : Having array: print last ? :",
    "Broadcasting: unleash NumPy speed filling One Hot vector?: order tensorflow, hot vector classes. create -hot vector, ripe numpy broadcasting.",
    "subtraction operation multidimensional : . element zero subtract columnwise. explanation : subtraction , : faster perform operation ? using numpy changed here easy understand numpy object",
    "rank d tensor along axis tensorflow?: ranks d tensor Tensorflow. numpy using : ranks : tensorflow?",
    "numpy three dimensiona slicing indexing ellipsis ?: 'm having hard understanding numpy's slicing indexing First : According documentation, objects selection tuple less N , : assumed subsequent dimensions. means [[ ], [ ], [ ]] , [[4], [5], [6]] 2x3 itself? ? ellipsis, Ellipsis expand : objects needed selection tuple length .ndim. There may single ellipsis present. Why [..., ] means?",
    "Adding 1D array Image?: import numpy np import random PIL import Image im = Image.open('baboon.png') = np. im) # array 512 512 = np.random.randint( , 131072) #1D array 512 512 add 132072 times randomly 512 512 . done form original + added ?",
    "loading : load using , load once. having fix . : : loading:",
    "sparse dataframe head : head sparse dataframe created using get_dummies. import numpy np; import pd;",
    "np.genfromtxt multiple delimiters?: : import numpy using np.genfromtxt. biggest ';' ',' delimiters. : : TypeError: Can't 'bytes' object str implicitly solve ? 'm open completely (better) ideas."
   ],
   "code": [
    "def load_graph(frozen_graph_filename):\n    # We load the protobuf file from the disk and parse it to retrieve the \n    # unserialized graph_def\n    with tf.gfile.GFile(frozen_graph_filename, \"rb\") as f:\n        graph_def = tf.GraphDef()\n        graph_def.ParseFromString(f.read())\n\n    # Then, we import the graph_def into a new Graph and return it \n    with tf.Graph().as_default() as graph:\n        # The name var will prefix every op/nodes in your graph\n        # Since we load everything in a new graph, this is not needed\n        tf.import_graph_def(graph_def, name=\"prefix\")\n    return graph\n\nfor op in graph.get_operations(): \n    print (op.name(), op.value()\n\n# This line is from my graph where the operator's name is \"y_\" and the value is \":0 \"    \ny = graph.get_tensor_by_name('prefix/y_:0')\n",
    ">>> x[:,-1]\narray([0, 0, 1, 1])\n>>> x[:,-1]==1\narray([False, False,  True,  True], dtype=bool)\n>>> x[x[:,-1]==1]\narray([[ 7,  8,  1],\n       [10, 11,  1]])\n",
    "(classVector[:,None] == uniques).astype(float)\n\nIn [47]: classVector\nOut[47]: array([15, 16, 24, 20, 14, 12, 14, 19, 12, 21])\n\nIn [48]: uniques = np.unique(classVector)\n\nIn [49]: uniques\nOut[49]: array([12, 14, 15, 16, 19, 20, 21, 24])\n\nIn [50]: (classVector[:,None] == uniques).astype(float)\nOut[50]: \narray([[ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n       [ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n       [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n       [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.]])\n",
    ">>> l = np.array([[1, 2, 8], [8, 2, 7], [7, 2, 5]])\n>>> l[:, 1:] -= l[:, :-1]\n>>> l[:, 0] = 0\n>>> l\narray([[ 0,  1,  6],\n       [ 0, -6,  5],\n       [ 0, -5,  3]])\n",
    "sess = tf.InteractiveSession()\na = tf.constant(np.array([[0,3,2], [6,5,4]]))\n# tf.nn.top_k sorts in ascending order, so negate to switch the sense\n_, ranks = tf.nn.top_k(-a, 3)\n# top_k outputs 0 based indices, so add 1 to get the same\n# effect as rankdata\nranks = ranks + 1\nsess.run(ranks)\n\n# output :\n# array([[1, 3, 2],\n#        [3, 2, 1]], dtype=int32)\n",
    "In [40]: x\nOut[40]: \narray([[[1],\n        [2],          # <= slice 1 of shape 3x1\n        [3]],\n\n       [[4],\n        [5],          # <= slice 2 of shape 3x1\n        [6]]])\n\nIn [42]: x[1:2]\nOut[42]: \narray([[[4],\n        [5],\n        [6]]])\n\nIn [45]: x.ndim\nOut[45]: 3\n\nIn [47]: x[...,0]\nOut[47]: \narray([[1, 2, 3],\n       [4, 5, 6]])\n\nIn [49]: x[0, ..., 0]\nOut[49]: array([1, 2, 3])\n",
    "from PIL import Image\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nim = Image.open('baboon.png')\n\nl = np.array(im)\n\ndata = 50*np.random.randint(2, size=(512,512,3))\n\nl_new = (l+data).astype(np.uint8)\n\nfig, ax = plt.subplots(1,2)\nax[0].imshow(l)\nax[1].imshow(l_new)\nfig.show()\n\nfrom PIL import Image\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Load image, convert to greyscale\nim = Image.open('baboon.png').convert('L')\n\nl = np.array(im)\n\ndata = np.random.randint(2, size=131072)\n\n# To add we need to pad data so it contains the same number of elements\npadSize = (l.shape[0]*l.shape[1])-data.shape[0]\ndata_new = np.pad(data, (0,padSize), mode='constant')\n\n# Now we reshape data\ndata_reshaped = data_new.reshape((512,512))\n\nl_new = l+data_reshaped\n\nfig, ax = plt.subplots(1,2)\nax[0].imshow(l, cmap=plt.cm.Greys)\nax[1].imshow(l_new,cmap=plt.cm.Greys)\nfig.show()\n",
    "import numpy as np\nfrom itertools import islice\n\nwith open(r'C:\\\\path\\\\to\\\\file\\\\a.txt') as f:\n    while True:\n        try :\n            line1 = next(f)\n            line2 = next(f)\n        except StopIteration:\n            break\n\n        a1 = np.loadtxt(islice(line1.split('   '), 2))\n        a2 = np.loadtxt(islice(line2.split('   '), 2))\n        a = np.array([a1,a2])\n\n        b1 = np.loadtxt(islice(line1.split('   '), 2, 4))\n        b2 = np.loadtxt(islice(line2.split('   '), 2, 4))\n        b = np.array([b1,b2])\n\n        print(a)\n        print(b)\n\n[[ 1.  2.]\n [ 2.  3.]]\n[[ 3.  4.]\n [ 4.  5.]]\n[[ 3.  4.]\n [ 4.  5.]]\n[[ 5.  6.]\n [ 6.  7.]]\n[[ 5.  6.]\n [ 6.  7.]]\n[[ 7.  8.]\n [ 8.  9.]]\n",
    "np.random.seed(1997)\n\ndf = pd.DataFrame(np.random.randn(100, 4))\ndf.iloc[:-97] = np.nan\ndata = df.to_sparse()\n\nprint (type(data))\n<class 'pandas.core.sparse.frame.SparseDataFrame'>\n\nprint (data.head())\n          0        1         2         3\n0       NaN      NaN       NaN       NaN\n1       NaN      NaN       NaN       NaN\n2       NaN      NaN       NaN       NaN\n3  1.938422  1.78731 -0.619745 -2.560187\n4 -0.986231 -1.94293  2.677379 -1.813071\n\nprint (data.iloc[:5])\n          0        1         2         3\n0       NaN      NaN       NaN       NaN\n1       NaN      NaN       NaN       NaN\n2       NaN      NaN       NaN       NaN\n3  1.938422  1.78731 -0.619745 -2.560187\n4 -0.986231 -1.94293  2.677379 -1.813071\n\nprint (data[:5])\n          0        1         2         3\n0       NaN      NaN       NaN       NaN\n1       NaN      NaN       NaN       NaN\n2       NaN      NaN       NaN       NaN\n3  1.938422  1.78731 -0.619745 -2.560187\n4 -0.986231 -1.94293  2.677379 -1.813071\n",
    ">>> with open('2e70dfa1.csv', 'rb') as f:\n...     clean_lines = (line.replace(b';',b',') for line in f)\n...     data = np.genfromtxt(clean_lines, dtype=int, delimiter=',')\n...\n>>> data\narray([[1497484825,      34425,         -4,         28,        -14,\n                -4,         28,        -14,         -4,         28,\n               -14,         -4,         28,        -14,         -4,\n                28,        -14,         -4,         28,        -14],\n       [1497484837,      34476,         -4,         28,        -14,\n                -4,         28,        -14,         -4,         28,\n               -14,         -4,         28,        -14,         -4,\n                28,        -14,         -4,         28,        -14]])\n"
   ]
  },
  {
   "questions": [
    ": (-215) s >= function cv::setSize -opencv face Detection & recognition [ hold]: 's post. sorry inconvenience writing query . 137 \"test_img1 = cv2.imread('test- /'+new_file)\" shown .. comment . 137 uncomment 138 \"test_img1 = cv2.imread(\"test- /test1.jpg\") \" 's properly . tasks runs takes photographs using webcam saves current date .jpg . system facial recognition throws . directory named test- been saved. training- subfolder named s1 s2 contains person",
    "iteration function: here's . Sorry previous post clear . here's : z y give answer, why ? function supposed give answer?",
    "unrecognized faces opencv2 labeled \u201cunknown\u201d?: .7 opencv2. Currently subject enters frame labels most its photo database. Instead label untrained faces \"unknown\" far: trainer :",
    "Opencv Otsu Thresholding after numpy?: ex post optimize iteration numpy . Then face next binary here : (-215) src.type() == CV_8UC1 function cv::threshold solve ?",
    "save txt folder: script running well saving txt Desktop running script Desktop. However, save txt files Documents folder named ASCII. give command . 8phases.txt lines- script- please-"
   ],
   "code": [
    "new_file = os.path.basename(latest_file)\n",
    "y=z=x*0\n\ny=x*0\nz=x*0\n",
    "        if(id==1):\n            id=\"Admin\"\n            cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n            cv2.putText(img,\"Admin\",x+h/2,y+w+40),cv2.FONT_HERSHEY_SIMPLEX,0.6,(0,255,255),2)\n        elif(id==2):\n            id=\"Sonja\"\n            #cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,255),2)\n            cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,255),2)\n            cv2.putText(img,\"Sonja\",x+h/2,y+w+40),cv2.FONT_HERSHEY_SIMPLEX,0.6,(255,255,255),2)\n        else:\n            cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,255),2)#Red\n            cv2.putText(img,\"Unknown\",(x+h/2,y+w+40),cv2.FONT_HERSHEY_SIMPLEX,0.6,(0,0,255),2)\n",
    "processedimg = np.where(exg > 50, exg, 2)\nprocessedimg = cv2.convertScaleAbs(processedimg)\nret2,th2 = cv2.threshold(processedimg,0,255,cv2.THRESH_OTSU) //error line\n\ncv2. convertScaleAbs\n",
    "np.savetxt(r\"C:\\ASCII\\%s.txt\" % count,s)\n"
   ]
  },
  {
   "questions": [
    "fit log( - ) type functions scipy. curve_fit?: fit function log(y)= *log(b- )+c, , b c parameters fitted. relevant bit Where T Energy generated ( things fine). T . . . pretty sure fact point b T keep ValueError: Residuals finite initial point. sure solve .",
    "scikit - ValueError: post stackoverflow here save classifier. When mentioned post. keep ValueError: Vocabulary wasn't fitted empty! training follows: testing follows: thrown executing wrong here?",
    "curve_fit properly 4 parameters: Running , produces Graph, With parameters standard deviation: However, fit function: , produces standard deviation fix ?",
    "mean - TypeError: length converted scalars?: pass function define using lambda keyword plotting function, TypeError message. relevant piece : message: Whay TypeError stands case?",
    "fit cosine function?: wrote function parameters cosine function: Matlab amplitude, offset shift cosine function?",
    "overcome y length scipy.interpolate.interp1d()?: put together function based smoothing matplotlib lines interpolate y \"ValueError: y must equal length along interpolation axis.\" assume wants array empty length numpy.linspace y distributed correctly . even 's right.",
    "curve_fit() using : TypeError: model() missing required positional arguments: 'mu' 'sigma'",
    "Access - : 'm access . Basically , 'weights' array . later calculation. ValueError: truth array element ambiguous. Use . () . () 've using np.extract() give ...",
    "intersection multiple curves ?: represented figure. curves were extrapolated whose equation known. equation curves unknown. Now, intersection curves? reproducible :",
    "proper curve_fit fit function takes 1D input returns array: scipy.optimize.curve_fit fit array ( 10x10 array) function defined follows function musq takes 1D array (dz np.arange( . , . , . )) returns array. When fit function ValueError: object too deep desired array. understand must input mismatch... proper fit function 1D input returns array? follows"
   ],
   "code": [
    "popt, pcov=curve_fit(logfunc, np.linspace(0.3, 3.2, 6), [8, 7, 6, 5, 4, 3], bounds=([0.1, 3.2, 0.1], [1.0, 3.6, 1.0]))\n",
    "X_new_counts = count_vect.fit_transform(docs_new)\n",
    "par, cov = curve_fit(f, x, y, p0=[1.,1.,1.,74.])\n\npar = [ 4.11892318e+02, 4.36953868e+02, 1.55741131e-02, 7.32560690e+01])\nstdev = [ 1.17579445e+01, 1.94401006e+01, 1.86709423e-03, 2.62952690e-01]\n",
    "def __float__(self):\n    if len(self) is 1:\n        return self.flatten()[0]\n    else:\n        raise TypeError, 'only length-1 arrays can be converted to Python scalars'\n",
    "y = B + A*cos(w*x + phi)\n\n%// Create some bogus data\n\nA   = 8;\nB   = -4;\nw   = 0.2;\nphi = 1.8;\n\nx = 0 : 0.1 : 8.4*pi;\ny = B + A*cos(w*x + phi) + 0.5*randn(size(x));\n\n%// Find kick-ass initial estimates\nL = length(y);\nN = 2^nextpow2(L);\n\nB0 = (max(y(:))+min(y(:)))/2;\n\nY = fft(y-B0, N)/L;\nf = 5/(x(2)-x(1)) * linspace(0,1,N/2+1);\n\n[A0,I] = max( 2*abs(Y(1:N/2+1)) );\nw0   = f(I);\nphi0 = 2*imag(Y(I));\n\n%// Refine the fit\nsol = fminsearch(@(t) sum( (y(:)-t(1)-t(2)*cos(t(3)*x(:)+t(4))).^2 ), [B0 A0 w0 phi0])\n\nsol = %// B was -4      A was 8       w was 0.2     phi was 1.8                \n         -4.0097e+000   7.9913e+000   1.9998e-001   1.7961e+000    \n",
    "def spline_it(key):\n    y = [i[1] for i in datapoints[key]]\n    x = np.arange(len(y))\n    interpolator = interp1d(x, y, kind='cubic')\n    x_smooth = np.linspace(0,len(y),len(y)*10)\n    y_smooth = interpolator(x_smooth)\n    return x_smooth, y_smooth\n",
    "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.optimize import curve_fit\ndef func(x, a, b, c):\n    return a * np.exp(-b * x) + c\n\nxdata = np.linspace(0, 4, 50)\ny = func(xdata, 2.5, 1.3, 0.5)\nydata = y + 0.2 * np.random.normal(size=len(xdata))\n\npopt, pcov = curve_fit(func, xdata, ydata,p0=[2,1,1])\n\nplt.ion()\nplt.plot(xdata,ydata,'o')\nxplot = np.linspace(0,4,100)\nplt.plot(xplot,func(xplot,*popt))\n",
    "#data = numpy array of size (141,141)\nweights = np.zeros([141,141])\nind = ((data > 40.) & (data < 50.)).astype(float) \nweights[np.where(ind==1)]=1.0\n",
    "def quadratic_intersections(p, q):\n    \"\"\"Given two quadratics p and q, determines the points of intersection\"\"\"\n    x = np.roots(np.asarray(p) - np.asarray(q))\n    y = np.polyval(p, x)\n    return x, y\n\nx1 = np.linspace(0, 0.4, 100)\ny1 = -100 * x1 + 100\nplt.figure(figsize = (7,7))\nplt.subplot(111)\n\nplt.plot(x1, y1, linestyle = '-.', linewidth = 0.5, color =  'black')\nfor i in range(5):\n    x_val = np.linspace(x[0, i] - 0.05, x[-1, i] + 0.05, 100)\n    poly = np.polyfit(x[:, i], y[:, i], deg=2)\n    y_int  = np.polyval(poly, x_val)\n    plt.plot(x[:, i], y[:, i], linestyle = '', marker = 'o')\n    plt.plot(x_val, y_int, linestyle = ':', linewidth = 0.25, color =  'black')\n    ix = quadratic_intersections(poly, [0, -100, 100])\n    plt.scatter(*ix, marker='x', color='black', s=40, linewidth=2)\n\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.xlim([0,.35])\nplt.ylim([40,110])\nplt.show()\n\nimport scipy.optimize\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.style\n\nmatplotlib.style.use('fivethirtyeight')\n%matplotlib inline\n\nf = lambda x: np.cos(x) - x\ng = np.sin\n\nh = lambda x: f(x) - g(x)\n\nx = np.linspace(0,3,100)\nplt.plot(x, f(x), zorder=1)\nplt.plot(x, g(x), zorder=1)\n\nx_int = scipy.optimize.fsolve(h, 1.0)\ny_int = f(x_int)\n\nplt.scatter(x_int, y_int, marker='x', s=150, zorder=2, \n            linewidth=2, color='black')\n\nplt.xlim([0,3])\nplt.ylim([-4,2])\n",
    "from scipy.optimize import least_squares\nimport numpy as np\n\ndef musq(x, param):\n    return 1.0/(1.0+param**2*(x/x[:,None])**2)\n\nx = np.arange(0.1,1.1,0.1)\nparam = np.arange(10)\ny = musq(x, param)\n\nresult = least_squares(lambda param: musq(x, param).ravel() - y.ravel(),\n                       x0=np.zeros_like(param))\n\n>>> result.x\narray([ 0.        ,  1.        ,  2.        ,  3.        ,  4.        ,\n        5.        ,  6.        ,  7.        ,  7.99999996,  8.99999922])\n"
   ]
  },
  {
   "questions": [
    "Image deduction Pillow Numpy: images: export red \"Hello\" : running deduction script: returns: rather . wrong? Also numpy Pillow Library? images : returns: Confused why pixelated around edges!",
    "Remove sequential NumPy index 's content: 'm iterating NumPy (nd) array OpenCV lines. remove lines outwith 8 degrees vertical. realise numpy array immutable 'm right demonstrates idea 'm ; go removing NumPy indexes? !",
    "Getting linearized numpy: emulate MATLAB function , returns linear nonzero array. : numpy similar function nonzero, returns tuple index . : function linear calculating myself?",
    "Numpy inner product vectors: take inner product vectors 's numpy Below returned instead 5",
    "Storing objects vs. fixed length Numpy array: bioinformatics , 've been pondering ramifications storing object instances Numpy rather , testing 've done performance worse instance. using CPython. Does anyone reason why? Specifically:",
    "Storing objects vs. fixed length Numpy array: bioinformatics , 've been pondering ramifications storing object instances Numpy rather , testing 've done performance worse instance. using CPython. Does anyone reason why? Specifically:",
    "Multiply dimensions using numpy: faster/optimised version current : faster using numpy functions (maybe reshaping blowing whole thing)?",
    "Numpy astype rounding wrong : turn float numpy array integers. : changes array: : , wondering had idea why ? np.uint64 using next. Thank advance.",
    "Converting string Numpy datetime: 'm using numpy .8. results below: produces : 'm wrong? 'm especially confused produces expected :",
    "Pandas frame creation inconsistencies: creating dataframe dictionary: Returns: Notice 2d items position ('pos') velocity ('vel') . However replace 2d 2d numpy array: exception: Unfortunately using contained within numpy array , ?"
   ],
   "code": [
    "im = im2.copy()\nim[im1 == im2] = 0\nim = Image.fromarray(im)\n\nfrom PIL import ImageChops\nfrom PIL import Image\n\nroot = '/root/'\nim1 = Image.open(root + '1.jpg')\nim2 = Image.open(root + '2.jpg')\n\ndef nonzero(a):\n    return 0 if a < 10 else 255\n\nmask = Image.eval(ImageChops.difference(im1, im2), nonzero).convert('1')\n\nim = Image.composite(im2, Image.eval(im2, lambda x: 0), mask)\n",
    "index = 0\nidx = []\nfor line in self.lines[0]:\n    if (line[1]*180)/np.pi > 8:     \n       idx.append(index)         \n    index+=1\n\nself.lines[0] = np.delete(self.lines[0], idx, axis=0)\n",
    ">>> np.flatnonzero(a)\narray([ 0, 15])\n\n>>> print inspect.getsource(np.flatnonzero)\ndef flatnonzero(a):\n    \"\"\"\n    Return indices that are non-zero in the flattened version of a.\n\n    This is equivalent to a.ravel().nonzero()[0].\n\n    [more documentation]\n\n    \"\"\"\n    return a.ravel().nonzero()[0]\n",
    "import numpy as np\nx = np.array([[1], [2]])\nnp.inner(np.transpose(x), np.transpose(x))\n\nimport numpy as np\nx = np.array([1,2])\nnp.inner(x, x)\n",
    "from random import random\n\nclass PointSet(object):\n    def __init__(self, numpoints):\n        self.points = [Point(random(), random()) for _ in xrange(numpoints)]\n\n    def update(self):\n        for point in self.points:\n            point.x += random() - 0.5\n            point.y += random() - 0.5\n\nclass Point(object):\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n\npoints = PointSet(100000)\npoint = points.points[10]\n\nfor _ in xrange(1000):\n    points.update()\n    print 'Position of one point out of 100000:', point.x, point.y\n\nimport numpy as np\n\nclass PointSet(object):\n    def __init__(self, numpoints):\n        self.coords = np.random.random((numpoints, 2))\n        self.points = [Point(i, self.coords) for i in xrange(numpoints)]\n\n    def update(self):\n        \"\"\"Update along a random walk.\"\"\"\n        # The \"+=\" is crucial here... We have to update \"coords\" in-place, in\n        # this case. \n        self.coords += np.random.random(self.coords.shape) - 0.5\n\nclass Point(object):\n    def __init__(self, i, coords):\n        self.i = i\n        self.coords = coords\n\n    @property\n    def x(self):\n        return self.coords[self.i,0]\n\n    @property\n    def y(self):\n        return self.coords[self.i,1]\n\n\npoints = PointSet(100000)\npoint = points.points[10]\n\nfor _ in xrange(1000):\n    points.update()\n    print 'Position of one point out of 100000:', point.x, point.y\n",
    "from random import random\n\nclass PointSet(object):\n    def __init__(self, numpoints):\n        self.points = [Point(random(), random()) for _ in xrange(numpoints)]\n\n    def update(self):\n        for point in self.points:\n            point.x += random() - 0.5\n            point.y += random() - 0.5\n\nclass Point(object):\n    def __init__(self, x, y):\n        self.x = x\n        self.y = y\n\npoints = PointSet(100000)\npoint = points.points[10]\n\nfor _ in xrange(1000):\n    points.update()\n    print 'Position of one point out of 100000:', point.x, point.y\n\nimport numpy as np\n\nclass PointSet(object):\n    def __init__(self, numpoints):\n        self.coords = np.random.random((numpoints, 2))\n        self.points = [Point(i, self.coords) for i in xrange(numpoints)]\n\n    def update(self):\n        \"\"\"Update along a random walk.\"\"\"\n        # The \"+=\" is crucial here... We have to update \"coords\" in-place, in\n        # this case. \n        self.coords += np.random.random(self.coords.shape) - 0.5\n\nclass Point(object):\n    def __init__(self, i, coords):\n        self.i = i\n        self.coords = coords\n\n    @property\n    def x(self):\n        return self.coords[self.i,0]\n\n    @property\n    def y(self):\n        return self.coords[self.i,1]\n\n\npoints = PointSet(100000)\npoint = points.points[10]\n\nfor _ in xrange(1000):\n    points.update()\n    print 'Position of one point out of 100000:', point.x, point.y\n",
    ">>> np.outer(a, b)\narray([[ 10,  20,  30,  40,  50,  60,  70,  80],\n       [ 20,  40,  60,  80, 100, 120, 140, 160],\n       [ 30,  60,  90, 120, 150, 180, 210, 240]])\n",
    ">>> a = np.array([5, 6, 7], dtype=float) - 1e-12\n>>> a\narray([ 5.,  6.,  7.])\n>>> a.astype(np.uint64)\narray([4, 5, 6], dtype=uint64)\n>>> np.around(a).astype(np.uint64)\narray([5, 6, 7], dtype=uint64)\n",
    ">>> data[0]\n['2015-01-03 05:00:00', 5, 5.01]\n\n'2015-01-03 05:00:00'\n\ndata = []\ndata.append('2015-01-03 05:00:00')\ndata.append('2015-01-04 05:00:00')\ndata.append('2015-01-05 05:00:00')\nnp.array(data, dtype=dt)\n\n#output\narray(['2015-01-03T05:00:00+0100', '2015-01-04T05:00:00+0100',\n       '2015-01-05T05:00:00+0100'], dtype='datetime64[s]')\n\nfor i in range(len(data)):\n    date = np.array(data[i][0], dtype=dt)\n    data[i][0] = date\n\n    >>> data\n[[array(datetime.datetime(2015, 1, 3, 4, 0), dtype='datetime64[s]'), 5, 5.01], \n[array(datetime.datetime(2015, 1, 4, 4, 0), dtype='datetime64[s]'), 7, 7.01], \n[array(datetime.datetime(2015, 1, 5, 4, 0), dtype='datetime64[s]'), 8, 8.01], \n[array(datetime.datetime(2015, 1, 6, 4, 0), dtype='datetime64[s]'), 10, 10.01]]\n\ndt = np.dtype([('name', np.str_, 16), ('grades', np.float64, (2,))])\nx = np.array([('Sarah', (8.0, 7.0)), ('John', (6.0, 7.0))], dtype=dt)\nx[1]\n#output:  \n        ('John', [6.0, 7.0])\n\nx[1]['grades']\n#output   \n        array([ 6.,  7.])\n",
    "obs_dict = {\n        'pos':[[0,0],[10,10]],\n        'vel':[[0,0],[0,0]],\n        'mass':np.array([10000,10000])\n       }\nprint pd.DataFrame(obs_dict)`\n\ntt = pd.DataFrame(obs_dict)\ntt.dtypes\n\nmass     int64\npos     object\nvel     object\ndtype: object\n"
   ]
  },
  {
   "questions": [
    "Pandas - invalid entry choicelist: 'm filter , contains certain string, 'll append specific . Example: , : wrong?",
    "Finding intersection/difference lists: lists: filter similar those b. Like case, : most effective ?",
    "Plotting irrational function numpy piecewise matplotlib: 'm Irrational function matplotlib using piecewise Numpy , : : .",
    "Numpy assignment casting int: 'm fairly numpy. As shown below, cast numeric strings integers, seem 'stick', below: string ints array ?",
    "() : check string phrases contains certain keywords phd_words. . fix ?",
    "Get mean containing NaNs : mean contains NaNs. By using: expected NaN wrong. mean?",
    "Randomly shuffle labels files order: l numpy contains contains labels. l shuffle respect their labels. , l shuffle labels order. preserves order shuffling ?",
    "check matrix contains zero ?: matrix, 'd check zeros somewhere . numpy?",
    "slice numpy based condition: numpy array filtered , containing 999 using numpy slicing? Desired :",
    "Pandas Error: ValueError: Expected \u201cX\u201d fields \u201cX\u201d, saw \u201cX\u201d: 'm excel using . below: below: Are around ?"
   ],
   "code": [
    "conditions = [df['columnA'].str.contains('valueA', na=False)]\n\ndf = pd.DataFrame({'columnA':['valueA  ff','ss valueA','valueA 4','w','e',np.nan]})\nprint (df)\n      columnA\n0  valueA  ff\n1   ss valueA\n2    valueA 4\n3           w\n4           e\n5         NaN\n\nprint (df['columnA'].str.contains('valueA'))\n0     True\n1     True\n2     True\n3    False\n4    False\n5      NaN\nName: columnA, dtype: object\n\nprint (df['columnA'].str.contains('valueA', na=False))\n0     True\n1     True\n2     True\n3    False\n4    False\n5    False\nName: columnA, dtype: bool\n\nconditions = [df['columnA'].str.contains('valueA', na=False)]\nchoices    = ['valueB']\n\ndf['columnB'] = np.select(conditions,  choices, default = 'default')\nprint (df)\n      columnA  columnB\n0  valueA  ff   valueB\n1   ss valueA   valueB\n2    valueA 4   valueB\n3           w  default\n4           e  default\n5         NaN  default\n",
    "a = [('when', 3), ('why', 4), ('throw', 9), ('send', 15), ('you', 1)]\nb = ['the', 'when', 'send', 'we', 'us']\nfiltered = [i for i in a if not i[0] in b]\n\n>>>print(filtered)\n[('why', 4), ('throw', 9), ('you', 1)]\n",
    "import numpy as np\nimport matplotlib.pyplot as plt\n\n\np = np.poly1d([-4., 32., -64., 0., 1.])\nroots = p.r\nprint(roots)\nx = np.arange(roots[3], roots[2], .001)\nx1 = np.arange(roots[1], roots[0], .001)\nx = np.append(x, x1)\nfunc = np.piecewise(x, [(roots[3] < x) & (x < roots[2]), (roots[1] < x) & (x < roots[0])], \n                    [lambda x: (4. * x - 8.) / np.sqrt(1. - (8. * x - 2. * x ** 2.) ** 2.), \n                     lambda x: (4. * x - 8.) / np.sqrt(1. - (8. * x - 2. * x ** 2.) ** 2.)])\npos = np.where(np.abs(np.diff(func)) >= 10.)[0] + 1\nx = np.insert(x, pos, np.nan)\nfunc = np.insert(func, pos, np.nan)\nplt.ylim(-50., 50.)\nplt.grid('on')\nplt.plot(x, func, 'b-')\nfor i in roots:\n    plt.vlines(i, -100, 100, colors='red', linestyles='dashed')\nplt.legend([r'$g_3(x)=\\frac{4x-8}{\\sqrt{1-\\left(8x-2x^2\\right)^2}}$', r'$x=-0.12132034$', \n            r'$x=0.12917131$', r'$x=3.87082869$', r'$x=4.12132034$'], loc='best')\nplt.title(r'$Funci\u00f3n\\;Punto\\;Fijo\\;3$')\nplt.savefig('ecuacioncoseno2.png', bbox_inches='tight')\nplt.show()\n",
    "a = a.astype(object)\na[:,1:3] = a[:,1:3].astype(int)\nprint(a)\n> [['a' 1 2]\n   ['b' 3 4]]\n",
    "In [1]: %pylab\nUsing matplotlib backend: Qt4Agg\nPopulating the interactive namespace from numpy and matplotlib\n\nIn [2]: if any('b' in w for w in ['a', 'c']):\n   ...:     print('What?')\n   ...:\nWhat?\n\nIn [3]: any('b' in w for w in ['a', 'c'])\nOut[3]: <generator object <genexpr> at 0x7f6756d1a948>\n\nIn [4]: any\nOut[4]: <function numpy.core.fromnumeric.any>\n",
    "np.nanmean(mylist)\n\nIn [108]: np.nanmean([np.nan, 1, 2, np.nan, 3])\nOut[108]: 2.0\n",
    "idx = np.random.permutation(len(data))\nx,y = data[idx], classes[idx]\n",
    "In [19]: a\nOut[19]: \narray([[9, 4, 0, 0, 7, 2, 0, 4, 0, 1, 2],\n       [0, 2, 0, 0, 0, 7, 6, 0, 6, 2, 0],\n       [6, 8, 0, 4, 0, 6, 2, 0, 8, 0, 3],\n       [5, 4, 0, 0, 0, 0, 0, 0, 0, 3, 8]])\n\nIn [20]: (~a.any(axis=0)).any()\nOut[20]: True\n\nIn [26]: numpy.where(~a.any(axis=0))[0]\nOut[26]: array([2])\n",
    ">>> mask = (a!=999)\n>>> dim1 = np.any(mask, axis=1).sum()\n>>> a[mask].reshape(dim1, -1)\narray([[ 1,  2,  3,  4],\n       [ 5,  6,  7,  8],\n       [ 9, 10, 11, 12]])\n",
    "import pandas as pd\nimport numpy as np\ndf = pd.read_excel('flielocation.xlsx',  sheetname=None, parse_cols=8)\n"
   ]
  },
  {
   "questions": [
    "Strange behaviour pycuda kernel: 'm quite cuda pycuda. kernel creates matrix ( dimension n d) array ( d), simply \"repeating\" n times: , suppose we n = 4 d = , array [ ] kernel : ( matrix 4x3). Basically, 's numpy.tile(array, (n, )) 've written below: Now, d equals power >= 16 right ( numpy.tile(vec_cpu, (n, )) ); d equals anything else (let's say 88) element matrix correct , except : entries right others , apparently random, wrong element, , entries wrong . Example: really 't figure causing , maybe 's 'm missing... appreciated, thanks advance!",
    "Process matrix : , 4* matrix: reshape * matrix mean original matrix, : effective ?",
    "Selecting matrix matrix: select element matrix according matrix. matrix thus contains indexes pick.",
    "Concatenating matrix (numpy): matrix b put its ( ,4) empty matrix . Based : [[8, ][ ,4]] np.concatenate: got : ValueError: input must dimensions Can anyone please explain fix ? rather np.concatenate ? Thank",
    "Calculate matrix mean: 've got matrix: weights w1,w2,w3, calculate mean matrix ( ) ? : advance. EDIT: input ( , 37375, ), instead ( , ), ( , ). mean , :",
    "create matrix array under diagonal numpy: create matrix using whose matrix under diagonal. matrix thought np.tril expect. missing ? apologize advance trivial figure looping.",
    "Image matrix : Im matrix. says : \"ValueError: truth array element ambiguous. Use . () . ()\" Thank advance.",
    "Fast inverse transpose matrix : matrix (n, n, , ) n 5000. Now inverse transpose matrix : faster, efficient ?",
    "Multiply together matrices Numpy: 'm looking efficient multiply matrices Numpy. matrix : matrix multiply along long axis, 4x4 matrix. clearly : super slow. faster (perhaps using einsum function fully understand yet)?",
    "Sparse matrix manipulation: original matrix : separate X matrix rest matrix. : makes matrix : look original?"
   ],
   "code": [
    "if (y > n ||  x > d) return;\nout[y * d + x] = in[x];\n\nif (y >= n ||  x >= d) return;\nout[y * d + x] = in[x];\n\nif ((y < n) && (x < d))\n    out[y * d + x] = in[x];\n",
    "a = np.array([[1, 2], [3, 4], [5, 6],[7,8]])\nstep = 2\n\na.reshape(-1, step, a.shape[-1]).mean(1)\n#array([[ 2.,  3.],\n#       [ 6.,  7.]])\n\nstep = 2\nnp.add.reduceat(a, np.arange(0,len(a),step))/step\n#array([[ 2.,  3.],\n#       [ 6.,  7.]])\n",
    "myArray = numpy.array([[2, 3, 4],\n                       [6, 7, 8],\n                       [9, 1, 5]])\n\nindices = numpy.array([2, 0, 1])\n\nrowSelector = numpy.arange(myArray.shape[0])\nmyArray[rowSelector, indices]\n\narray([4, 6, 1]) \n",
    "cols = [1, 3]\na = b[:, cols]\n",
    "in=in.reshape((-1,3,2))\n\nw = np.random.rand(3)\n\nout1 = np.average(in, weights = w, axis = 1)\n\nout1 = np.sum(t*w[None,:, None], axis = 1) / np.sum(w)\n",
    "x = np.ones((5, 5), dtype=float)\nx[np.triu_indices(5, 1)] = x1        # sets the upper triangle\nx[np.triu_indices(5, 1)[::-1]] = x1  # sets the lower triangle \n",
    "m, n = arr.shape\nfor x in range(m):\n    for y in range(n):\n        if arr[x,y] > 1:\n            normal.append(1)\n        else:\n            normal.append(0)\n",
    "def adjoint(A):\n    \"\"\"compute inverse without division by det; ...xv3xc3 input, or array of matrices assumed\"\"\"\n    AI = np.empty_like(A)\n    for i in xrange(3):\n        AI[...,i,:] = np.cross(A[...,i-2,:], A[...,i-1,:])\n    return AI\n\ndef inverse_transpose(A):\n    \"\"\"\n    efficiently compute the inverse-transpose for stack of 3x3 matrices\n    \"\"\"\n    I = adjoint(A)\n    det = dot(I, A).mean(axis=-1)\n    return I / det[...,None,None]\n\ndef inverse(A):\n    \"\"\"inverse of a stack of 3x3 matrices\"\"\"\n    return np.swapaxes( inverse_transpose(A), -1,-2)\ndef dot(A, B):\n    \"\"\"dot arrays of vecs; contract over last indices\"\"\"\n    return np.einsum('...i,...i->...', A, B)\n\n\nA = np.random.rand(2,2,3,3)\nI = inverse(A)\nprint np.einsum('...ij,...jk',A,I)\n",
    "while len(a) > 1:\n    a = np.matmul(a[::2, ...], a[1::2, ...])\n\nres = A * B * C * D * ...         # 1024 remaining multiplications\n\nres = (A * B) * (C * D) * ...     # 512 remaining multiplications\n\nres = ((A * B) * (C * D)) * ...   # 256 remaining multiplications\n",
    "In [1]: from scipy import sparse\n\nIn [2]: original_matrix = sparse.csc_matrix(([1,1,1,1,1,1,1,1], \n([32, 108, 32, 108, 108, 432, 432, 432], [69901, 69901, 69902, \n69903, 69904, 69905, 69906, 69907])), shape=[500,103515])\n\nIn [3]: print original_matrix\n  (32, 69901)   1\n  (108, 69901)  1\n  (32, 69902)   1\n  (108, 69903)  1\n  (108, 69904)  1\n  (432, 69905)  1\n  (432, 69906)  1\n  (432, 69907)  1\n\nIn [4]: new_matrix = original_matrix.tocsr()\nOut[4]:\n<500x103515 sparse matrix of type '<type 'numpy.int64'>'\n    with 8 stored elements in Compressed Sparse Row format>\n\nIn [5]: print new_matrix\n  (32, 69901)   1\n  (32, 69902)   1\n  (108, 69901)  1\n  (108, 69903)  1\n  (108, 69904)  1\n  (432, 69905)  1\n  (432, 69906)  1\n  (432, 69907)  1\n\nIn [6]: cutoff = 100\n\nIn [7]: mat1 = original_matrix[:cutoff]\n\nIn [8]: mat2 = original_matrix[cutoff:]\n\nIn [9]: print mat1\n  (32, 69901)   1\n  (32, 69902)   1\n\nIn [10]: print mat2\n  (108, 69901)  1\n  (108, 69903)  1\n  (108, 69904)  1\n  (432, 69905)  1\n  (432, 69906)  1\n  (432, 69907)  1\n"
   ]
  },
  {
   "questions": [
    ".6: Histogram based space its name: histogram , normally , histogram space its name. Column name: 'Type ' Attempt: knew wouldn't . : creating variable string 'Type ' variable place 'Type ' invalid. Anyone ideas correct approach making histogram based off space its name?",
    "NumPy: 1D interpolation 3D array: 'm rather NumPy. Anyone idea making , especially nested loops, compact/efficient? BTW, dist three dimensional numpy . !",
    "append dimensional variable: variable. variable dimensional array. thinking variable matrix n m. append . variable n m+ . : : whole :",
    "Using numpy mgrid variable : numpy.mgrid variable ? 't examples github anyone using anything hardcoded .",
    "NetCDF4 Assign variable issue: netCDF create variables using netCDF4. However program failed assign array. Below solve ? appreciated. TIA",
    "Bring variables increasing name numpy array : big variables increasing their name: easy (maybe ) create numpy array contains variables ?",
    "print tensor variable: tensor variable matrix 4 * 5 wondering quick print variable console. Can print print variable?",
    "Dividing Histograms Pandas: reading csv , making histograms follows: bin bin ratio histograms. easy ?",
    "Sigma Notation : create sigma sum . 100 100 matrix (created numpy) 100 . matrix variable , variable Network. sum look . j matrix refer specific , j Network refers . , wanted h67, sum : follows, think right. ?",
    "loading dataset (numpy) variable spaces delimiting : big dataset contains numeric its variable spaces delimiting , : When : : change ignore multiple spaces well?"
   ],
   "code": [
    "fig = a.plot(kind = 'hist',bins = 50,figsize = (15,15))\nfig.figure #shows the figure\n",
    "def interpolate_to_distance(self, distance):\n    dshape = self.dist.shape\n    dist = self.dist.T.reshape(-1, dshape[-1])\n    data = self.data.T.reshape(-1, dshape[-1])\n    intdata = np.array([np.interp(distance, di, da)\n                        for di, da in zip(dist, data)])\n    return intdata.reshape(dshape[0:2]).T\n\nimport numpy as np\n\nclass TestClass(object):\n    def interpolate_to_distance(self, distance):\n        dshape = self.dist.shape\n        dist = self.dist.T.reshape(-1, dshape[-1])\n        data = self.data.T.reshape(-1, dshape[-1])\n        intdata = np.array([np.interp(distance, di, da)\n                            for di, da in zip(dist, data)])\n        return intdata.reshape(dshape[0:2]).T\n\n    def interpolate_to_distance_old(self, distance):\n        interpolated_data=np.ndarray(self.dist.shape[1:])\n        for j in range(interpolated_data.shape[1]):\n            for i in range(interpolated_data.shape[0]):\n                interpolated_data[i,j]=np.interp(\n                           distance,self.dist[:,i,j],self.data[:,i,j])\n        return(interpolated_data)\n\nif __name__ == '__main__':\n    testobj = TestClass()\n\n    testobj.dist = np.random.randn(3, 3, 3)\n    testobj.data = np.random.randn(3, 3, 3)\n\n    distance = 0\n    print 'Old:\\n', testobj.interpolate_to_distance_old(distance)\n    print 'New:\\n', testobj.interpolate_to_distance(distance)\n\nOld:\n[[-0.59557042 -0.42706077  0.94629049]\n [ 0.55509032 -0.67808257 -0.74214045]\n [ 1.03779189 -1.17605275  0.00317679]]\nNew:\n[[-0.59557042 -0.42706077  0.94629049]\n [ 0.55509032 -0.67808257 -0.74214045]\n [ 1.03779189 -1.17605275  0.00317679]]\n\nnp.all(np.diff(xp) > 0)\n",
    "In [121]: from scipy import sparse\nIn [122]: M = sparse.csr_matrix([[0,1,0],[1,0,1]])\n\nIn [123]: M.A   # show as array\nOut[123]: \narray([[0, 1, 0],\n       [1, 0, 1]], dtype=int32)\n\nIn [124]: M.todense()  # show a numpy matrix\nOut[124]: \nmatrix([[0, 1, 0],\n        [1, 0, 1]], dtype=int32)\n\nIn [125]: col=np.array([[2],[3]])  # a simple column array\nIn [126]: col\nOut[126]: \narray([[2],\n       [3]])\n\nIn [128]: sparse.hstack([M,col])\nOut[128]: \n<2x4 sparse matrix of type '<class 'numpy.int32'>'\n    with 5 stored elements in COOrdinate format>\n\nIn [129]: sparse.hstack([M,col]).A\nOut[129]: \narray([[0, 1, 0, 2],\n       [1, 0, 1, 3]], dtype=int32)\n\nIn [130]: sparse.vstack([M,[1,2,3]]).A   # or add a row\nOut[130]: \narray([[0, 1, 0],\n       [1, 0, 1],\n       [1, 2, 3]], dtype=int32)\n",
    "np.mgrid[[slice(i,j) for i,j in [(1,10)]*10]]\n\nnp.mgrid[slice(1,10),slice(1,10)]  # same as\nnp.mgrid[1:10,1:10]\n",
    "file.variables[\"tmp\"][0,0,0,0] = 0.1234\n//read complete var\nputDataInHere = file.variables[\"tmp\"][:]\n\n<type \"netCDF4._netCDF4.Variable\">\nfloat32 temp(time, level, lat, lon)\n    least_significant_digit: 3\n    units: K\nunlimited dimensions: time, level\ncurrent shape = (0, 0, 73, 144)\n",
    "var0 = 1\nvar1 = 2\nvar3 = 15\n\nt = open('test.txt',r)\ndata = t.readlines()\nt.close()\nfor line in data:\n    name,value = line.split('=')\n    name.strip()\n    value = int(value.strip())\n",
    "In [187]: arr = np.arange(4*5).reshape(4,5)\n\nIn [188]: print(arr)\n[[ 0  1  2  3  4]\n [ 5  6  7  8  9]\n [10 11 12 13 14]\n [15 16 17 18 19]]\n",
    "import pandas as pd\nimport numpy as np\ndf = pd.DataFrame({'Fare': np.random.uniform(0, 600, 400), \n                   'Survived': np.random.randint(0, 2, 400)})\n\ndf['fare_bin'] = pd.cut(df['Fare'], bins=[0,10,20,30,45,60,75,100,600])\n\ndf.groupby('fare_bin').apply(lambda g: (g.shape[0], g.loc[g['Survived'] == 1, :].shape[0]))\n\nOut[34]: \nfare_bin\n(0, 10]           (7, 4)\n(10, 20]          (9, 6)\n(100, 600]    (326, 156)\n(20, 30]          (5, 4)\n(30, 45]         (12, 6)\n(45, 60]        (15, 11)\n(60, 75]         (13, 7)\n(75, 100]        (13, 6)\ndtype: object\n\ndef get_ratio(g):\n    try:\n        return float(g.shape[0]) / g.loc[g['Survived'] == 1, :].shape[0]\n    except ZeroDivisionError:\n        return np.nan\ndf.groupby('fare_bin').apply(get_ratio)\n\nOut[30]: \nfare_bin\n(0, 10]       1.750000\n(10, 20]      1.500000\n(100, 600]    2.089744\n(20, 30]      1.250000\n(30, 45]      2.000000\n(45, 60]      1.363636\n(60, 75]      1.857143\n(75, 100]     2.166667\ndtype: float64\n",
    "def new_sum(i,j): \n    hi=0\n    for n in range(j+1):\n       hi+= A[i][n]*Network[n]\n    return hi\n",
    ">>> from io import StringIO\n>>> dataset = StringIO('''\\\n... 4 5 6\n... 7 8     9\n... 2 3 4''')\n>>> import numpy\n>>> dataset_as_numpy = numpy.loadtxt(dataset)\n>>> dataset_as_numpy\narray([[ 4.,  5.,  6.],\n       [ 7.,  8.,  9.],\n       [ 2.,  3.,  4.]])\n"
   ]
  },
  {
   "questions": [
    "OrderedDicts equal tolerance: 100 OrderedDicts , likely equal. 100 dicts foo, unique items, item unique its equal dict, tolerance .01. Importantly we assume order keys OrderedDicts . np.isclose(foo. (), baz. (), atol .01), 'd 10000 times compare ; actually less b/c - -fly ignore those found redundant. efficient approach ? Another approach : uniques = {tuple( . ()) list_of_ord_dicts}, incorporate tolerance here?"
   ],
   "code": [
    "from collections import OrderedDict\nfrom random import random\nfrom copy import copy\nimport pandas as pd\nfrom sklearn import cluster\n\nhundred_dicts = [OrderedDict(a=random(), b=random(), c=random()) for _ in range(90)]\nhundred_dicts.extend(copy(hundred_dicts[:10]))\n\ndf = pd.DataFrame(hundred_dicts)\nkmeans = cluster.KMeans(\n        n_clusters=len(hundred_dicts),\n        random_state=0,\n        tol=0.01).fit(df)\nlabels = kmeans.labels_\ndf['cluster'] = kmeans.labels_\ndf = df.drop_duplicates(subset='cluster')\n"
   ]
  },
  {
   "questions": [
    "TypeError: len() unsized object slicing dataframe - float formats?: slice dataframe based previously defined conditions defined separate array. When looping array relevant slices dataframe, . iteration fine, breaks during iteration, throwing TypeError: len() unsized object. dataframe: : printed outputs: after , throws . However, slice dataframe using printed outside , fine. prints missing? complete traceback below, helps: OUTCOME turns dataframe troubles slicing numpy floats. converting z0 zi float solves !",
    "\u201cTypeError: len() unsized object\u201d using insert : objective: insert array index position ( ) Language used: numpy library : gave : TypeError: len() unsized object. ideas?",
    "fix \u201cTypeError: len() unsized object\u201d: : TypeError: len() unsized object after running script: fix ?",
    "len() unsized object using scipy's pearson correlation: datasets lists numbers calculate correlation p- using scipy stats . numbers lists equal. : , returns: TypeError: len() unsized object wrong here? txt files numbers, \"[12,13,5,7]\"",
    "Unsized object numpy.random.permutation?: right now stuck : To give : \"TypeError: len() unsized object.\" 't figure issue since 128 integer. probably been resolved before here: http://mail.scipy.org/pipermail/numpy discussion/2007 January/025592.html their isn't helpful since floats. Can anyone 's going wrong here?",
    "Looping dataframe TypeError: len() unsized object: Below writing keeps returning . Cant quiet figure fix . think statement fix. TypeError: len() unsized object main objective compare dataframes within their respective 'Type'. Each dataframe similar wish automate process. Comparing returning true false statement tell they match. Returns: type 'numpy.int64', type 'numpy.int64' Both type. /usr/local/lib/python2.7/site packages/ /core/ops.pyc wrapper(self, , axis) 739 NotImplemented --> 741 len(self) != len( ): TypeError: len() unsized object",
    "ValueError: string float: Numpy array [closed]: snippet data2 dataframe. Why isn't string object converted float? Same converting string int64.",
    "ValueError: objects aligned: Why give \"ValueError: objects aligned\"? write vector v= np.array([[t],[t1]]) didn't either. wrong? !",
    "sort based numpy's argsort function: : Now numpy's argsort function sorted : : When sort using fine: apply , throws TypeError: integer element converted index now sort using - converting array ?",
    "TypeError: length converted scalars NUMPY: Running TypeError: TypeError: length converted scalars On 21 v=(Q/((4*math.pi*e0)(math.sqrt(( * +r0** )))))"
   ],
   "code": [
    "z0 = float(z0)\nzi = float(zi)\n",
    ">>> help(insert)\n\nParameters\n----------\narr : array_like\n    Input array.\nobj : int, slice or sequence of ints\n    Object that defines the index or indices before which `values` is\n    inserted.\nvalues : array_like\n    Values to insert into `arr`. If the type of `values` is different\n    from that of `arr`, `values` is converted to the type of `arr`.\naxis : int, optional\n    Axis along which to insert `values`.  If `axis` is None then `arr`\n    is flattened first.\n",
    "nv = v.size\nnu = u.size\n\n>>> v = np.fromstring(input('enter the elements of the vector separated by comma: '), dtype=int, sep=',')\nenter the elements of the vector separated by comma: 1, 2, 3\n>>> v\narray([1, 2, 3])\n>>> len(v)\n3\n>>> v.size\n3\n",
    "from scipy.stats.stats import pearsonr\n\na=open(\"a.txt\")\nb=open(\"b.txt\")\n\na_array = create_array(a)\nb_array = create_array(b)\nprint pearsonr(a_array,b_array)\n\ndef create_array(file):\n    ret = []\n    for line in file:\n        line.replace('[','')\n        line.replace(']','')\n        ret = line.split(',') \n        map(lambda x: int(x), ret)\n\n    return ret\n",
    "sage: import numpy\nsage: perm = numpy.random.permutation(12)\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\n<ipython-input-3-38b6a5e3e889> in <module>()\n----> 1 perm = numpy.random.permutation(Integer(12))\n\n/opt/sage/local/lib/python2.7/site-packages/numpy/random/mtrand.so in mtrand.RandomState.permutation (numpy/random/mtrand/mtrand.c:21297)()\n\n/opt/sage/local/lib/python2.7/site-packages/numpy/random/mtrand.so in mtrand.RandomState.shuffle (numpy/random/mtrand/mtrand.c:20965)()\n\nTypeError: len() of unsized object\n\n----> 1 perm = numpy.random.permutation(Integer(12))\n\nperm = numpy.random.permutation(12)\n\nperm = numpy.random.permutation(Integer(12))\n\nsage: perm = numpy.random.permutation(12r)\n\nsage: perm = numpy.random.permutation(12r)\nsage: perm    # random\narray([ 9,  0, 11,  4,  2, 10,  3,  5,  7,  6,  1,  8])\n\nsage: perm = numpy.random.permutation(int(12))\nsage: perm    # random\narray([ 5,  9,  1,  7,  0,  2, 10,  6,  3,  8,  4, 11])\n\nsage: preparser(False)\nsage: perm = numpy.random.permutation(12)\nsage: perm    # random\narray([ 0,  2,  7,  5,  8, 11,  1,  6,  9, 10,  3,  4])\n",
    "# generate some example data.\nimport numpy as np\nimport pandas as pd\n\nN = 10\nvalues = ['a','b','c']\ndf1 = pd.DataFrame({\"Type\": np.random.choice(values, size=N)})\ndf2 = pd.DataFrame({\"Type\": np.random.choice(values, size=N)})\n\ndf1.Type.eq(df2.Type)\n\n0    False\n1    False\n2    False\n3    False\n4    False\n5    False\n6    False\n7    False\n8    False\n9     True\nName: Type, dtype: bool\n",
    "In [86]: pd.to_numeric(df['data'], errors='coerce')\nOut[86]: \n0    1.0\n1    2.0\n2   -3.0\n3    5.5\nName: data, dtype: float64\n\nIn [91]: pd.to_numeric(df['data'], errors='coerce').tolist()\nOut[91]: [1.0, 2.0, -3.0, 5.5]\n",
    "a = np.dot(scipy.linalg.expm(M1, q=0),v)\n\na = np.dot(scipy.linalg.expm(M1, q=0),v)\n\nv.shape\nOut[16]: (2, 201, 201)\n\nM.shape\nOut[18]: (2, 2)\n",
    "In [8]: np.array(myList2)[so]\nOut[8]: array([1, 4, 2, 3, 5])\n\nIn [7]: [myList2[i] for i in so]\nOut[7]: [1, 4, 2, 3, 5]\n",
    ">>> import numpy as np\n>>> import math\n>>> a = np.arange(5)\n>>> np.sqrt(a)\narray([ 0.        ,  1.        ,  1.41421356,  1.73205081,  2.        ])\n#error\n>>> math.sqrt(a)\nTraceback (most recent call last):\n  File \"<ipython-input-78-c7d50051514f>\", line 1, in <module>\n    math.sqrt(a)\nTypeError: only length-1 arrays can be converted to Python scalars\n\n>>> \n"
   ]
  },
  {
   "questions": [
    "shift thinking 'vectorize computation' using ' -loops'?: definitely notional , wanted others expertise input topic SO. Most programming coming Numpy lately. 've been matching items sizes. Most go - even worst, nested - . 'm ultimately avoid using -loops gain experience Data Science -loops perform slower. well aware Numpy pre defined cmds research, those whom experienced, general school thought iterate ? Something similar : 'm well aware skin cat , interested others approach thinking.",
    "Multiple vectorized string function?: querying DataFrame contain certain string ? Something Series.str except DataFrame? 's far: Ideally, replace last lines similar : ?",
    "np.vectorize nan - play nice?: Let's say np.sin expected However vectorize own function 'll fail initize returned noneg integer zero we nan float. 've found far : However ugly, better ignore nan vectorize?",
    "vectorize containing -statement numpy?: fairly numpy. , desired : get_result function contains - , however, therefore awkwardly slow larger input vectors S. Can function vectorized numpy syntax? appreciated.",
    "vectorize ?: Numpy vectorization operations section faster succeed . somebody idea... . 's working loops: Where,"
   ],
   "code": [
    "In [273]: small_array = np.array([\"a\", \"b\"])\n     ...: big_array = np.array([\"a\", \"b\", \"c\", \"d\"])\n     ...: \n     ...: for i in range(len(small_array)):\n     ...:     for p in range(len(big_array)):\n     ...:         if small_array[i] == big_array[p]:\n     ...:             print( \"This item is matched: \", small_array[i])\n     ...:             \nThis item is matched:  a\nThis item is matched:  b\n\nIn [274]: small_array\nOut[274]: \narray(['a', 'b'],\n      dtype='<U1')\nIn [275]: big_array\nOut[275]: \narray(['a', 'b', 'c', 'd'],\n      dtype='<U1')\n\nIn [276]: small_array[:,None]\nOut[276]: \narray([['a'],\n       ['b']],\n      dtype='<U1')\n\nIn [277]: small_array[:,None]==big_array\nOut[277]: \narray([[ True, False, False, False],\n       [False,  True, False, False]], dtype=bool)\n\nIn [278]: _.all(axis=0)\nOut[278]: array([False, False, False, False], dtype=bool)\n\nIn [280]: __.all(axis=1)\nOut[280]: array([False, False], dtype=bool)\n\nIn [284]: (small_array[:,None]==big_array).any(0)\nOut[284]: array([ True,  True, False, False], dtype=bool)\nIn [285]: (small_array[:,None]==big_array).any(1)\nOut[285]: array([ True,  True], dtype=bool)\n\nIn [286]: np.in1d(big_array, small_array)\nOut[286]: array([ True,  True, False, False], dtype=bool)\n\nIn [288]: for x in small_array:\n     ...:     print(x==big_array)\n     ...:     \n[ True False False False]\n[False  True False False]\n",
    "a = pd.np.char.array(df.values)\nmask = a.find('dolor')!=-1\ndf2 = df.iloc[np.any(mask, axis=1)]\n\n       one    two    three    four\n0    Lorem  ipsum    dolor     sit\n4   dolore  magna  aliqua.      Ut\n9     Duis   aute    irure   dolor\n11   velit   esse   cillum  dolore\n",
    "def noneg(n):\n    if n < 0:\n         return n.__class__(0)\n    return n\nnoneg(nv)\n",
    "res=np.zeros(S.shape[0],dtype=np.float64)\nmask - S-K>delS\nres[mask] = ...S[mask]\nres[~mask] = ...S[~mask]\n\nfor j in range(res.shape[0]):\n    if S[j]-K>delS:\n        res[j]+=np.floor((S[j]-K)/delS)\n        K+=np.floor((S[j]-K)/delS)*delS\n    elif S[j]-K<-delS:\n        res[j]+=np.ceil((S[j]-K)/delS)\n        K+=np.ceil((S[j]-K)/delS)*delS\n\ndef get_result(S,K,delS):\n    S = S/delS\n    res=np.zeros(S.shape[0],dtype=np.float64)\n    for j in range(res.shape[0]):\n        x = S[j] - K/delS\n        xa = np.floor(np.abs(x)) * np.sign(x)\n        res[j] += xa\n        K += xa*delS         \n    return res\n",
    "# Calculate \"((a + b * np.dot(tab[i], vectors[n])) ** d)\" part\np1 = (a + b*np.einsum('ij,kj->ki',tab,vectors))**d\n\n# Include \"+= coef[0][n] *\" part to get the final output\ny_vectorized = np.dot(coef,p1)\n\nIn [168]: N = 50\n     ...: M = 50\n     ...: P = 50\n     ...: \n     ...: tab = np.random.rand(N,M)\n     ...: vectors = np.random.rand(P,M)\n     ...: coef = np.random.rand(1,P)\n     ...: \n     ...: a = 3.233\n     ...: b = 0.4343\n     ...: c = 2.0483\n     ...: d = 3\n     ...: \n\nIn [169]: %timeit original_approach(tab,vectors,coef,a,b,c,d)\n100 loops, best of 3: 4.18 ms per loop\n\nIn [170]: %timeit proposed_approach(tab,vectors,coef,a,b,c,d)\n10000 loops, best of 3: 136 \u00b5s per loop\n\nIn [196]: %timeit original_approach(tab,vectors,coef,a,b,c,d)\n10 loops, best of 3: 37.9 ms per loop\n\nIn [197]: %timeit proposed_approach(tab,vectors,coef,a,b,c,d)\n1000 loops, best of 3: 1.91 ms per loop\n"
   ]
  },
  {
   "questions": [
    "Get coordinates squares numpy matrix: Given numpy matrix represented . few assumptions input matrix: questions. most efficient array coordinates green dots? array corners squares around green dot? looking after :",
    "'Concatenating' numpy matrix: numpy matrix 'concatenate' matrix matrix ?",
    "shapes numpy matrix: 'm input vectors numpy matrix : However keep : 've using flatten reshape, nothing",
    "Add s numpy matrix: add numpy array specific numpy matrix. Given: add b . expected : using \"+\" operator, got : best ?",
    "Concatenate numpy matrix : numpy matrix concatenate together end long array. now doe seem pythonic. 'm sure better . Thank .",
    "Convert dataframe numpy matrix: dataframe form numpy matrix Can anyone ?",
    "Swap zeros numpy matrix: numpy matrix : Now shift numbers right swap zeros left : short pythonic , perhaps api numpy, scikit learn?",
    "Transform numpy matrix: transform numpy matrix (say 'Mat') manner: Given below using ( loops). wondering faster implement . much appreciated.",
    "append numpy matrix empty numpy array: append numpy matrix) ge : \"All\" variable add \"h\" \"All\" ?",
    "append numpy matrix empty numpy array: append numpy matrix) ge : \"All\" variable add \"h\" \"All\" ?"
   ],
   "code": [
    "def find_boxes(np_matrix):\n    np_mat = np_matrix[::-1, :]  # reversed in expected output\n    def find_extent(arr, val):\n        xn = arr.size\n        x0 = np.flatnonzero(arr == 1)\n        xi = np.searchsorted(x0, val, side = 'right')\n        if xi == x0.size:\n            x1 = x0[xi-1]\n            x2 = xn - 1\n        elif xi == 0:\n            x1 = 0\n            x2 = x0[xi]\n        else:\n            x1 = x0[xi-1]\n            x2 = x0[xi]\n        return np.array([x1, x2])\n\n    green = np.where(np_mat == 2)\n    green = tuple(g[np.argsort(green[-1])] for g in green)\n    coords = np.empty((green[0].size, 2, 4))\n\n    for i, (x, y) in enumerate(zip(*green)):\n        coords[i, 0] =   np.tile(find_extent(np_mat[x, :], y),       2)\n        coords[i, 1] = np.repeat(find_extent(np_mat[:, y], x)[::-1], 2)  # reversed again\n    return np.stack(green)[::-1].T, coords.swapaxes(1,2).astype(int)\n    # reversed again and transposed\n\nfind_boxes(np_matrix)\nOut: \n(array([[ 0,  0],\n        [ 7, 12],\n        [16, 27],\n        [29, 21],\n        [34,  7]], dtype=int32), \n array([[[ 0,  6],\n         [ 2,  6],\n         [ 0,  0],\n         [ 2,  0]],\n\n        [[ 3, 14],\n         [ 9, 14],\n         [ 3,  7],\n         [ 9,  7]],\n\n        [[12, 31],\n         [23, 31],\n         [12, 24],\n         [23, 24]],\n\n        [[25, 22],\n         [32, 22],\n         [25, 15],\n         [32, 15]],\n\n        [[33, 13],\n         [35, 13],\n         [33,  0],\n         [35,  0]]]))\n",
    "In [25]: import numpy as np\n\nIn [26]: a = np.array([[1,2],[3,45]])\n\nIn [27]: a\nOut[27]: \narray([[ 1,  2],\n       [ 3, 45]])\n\nIn [28]: [''.join(str(x) for x in row) for row in a.T]\nOut[28]: ['13', '245']\n\nIn [29]: np.array([''.join(str(x) for x in row) for row in a.T], int)\nOut[29]: array([ 13, 245])\n",
    "In [161]: x = np.zeros((10,10))\n\nIn [162]: x[:,1] = np.ones((1,10))  # or x[:,1] = np.ones(10)\n\nIn [163]: x[:,1] = np.ones((10,1))\n...\nValueError: could not broadcast input array from shape (10,1) into shape (10)\nIn [166]: x[:,1].shape\nOut[166]: (10,)\nIn [167]: x[:,[1]].shape\nOut[167]: (10, 1)\n\nIn [168]: x[:,[1]] = np.ones((10,1))\n",
    ">>> a = numpy.zeros(shape=(2,2))\n>>> b = numpy.ones(shape=(1,2))\n>>> a[:len(b)] += b\n>>> a\narray([[ 1.,  1.],\n       [ 0.,  0.]])\n\n>>> a = numpy.zeros(shape=(2,2))\n>>> a[0] += b[0]\n>>> a\narray([[ 1.,  1.],\n       [ 0.,  0.]])\n",
    ">>> a = numpy.arange(9).reshape(3, 3)\n>>> a.ravel()\narray([0, 1, 2, 3, 4, 5, 6, 7, 8])\n\n>>> a.ravel()[5] = 99\n>>> a\narray([[ 0,  1,  2],\n       [ 3,  4, 99],\n       [ 6,  7,  8]])\n>>> a.flatten()[5] = 77\n>>> a\narray([[ 0,  1,  2],\n       [ 3,  4, 99],\n       [ 6,  7,  8]])\n\n>>> %timeit a.ravel()\n1000000 loops, best of 3: 468 ns per loop\n>>> %timeit a.flatten()\n1000000 loops, best of 3: 1.42 us per loop\n>>> %timeit numpy.concatenate(a)\n100000 loops, best of 3: 2.26 us per loop\n\n>>> a = numpy.arange(9).reshape(3, 3)\n>>> a.reshape(1, -1)\narray([[0, 1, 2, 3, 4, 5, 6, 7, 8]])\n>>> %timeit a.reshape(1, -1)\n1000000 loops, best of 3: 736 ns per loop\n",
    "arr = df.pivot('user_id', 'item_id', 'rating').fillna(0).astype(int).values\nprint (arr)\n[[5 3 0]\n [3 0 5]]\n\narr = df.set_index(['user_id','item_id']).unstack(fill_value=0).values\nprint (arr)\n[[5 3 0]\n [3 0 5]]\n",
    "valid_mask = a!=0\nflipped_mask = valid_mask.sum(1,keepdims=1) > np.arange(a.shape[1]-1,-1,-1)\na[flipped_mask] = a[valid_mask]\na[~flipped_mask] = 0\n\nIn [90]: a\nOut[90]: \narray([[ 2,  1, 23, 32],\n       [34,  0,  3,  0],  # <== Added a zero in between for variety\n       [ 3, 33,  0,  0],\n       [32,  0,  0,  0]])\n\n# After code run -\n\nIn [92]: a\nOut[92]: \narray([[ 2,  1, 23, 32],\n       [ 0,  0, 34,  3],\n       [ 0,  0,  3, 33],\n       [ 0,  0,  0, 32]])\n\nIn [94]: a\nOut[94]: \narray([[1, 1, 2, 3, 1, 0, 3, 0, 2, 1],\n       [2, 1, 0, 1, 2, 0, 1, 3, 1, 1],\n       [1, 2, 0, 3, 0, 3, 2, 0, 2, 2]])\n\n# After code run -\n\nIn [96]: a\nOut[96]: \narray([[0, 0, 1, 1, 2, 3, 1, 3, 2, 1],\n       [0, 0, 2, 1, 1, 2, 1, 3, 1, 1],\n       [0, 0, 0, 1, 2, 3, 3, 2, 2, 2]])\n\n# Proposed in this post\ndef masking_based(a):\n    valid_mask = a!=0\n    flipped_mask = valid_mask.sum(1,keepdims=1) > np.arange(a.shape[1]-1,-1,-1)\n    a[flipped_mask] = a[valid_mask]\n    a[~flipped_mask] = 0\n    return a\n\n# @Psidom's soln            \ndef sort_based(a):\n    return a[np.arange(a.shape[0])[:, None], (a != 0).argsort(1, kind=\"mergesort\")]\n\nIn [205]: a = np.random.randint(0,4,(1000,1000))\n\nIn [206]: %timeit sort_based(a)\n10 loops, best of 3: 30.8 ms per loop\n\nIn [207]: %timeit masking_based(a)\n100 loops, best of 3: 6.46 ms per loop\n\nIn [208]: a = np.random.randint(0,4,(5000,5000))\n\nIn [209]: %timeit sort_based(a)\n1 loops, best of 3: 961 ms per loop\n\nIn [210]: %timeit masking_based(a)\n1 loops, best of 3: 151 ms per loop\n",
    "Mat = Mat - np.outer(np.sum(Mat, axis=1), np.sum(Mat, axis=0))\n",
    "All=np.array([]).reshape((0,3))\n\nfor i in data:\n    h=i*Weights      \n    All=np.concatenate((All,h))\n\nAll\n#array([[  8.,   8.,   8.],\n#       [  8.,   8.,   8.],\n#       [  8.,   8.,   8.],\n#       [ 12.,  12.,  12.],\n#       [ 12.,  12.,  12.],\n#       [ 12.,  12.,  12.]])\n\nAll=np.array([])\nfor i in data:\n    h=i*Weights      \n    if len(All) == 0:\n        All = h\n    else:\n        All=np.concatenate((All,h))\n\nAll\n#array([[ 8,  8,  8],\n#       [ 8,  8,  8],\n#       [ 8,  8,  8],\n#       [12, 12, 12],\n#       [12, 12, 12],\n#       [12, 12, 12]])\n\nimport itertools\nnp.array([i*j for i,j in itertools.product(data, Weights)])\n\n#array([[ 8,  8,  8],\n#       [ 8,  8,  8],\n#       [ 8,  8,  8],\n#       [12, 12, 12],\n#       [12, 12, 12],\n#       [12, 12, 12]])\n",
    "All=np.array([]).reshape((0,3))\n\nfor i in data:\n    h=i*Weights      \n    All=np.concatenate((All,h))\n\nAll\n#array([[  8.,   8.,   8.],\n#       [  8.,   8.,   8.],\n#       [  8.,   8.,   8.],\n#       [ 12.,  12.,  12.],\n#       [ 12.,  12.,  12.],\n#       [ 12.,  12.,  12.]])\n\nAll=np.array([])\nfor i in data:\n    h=i*Weights      \n    if len(All) == 0:\n        All = h\n    else:\n        All=np.concatenate((All,h))\n\nAll\n#array([[ 8,  8,  8],\n#       [ 8,  8,  8],\n#       [ 8,  8,  8],\n#       [12, 12, 12],\n#       [12, 12, 12],\n#       [12, 12, 12]])\n\nimport itertools\nnp.array([i*j for i,j in itertools.product(data, Weights)])\n\n#array([[ 8,  8,  8],\n#       [ 8,  8,  8],\n#       [ 8,  8,  8],\n#       [12, 12, 12],\n#       [12, 12, 12],\n#       [12, 12, 12]])\n"
   ]
  },
  {
   "questions": [
    "matplotlib scatter text point: scatter annotate numbers . y vs annotate corresponding numbers n. ideas?",
    "Matplotlib Scatter numpy index marker: numpy array 'm scatter using matplotlib. : Now replace red dots correspondig index numpy array. ? Thank !",
    ": Matplotlib imshow shift xlabel numbers: shift y axis label numbers + ? created, label numbers begin : :",
    "numpy shuffle constraint: shuffle d numpy array, constraint match corresponding (ie., index) array . assumed array unique. , 's best ? ideas?",
    "Unicode string Matplotlib annotate: , ever label unicode string, annotate fails throwing , resolve ?",
    "average corresponing unique : numpy array : uniques , average corresponding . pythonic ?",
    "Changing text clabel Matplotlib: specify text contour label (instead contour put text) 've : . idea?",
    "Numpy operation : many c smaller 12 random numbers rnd. needs numpy lists 's faster. array 12 , describing many small corresponding rnd.",
    "Numpy histogram, take maximum bin: series numbers bin . maximum bin? Have look : wondering .5 ( maximum 4) instead 6.9 4th bin.",
    ": numpy larger smaller : look numbers range? However, give c numbers, desire"
   ],
   "code": [
    "y=[2.56422, 3.77284,3.52623,3.51468,3.02199]\nz=[0.15, 0.3, 0.45, 0.6, 0.75]\nn=[58,651,393,203,123]\n\nfig, ax = plt.subplots()\nax.scatter(z, y)\n\nfor i, txt in enumerate(n):\n    ax.annotate(txt, (z[i],y[i]))\n",
    "from matplotlib import pyplot as plt\n\nimport numpy as np\nN = 100\nmatrix = np.random.rand(N,2)\n\nplt.plot(matrix[:,0],matrix[:,1], 'ro', alpha = 0.5)\nfor i in range(matrix.shape[0]):\n    plt.text(matrix[i,0], matrix[i,1], str(i))\n\nplt.show()\n",
    "plt.imshow(jacaardMatrix, extent=[2,5,2,5])\n",
    "def random_derangement(n):\n    while True:\n        v = np.arange(n)\n        for j in np.arange(n - 1, -1, -1):\n            p = np.random.randint(0, j+1)\n            if v[p] == j:\n                break\n            else:\n                v[j], v[p] = v[p], v[j]\n        else:\n            if v[0] != 0:\n                return v\n",
    "from matplotlib import pyplot as plt\n\nl = '\\xe2'\n\nplt.annotate('%s' % l, (0, 0))\n# raises UnicodeDecodeError: 'ascii' codec can't decode byte 0xe2 in position 0: ordinal not in range(128)\n\nplt.annotate('%s' % l.decode('unicode-escape'), (0, 0))\n# works\n\n# converter function that decodes a string as unicode\nconv = {0:(lambda s: s.decode('unicode-escape'))}\n\nlabels = np.genfromtxt(inputFile, dtype='unicode', converters=conv, usecols=0)\n",
    ">>> A = [[1,1,1,2,3,1,2,3],[0.1,0.2,0.2,0.1,0.3,0.2,0.2,0.1]]\n>>> unq, unq_idx = np.unique(A[0], return_inverse=True)\n>>> unq_sum = np.bincount(unq_idx, weights=A[1])\n>>> unq_counts = np.bincount(unq_idx)\n>>> unq_avg = unq_sum / unq_counts\n>>> unq\narray([1, 2, 3])\n>>> unq_avg\narray([ 0.175,  0.15 ,  0.2  ])\n\n>>> np.vstack((unq, unq_avg))\narray([[ 1.   ,  2.   ,  3.   ],\n       [ 0.175,  0.15 ,  0.2  ]])\n",
    "plt.clabel(CS, fontsize=10, inline=1, fmt=r'$\\alpha=0$')\n",
    "(c[:,None] < rnd).sum(0)\n\nnp.searchsorted(c,rnd)\n",
    "print [max(a[(a>=(i))&(a<i+1)]) if a[(a>=(i))&(a<i+1)].size else 0 for i in bins]\n[0, 1.0, 0, 3.5, 4.0, 5.0, 6.0, 7.7999999999999998, 8.0, 9.0, 10.0]\n",
    "(c > 2) & (c < 5)\n\narray([False,  True,  True, False, False], dtype=bool)\n"
   ]
  },
  {
   "questions": [
    "multiple spectrograms scale?: , noise subtracted scale accurately compare . 's best ? Right now 'm : Where diff aesthetic reasons",
    ": multiple arithmetic operations numpy array: ( subtract sum previous current): Question: write pythonic (prefer )? Thx advance.",
    "NumPy: better multiply matrix array -place?: 'm NumPy , occasionally multiply . Right now, 'm : 's ugly ( slow?). cleaner ?",
    "multiply numpy array scalar: numpy array 'm multiply scalar keeps throwing : :",
    ".. processing: store histograms images database later used compare histogram user. : store histograms & compare histograms?",
    "Structured Array multiple array: uses zip() create structured array. 's low efficiency, builtin functions NumPy.",
    "Compare multiple histograms OpenCV: dataset images, create histogram store (write) , input, compare histogram ones already they identical. far : Can someone guide ? !",
    "'t multiply sequence non int type 'float': evaluate formula, np numpy: : overcome ?",
    "selecting matrix : txt files extract array. They look : . plan - , column3, ..., - 11 array, rest put single array. 'm seem anywhere, lot errors. ideas?",
    "Numpy np. multiple condition: multiple condition using numpy. 'm seem . : There alternative job?"
   ],
   "code": [
    "f1, t1, Sxx1 = spectrogram(np.diff(rawdata), F_S)\nf2, t2, Sxx2 = spectrogram(np.diff(rawdata - noise), F_S)\n\nSxx_min = np.amin(np.minimum(Sxx1, Sxx2))\nSxx_max = np.amax(np.maximum(Sxx1, Sxx2))\n\nplt.subplot(211)\nplt.pcolormesh(t1, f1, Sxx1, vmin=Sxx_min, vmax=Sxx_max)\nplt.ylabel('Frequency [Hz]')\nplt.xlabel('Time [sec]')\nplt.colorbar()\n\nplt.subplot(212)\nplt.pcolormesh(t2, f2, Sxx2, vmin=Sxx_min, vmax=Sxx_max)\nplt.ylabel('Frequency [Hz]')\nplt.xlabel('Time [sec]')\nplt.colorbar()\n",
    "arr = np.zeros((N, M, T))\nfor it in xrange(T):\n    arr[:,:,it] -= np.sum(arr[:,:,:it], axis=2)\n\nfor it in xrange(T): arr[:,:,it] -= np.sum(arr[:,:,:it], axis=2)\n",
    "vector_arr = np.concatenate([vector[np.newaxis, :] for vector in vectors], axis=0)\nrotated_vector_arr = np.dot(vector_arr, rotation_matrix)\n",
    "Flux140[Flux140 == 'null'] = '-1'\n\nFlux140 = Flux140.astype(float)\n\nFlux140[Flux140 == -1] = np.nan\n\ntripled = Flux140 * 3\n",
    "import numpy as np\nfrom scipy.misc import imread\nfrom matplotlib import pyplot as plt\n\npic = r\"C:\\Users\\Public\\Pictures\\Sample Pictures\\Koala.jpg\"\n\n\ndef thresholded(center_, pixels):\n    out = []\n    for a_ in pixels:\n        if a_ >= center_:\n            out.append(1)\n        else:\n            out.append(0)\n    return out\n\n\ndef get_pixel_else_0(l, idx, idy, default=0):\n    try:\n        return l[idx, idy]\n    except IndexError:\n        return default\n\nimg = imread(pic, mode='I')\ntransformed_img = imread(pic, mode='I')\n\nfor x in range(0, len(img)):\n    for y in range(0, len(img[0])):\n        center        = img[x, y]\n        top_left      = get_pixel_else_0(img, x-1, y-1)\n        top_up        = get_pixel_else_0(img, x, y-1)\n        top_right     = get_pixel_else_0(img, x+1, y-1)\n        right         = get_pixel_else_0(img, x+1, y)\n        left          = get_pixel_else_0(img, x-1, y)\n        bottom_left   = get_pixel_else_0(img, x-1, y+1)\n        bottom_right  = get_pixel_else_0(img, x+1, y+1)\n        bottom_down   = get_pixel_else_0(img, x,   y+1)\n\n        values = thresholded(center, [top_left, top_up, top_right, right, bottom_right,\n                                      bottom_down, bottom_left, left])\n\n        weights = [1, 2, 4, 8, 16, 32, 64, 128]\n        res = 0\n        for a in range(0, len(values)):\n            res += weights[a] * values[a]\n\n        transformed_img.itemset((x, y), res)\n\n    # print x\nplt.figure()\nplt.imshow(img)\nplt.title('image')\nplt.figure()\nplt.imshow(transformed_img)\nplt.title('thresholded image')\n\nhist, bins = np.histogram(img.flatten(), 256, [0, 256])\n\ncdf = hist.cumsum()\ncdf_normalized = cdf * hist.max() / cdf.max()\nplt.figure()\nplt.plot(cdf_normalized, color='b')\nhist_trans, bins_trans = np.histogram(transformed_img.flatten(), 256, [0, 256])\nplt.bar(bins_trans[:-1], hist_trans, width=np.diff(bins_trans), color='r')\nplt.xlim([0, 256])\nplt.legend(('cdf', 'histogram'), loc='upper left')\nplt.show()\n\nfile = r'd:\\temp\\1.npy'\nnp.save(file, hist_trans)\n\n# do something here...\n\nhist_trans1 = np.load(file)\nprint(np.linalg.norm((hist - hist_trans1)))\n",
    "import numpy as np\n\na=np.array([1,2,3,4,5,6,7,8,9])\nb=np.array([\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\"])\nc=np.array([9,8,7,6,5,4,3,2,1])\n\nd = np.rec.fromarrays([a,b,c], formats=['i','S32','i'], names=['num','char','len'])\n\nIn [2]: %timeit d = np.rec.fromarrays([a,b,c], formats=['i','S32','i'], names=['num','char','len'])\n10000 loops, best of 3: 86.5 us per loop\n\nIn [6]: import itertools\n\nIn [7]: %timeit np.fromiter(itertools.izip(a,b,c),dtype=datatype)\n100000 loops, best of 3: 11.5 us per loop\n",
    "import os\nimport glob\nimport numpy as np\nfrom skimage import io\n\nroot = 'C:\\Users\\you\\imgs'  # Change this appropriately\nfolders = ['Type_1', 'Type_2', 'Type_3']\nextension = '*.bmp'  # Change if necessary\n\ndef compute_red_histograms(root, folders, extension):\n    X = []\n    y = []\n    for n, imtype in enumerate(folders):\n        filenames = glob.glob(os.path.join(root, imtype, extension))    \n        for fn in filenames:\n            img = io.imread(fn)\n            red = img[:, :, 0]\n            h, _ = np.histogram(red, bins=np.arange(257), normed=True)\n            X.append(h)\n            y.append(n)\n    return np.vstack(X), np.array(y)\n\nX, y = compute_red_histograms(root, folders, extension)\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n\nfrom sklearn.svm import SVC\n\nclf = SVC()\nclf.fit(X_train, y_train)\n\nIn [197]: y_test\nOut[197]: array([0, 2, 0, ..., 0, 0, 1])\n\nIn [198]: clf.predict(X_test)\nOut[198]: array([2, 2, 2, ..., 2, 2, 2])\n\nIn [199]: y_test == clf.predict(X_test)\nOut[199]: array([False,  True, False, ..., False, False, False], dtype=bool)\n\nIn [200]: clf.score(X_test, y_test)\nOut[200]: 0.3125\n",
    "buf=pow(-(alpha*[D/Ds]),beta)\n\nbuf=pow(-(alpha*(D/Ds)),beta)\n\n[D/Ds]\n\nalpha * (D/Ds)\n\n>>> [1] * 4\n[1, 1, 1, 1]\n\n[1] * 4.0\nTypeError: can't multiply sequence by non-int of type 'float'\n\n>>> (1 + 2) * 4\n12\n",
    "a = np.loadtxt(\"datafile.txt\", int, delimiter=\",\")\n\nfor i in range(a.shape[1]):\n    # this will loop over i from 0 to the column count in a\n    print(a[0][i]) # print(a[0,i]) will also work but only on numpy array\n\nprint(a[:6])\n",
    "Mur    = np.array([200,246,372])*3*5\nMumax  = np.array([1400,600,700])*3*5\nMu     = np.array([100,500,2000])*3*5\nAcreq  = np.where(Mu<Mur,0,\"zero\")\nAcreq  = np.where((Mur<Mu)&(Mu<Mumax),45,Acreq)\nAcreq  = np.where(Mu>Mumax,60,Acreq)\n\nprint(Acreq)\n\n['0' '45' '60']\n\nconditions  = [Mu<Mur, (Mur<Mu)&(Mu<Mumax), Mu>Mumax ]\nchoices     = [ 0, 45, 60 ]\nAcreq       = np.select(conditions, choices, default='zero')\nprint(Acreq)\n\n\n['0' '45' '60']\n\nnp.where((Mur<Mu)&(Mu<Mumax),45,np.where(Mu>Mumax,60,np.where(Mu<Mur,0,\"zero\")))\n"
   ]
  },
  {
   "questions": [
    "Change using numpy.savetxt: When MAC well, copy computer(windows system), . Anyone why? 1349 1411 1378 1434 1309 1301 1295 1528 1226 1332,",
    "Why sin(180) zero using numpy?: Does anyone why below equal ? : When enter .22e 16.",
    ": Compute average big numbet saving : huge lists compute average storing . implementation ?",
    ": Saving / loading using numpy: saved array complex numbers using , worked trouble. However, loading, yields , Using: .7.9 64 bit .19 GB .",
    "Reading text numpy.loadtxt: text . now : content comma separated numbers. Perhaps space end causing ? . wrote text Torch7.",
    "add big numpy matrix: happen D numpy matrix form add represents squared sum : numpy functions add third ? matrices using",
    "- Importing dat using numpy: Hey guys im import text using numpy imported cols vice versa. Am formatting wrong happnened? added picture below:",
    "passing numpy array parameter theano function: As beginner, simply compute dot product matrices using theano. . , message \"TypeError: Unknown parameter type: \" Can anyone tell whats wrong ?",
    "Zero pad numpy array: 's pythonic pad array zeros end? real case, fact pad array closest multiple 1024. Ex: 1342 => 2048, 3000 => 3072",
    "write integers numpy array txt : write txt using numpy.savetxt() 't write using integers. : matrix 'm : 'm looking :"
   ],
   "code": [
    "a = [[1349, 1411, 1378, 1434, 1309, 1301, 1295, 1528, 1226, 1332]]\nnp.savetxt(\"Q1_ans.txt\", a, fmt=\"%d\", delimiter=\"\\r\\n\")\n",
    "abs(y - x) < abs_bounds and abs(y-x) < rel_bounds * y\n\nnp.allclose(x, y, rel_bounds, abs_bounds)\n\nnp.allclose(0, np.sin(np.radians(180)), rel_bounds, abs_bounds)\n",
    "running_sum = None\ncount = 0\nfor a in yourarraysource:\n    if running_sum is None:\n        running_sum = a\n    else:\n        running_sum = running_sum + a\n    count += 1\naverage = running_sum / count\n\nrunning_sum = 0\ncount = 0\nfor a in yourarraysource:\n    running_sum += a.sum()\n    count += a.size\naverage = running_sum / count\n",
    "with open(file_name, \"rb\") as file_:\n    variable_name = np.load(file_)\n",
    "import numpy as np\n\nfnam = 'file.txt'\ntest_fnames = np.genfromtxt(fnam, dtype=None, delimiter=',')\n\nimport numpy as np\n\nfnam = 'file.txt'\ntest_fnames = np.genfromtxt(fnam, dtype=None, delimiter=',')[:,:-1]\n",
    "a = np.array([[2,3], [1,2], [3,9]])\n\nnp.column_stack((a, np.sum(np.power(a, 2), axis=1)))\n#array([[ 2,  3, 13],\n#       [ 1,  2,  5],\n#       [ 3,  9, 90]])\n",
    "unpack : bool, optional\n\nIf True, the returned array is transposed, so that arguments may be\nunpacked using x, y, z = loadtxt(...). When used with a record data-type, \narrays are returned for each field. Default is False.`\n",
    "import theano\nimport theano.tensor as T\nimport numpy as np\n\na = T.matrix('a')\nb = T.matrix('b')\nz = T.dot(a, b)\nf = theano.function([a, b], z)\na_d = np.asarray([[2, 4], [6, 8]], dtype=theano.config.floatX)\nb_d = np.ones(a_d.shape, dtype=theano.config.floatX)\nprint(f(a_d, b_d))\n",
    "B = np.pad(A, (0, 1024 - len(A)%1024), 'constant')\nB\n# array([1, 2, 3, ..., 0, 0, 0])\nlen(B)\n# 1024\n\nA = np.ones(3000)\nB = np.pad(A, (0, 1024 - len(A)%1024), 'constant')\nB\n# array([ 1.,  1.,  1., ...,  0.,  0.,  0.])\n\nlen(B)\n# 3072\n",
    "savetxt(fname='newPicksData.txt', X=new_picks.astype(int), fmt ='%.0f\\n')\n"
   ]
  },
  {
   "questions": [
    "Parsing CSV Pandas Python3: parse movie database Python3. parse genres movie variables. : First movie_id, movie_name, third genres parse seperate varibles those belongs corresponding movie. words, seperator database \"|\". achieve ? :",
    "names numpy genfromtxt : using numpy genfromtxt , headers key . , names corresponding . Below Currently, shows format suggestions?",
    "Remove CSV: 'm CSV files. lat lon fields both files discard . 've fail, runs long produce . issue ? faster?",
    "Finding element corresponding maximum : align 4d z array 4d QCLOUD array z QCLOUD max occurs?",
    "Shorter One Liner NumPy grabbing indexes: : idxs = indexes s.t. corresponding labels lbl Question: shorter -liner? !",
    "three legends corresponding bars bar ?: create, however, three legends corresponding bars. :",
    "numpy indexing : (r, index[r]) put +(j )*dy corresponding record matrix/array look - having instead -",
    "Name variables using suffix entered input: name variables function, using suffix ( string) entered input function, order apply function once, obtaining results name? 'd :",
    "setup odes : setup odes corresponding initial conditions ? '(t) = (t) - y(t) - e^t y'(t) = (t) + y(t) + 2e^t ( )= - y( )= - <= t <= 4 far:",
    "numpy indexing: quite numpy. Can pls understand indexing used . six - put 10 corresponding empty matrix. look - far - wrong . pls."
   ],
   "code": [
    "df = pd.read_csv(\"movielens/movies.csv\", sep=\"[,|]\", header=None, engine='python')\nprint (df)\n   0                 1          2          3         4       5        6\n0  1  Toy Story (1995)  Adventure  Animation  Children  Comedy  Fantasy\n1  2    Jumanji (1995)  Adventure   Children   Fantasy    None     None\n\nmovie_db = pd.read_csv(\"movielens/movies.csv\", sep=\",\", names=header)\n\ndf =  movie_db.join(movie_db.pop('genres').str.get_dummies())\nprint (df)\n   movie_id             title  Adventure  Animation  Children  Comedy  Fantasy\n0         1  Toy Story (1995)          1          1         1       1        1\n1         2    Jumanji (1995)          1          0         1       0        1\n\ndf = movie_db.join(movie_db.pop('genres').str.split('|', expand=True))\nprint (df)\n   movie_id             title          0          1         2       3        4\n0         1  Toy Story (1995)  Adventure  Animation  Children  Comedy  Fantasy\n1         2    Jumanji (1995)  Adventure   Children   Fantasy    None     None\n",
    "In [94]: fn = r'D:\\temp\\.data\\z.csv'\n\nIn [95]: df = pd.read_csv(fn)\n\nIn [96]: df\nOut[96]:\n     header0  header1  header2\n0     mydate      3.4      2.0\n1   nextdate      4.0      6.0\n2  afterthat      7.0      8.0\n\nIn [97]: df.set_index('header0').to_dict('index')\nOut[97]:\n{'afterthat': {'header1': 7.0, 'header2': 8.0},\n 'mydate': {'header1': 3.3999999999999999, 'header2': 2.0},\n 'nextdate': {'header1': 4.0, 'header2': 6.0}}\n\nIn [107]: df.set_index('header0').to_json(orient='index')\nOut[107]: '{\"mydate\":{\"header1\":3.4,\"header2\":2.0},\"nextdate\":{\"header1\":4.0,\"header2\":6.0},\"afterthat\":{\"header1\":7.0,\"header2\":8.0}}'\n",
    "from itertools import zip_longest\nimport numpy\nf=numpy.genfromtxt('/wind/addandclaimwithinlatlon.csv',delimiter=\",\",dtype=None,skiprows=0)\nf1=numpy.genfromtxt('/wind/new_2011.csv',delimiter=\",\",dtype=None,skiprows=0)\nfinal=[row for row,row1 in zip_longest(f,f1) if len(row)>3 and len(row1)>1 and row[1:3]!=row1[:2]]\n",
    "idx = np.argmax(qcloud)\nresult = z[tuple(idx)]\n",
    "idxs = np.where(labels == lbl)[0]\n\nidxs = np.nonzero(labels == lbl)[0]\n\nidxs = np.flatnonzero(labels == lbl)\n\nIn [332]: np.random.seed(1)\n\nIn [333]: labels = np.random.randint(5, size=10)\n\nIn [334]: labels\nOut[334]: array([3, 4, 0, 1, 3, 0, 0, 1, 4, 4])\n\nIn [335]: [i for i,x in enumerate(labels) if x==lbl]\nOut[335]: [3, 7]\n\nIn [336]: np.where(labels == lbl)[0]\nOut[336]: array([3, 7])\n\nIn [339]: labels = np.tile(labels, 1000)\n\nIn [340]: labels.shape\nOut[340]: (10000,)\n\nIn [341]: %timeit np.where(labels == lbl)[0]\n10000 loops, best of 3: 45.9 \u00b5s per loop\n\nIn [342]: %timeit [i for i,x in enumerate(labels) if x==lbl]\n100 loops, best of 3: 5.31 ms per loop\n\nIn [343]: 5310/45.9\nOut[343]: 115.68627450980392\n",
    "import numpy as np\nimport matplotlib.pyplot as plt\nx=[1,2,3]\ny=[399,499,100]\nLABELS = [\"node0\", \"node1\", \"failed\"]\nLEGENDS=['txed', 'rxed', 'failed']\ncr = ['g','r','b']\nfig,ax = plt.subplots()\nfor i in range(len(x)):\n    ax.bar(x[i],y[i],align='center',color=cr[i], label=LEGENDS[i])\nplt.xticks(x, LABELS)\nplt.legend()\nplt.show()\n",
    "import numpy as np\ndx = 8\ndy = 10\nbx = 5.34\nby = 1.09\nindex = np.zeros(dx+dy,dtype = 'int32')\nrows = []\ncols = []\nvals = []\nfor i in np.arange(2,dy+1):\n    for j in np.arange(1,dx+1):\n        theta = 180*np.arctan(abs(j-bx)/(i-by))/np.pi\n        if theta < 10:\n            r = np.around(np.sqrt((j-bx)**2+(i-by)**2))\n            r = r.astype(int) \n            if r > 0:\n                index[r] += 1\n                rows.append(r-1)\n                cols.append(index[r]-1)\n                vals.append(i+(j-1)*dy)\n\noutshape = max(rows)+1, max(cols)+1  # now you know the size\noutput = np.zeros(outshape, np.int)  \noutput[rows, cols] = vals\n\nIn [60]: output\nOut[60]: \narray([[ 0,  0,  0],\n       [ 0,  0,  0],\n       [44,  0,  0],\n       [45, 55,  0],\n       [46, 56,  0],\n       [47, 57,  0],\n       [48, 58,  0],\n       [39, 49, 59],\n       [40, 50, 60]])\n\nimport numpy as np\ndx = 8\ndy = 10\nbx = 5.34\nby = 1.09\nindex = np.zeros(dx+dy,dtype = 'int32')\noutshape = (nrows, ncols)                        # if you know the size\noutput = np.zeros(outshape, np.int)              # initialize the output matrix\nfor i in np.arange(2,dy+1):\n    for j in np.arange(1,dx+1):\n        theta = 180*np.arctan(abs(j-bx)/(i-by))/np.pi\n        if theta < 10:\n            r = np.around(np.sqrt((j-bx)**2+(i-by)**2))\n            r = r.astype(int) \n            if r > 0:\n                index[r] += 1\n                output[r-1, index[r]-1] = i+(j-1)*dy  # no need to set `s` or `c`\n",
    "mylist.append(myFun(int))\n\n mydict = {}\n for i in range(6): # or whatever your loop looks like\n   mydict[\"a_{0}\".format(i)] = myFun(int)\n",
    "import numpy as np\nfrom scipy.integrate import odeint\n\ndef equation(X, t):\n    x, y = X\n    return [ x+y-np.exp(t), x+y+2*np.exp(t) ]\n\ninit = [ -1.0, -1.0 ]\nt = np.linpsace(0, 4, 50)\nX = odeint(equation, init, t)\n\nx = X[:, 0]\ny = X[:, 1]\n",
    "In [1]: import numpy as np\nIn [2]: a = np.array([[2,0],[3,0],[3,1],[5,0],[5,1],[5,2]])\nIn [3]: b = np.zeros((6,3), dtype='int32')\n\nIn [4]: b[a[:,0], a[:,1]] = 10\n\nIn [5]: b\nOut[5]: \narray([[ 0,  0,  0],\n       [ 0,  0,  0],\n       [10,  0,  0],\n       [10, 10,  0],\n       [ 0,  0,  0],\n       [10, 10, 10]])\n\nb[x, y] = z\n\nb[a[:,0], a[:,1]] = 10\n\nIn [37]: a[1,1]\nOut[37]: 0\n\nIn [38]: b[a[1,1]]\nOut[38]: array([0, 0, 0])\n\nIn [33]: b[a].shape\nOut[33]: (6, 2, 3)\n\nb[a] = 10\n"
   ]
  },
  {
   "questions": [
    "numpy: create 2d numpy array filled strings regular array: regular filled strings equal length: transform 2d numpy array, : ?",
    "Numpy: determine numpy array equal : array numpy equal : algorithm , implemented numpy library?",
    "create D numpy array D array?: numpy array: n copies both D numpy array, ?",
    "Unwrap inner array NumPy array: transform numpy array: Into :",
    "slicing numpy array parts: 2d numpy array Something : Now divide parts. lets say numpy array . numpy array rest",
    "Insert d numpy array existing d array: d numpy array d array. elegant insert b ?",
    "sort array ?: form below: sort array . required : using ( ): sort array ?",
    "numpy : stored numpy array. extract pixel rectangle array. rectangle defined ((x1,y1),(x2,y2)) y s naturally . extract pixel using nested , pythonic ?",
    "Numpy select numpy array : select matrix. Numbers specified array. dimensional array. : : .",
    "Numpy select numpy array : select matrix. Numbers specified array. dimensional array. : : ."
   ],
   "code": [
    "In [187]: alist=['FADVAG', 'XXDXFA', 'GDXX..']\nIn [188]: arr = np.array([list(a) for a in alist])\nIn [189]: arr\nOut[189]: \narray([['F', 'A', 'D', 'V', 'A', 'G'],\n       ['X', 'X', 'D', 'X', 'F', 'A'],\n       ['G', 'D', 'X', 'X', '.', '.']],\n      dtype='<U1')\n\nnp.array(list(''.join(alist))).reshape(3,-1)\n",
    "np.all(numbers == 0)\n# or equivalently\n(numbers == 0).all()\n",
    "np.repeat(A,4).reshape(-1,4)\n\nnp.repeat(A[:,None],4,axis=1)\n\nnp.tile(A[:,None],4)\n",
    "a = numpy.array([[[10, 10]],\n     [[300, 300]],\n     [[10, 300]]])\nb = numpy.array([a[:,0]])\nprint(b)\n\n[[[ 10  10]\n  [300 300]\n  [ 10 300]]]\n\nb = numpy.swapaxes(a, 1, 0)\n",
    ">>> import numpy as np\n>>> A = np.array([[1,2,3,4],[4,5,6,7],[7,8,9,10]])\n>>> B = A[:2]\n>>> C = A[2:]\n>>> B\narray([[1, 2, 3, 4],\n       [4, 5, 6, 7]])\n>>> C\narray([[ 7,  8,  9, 10]])\n",
    "In [256]: np.column_stack((b, a))\nOut[256]:\narray([[0, 1, 2, 3],\n       [1, 4, 5, 6],\n       [2, 7, 8, 9]])\n",
    "for i in A: i.sort()\n\nA.sort()\n",
    "In [3]: a = numpy.arange(20).reshape((4,5))\n\nIn [4]: a\nOut[4]: \narray([[ 0,  1,  2,  3,  4],\n       [ 5,  6,  7,  8,  9],\n       [10, 11, 12, 13, 14],\n       [15, 16, 17, 18, 19]])\n\nIn [5]: a[2:4, 3:5]\nOut[5]: \narray([[13, 14],\n       [18, 19]])\n\nIn [6]: x=2 ; print a[x-1:x+1, :]\n[[ 5  6  7  8  9]\n [10 11 12 13 14]]\n",
    "a[numbers[:,None] > np.arange(a.shape[1])]\n\nIn [161]: a\nOut[161]: \narray([[ 0,  1,  2,  3,  4],\n       [ 5,  6,  7,  8,  9],\n       [10, 11, 12, 13, 14],\n       [15, 16, 17, 18, 19],\n       [20, 21, 22, 23, 24]])\n\nIn [162]: numbers\nOut[162]: array([3, 2, 0, 1, 2])\n\nIn [163]: numbers[:,None] > np.arange(a.shape[1]) # Mask to select elems\nOut[163]: \narray([[ True,  True,  True, False, False],\n       [ True,  True, False, False, False],\n       [False, False, False, False, False],\n       [ True, False, False, False, False],\n       [ True,  True, False, False, False]], dtype=bool)\n\nIn [164]: a[numbers[:,None] > np.arange(a.shape[1])] # Select w/ boolean indexing\nOut[164]: array([ 0,  1,  2,  5,  6, 15, 20, 21])\n",
    "a[numbers[:,None] > np.arange(a.shape[1])]\n\nIn [161]: a\nOut[161]: \narray([[ 0,  1,  2,  3,  4],\n       [ 5,  6,  7,  8,  9],\n       [10, 11, 12, 13, 14],\n       [15, 16, 17, 18, 19],\n       [20, 21, 22, 23, 24]])\n\nIn [162]: numbers\nOut[162]: array([3, 2, 0, 1, 2])\n\nIn [163]: numbers[:,None] > np.arange(a.shape[1]) # Mask to select elems\nOut[163]: \narray([[ True,  True,  True, False, False],\n       [ True,  True, False, False, False],\n       [False, False, False, False, False],\n       [ True, False, False, False, False],\n       [ True,  True, False, False, False]], dtype=bool)\n\nIn [164]: a[numbers[:,None] > np.arange(a.shape[1])] # Select w/ boolean indexing\nOut[164]: array([ 0,  1,  2,  5,  6, 15, 20, 21])\n"
   ]
  },
  {
   "questions": [
    "Logic operator boolean indexing Pandas: 'm working boolean index Pandas. why statement: fine whereas exists ? Example:",
    "multidimensional boolean indexing numpy: , numbers boolean : When index array returns 1D array: index array array expected :",
    "Unexpected behaviour indexing np.array boolean : Now, enter: : whole lot sense . Can anybody explain simply?",
    "indexing numpy: Given index array , D whose exist ? Example: D? Edit: 'm looking shot cases d big.",
    "Skipping csv using Pandas: quick reading csv using Pandas. CSV format: csv using . However, skip either entries NA ( case skip ). !",
    "Ragged transposition Pandas: table (ignoring index): table : Pandas ?",
    "Boolean Indexing turns operation: boolean indexing .. happened? thinking Bool indexing. operation ? asking correct Bool indexing. Rather, Im asking happening operation? legit?",
    "generator' object attribute ' ', problems loading scipy?: Im 'm triying load .arff : : Why happening? avoid ?. .arff:",
    "Using range while fancy indexing?: Can someone explain expression terms? take range zero?",
    "Pandas None logical indexing confusion: relatively user . 't understand why . Why returns True element actually equal None? Thank ."
   ],
   "code": [
    "(a['x']==1) and (a['y']==10)\n\nValueError: The truth value of an array is ambiguous. Use a.empty, a.any() or a.all().\n\n(a['x']==1) & (a['y']==10)\n",
    "In [9]: from itertools import izip\nIn [11]: array([r[ridx] for r, ridx in izip(x, idx) if ridx.sum() > 0])\nOut[11]: \narray([array([ 1.,  1.,  1.,  1.,  1.]), array([ 2.,  2.,  2.,  2.,  2.]),\n       array([ 3.,  3.,  3.,  3.,  3.]), array([ 4.,  4.,  4.,  4.]),\n       array([ 5.,  5.,  5.]), array([ 6.]), array([ 7.])], dtype=object)\n",
    "two_d[[0, 1], [3, 4]]\n\n>>> two_d[np.ix_(first, second)]\narray([[3, 4],\n       [8, 9]])\n",
    "A = zeros(D.shape)\nfor i, j in I:\n    A[i, j] = D[i, j]\n\nA = zeros(D.shape)\ni, j = I.T\nA[i, j] = D[i, j]\n",
    "In [11]: df.dropna(subset=['Value1', 'Value2', 'Value3'])\nOut[11]:\n   Num     Date  Value1  Value2  Value3\n0    1  7/29/11       1       2       3\n3    4   7/6/11      -1       0       2\n\nIn [21]: df.loc[:, ['Value1', 'Value2', 'Value3']].apply(pd.notnull)\nOut[21]:\n  Value1 Value2 Value3\n0   True   True   True\n1  False   True   True\n2   True  False  False\n3   True   True   True\n\nIn [22]: df.loc[:, ['Value1', 'Value2', 'Value3']].apply(pd.notnull).all(1)\nOut[22]:\n0     True\n1    False\n2    False\n3     True\ndtype: bool\n\nIn [23]: df[df.loc[:, ['Value1', 'Value2', 'Value3']].apply(pd.notnull).all(1)]\nOut[23]:\n   Num     Date  Value1  Value2  Value3\n0    1  7/29/11       1       2       3\n3    4   7/6/11      -1       0       2\n\nIn [24]: df = df[df.loc[:, ['Value1', 'Value2', 'Value3']].apply(pd.notnull).all(1)]\n",
    "df['score'] = df.groupby('group')['score'].rank()\ndf.set_index(['group','score']).unstack()\n\n      subgroup        \nscore        1  2    3\ngroup                 \nA            B  C    A\nB            C  A    F\nC            C  D  NaN\n",
    "import numpy as np\nA = np.random.rand(3,3)\nA[0:1,0:1]\nA[range(2),range(2)]\n\nA = np.random.rand(4,2)\nbool_index_list = [False, True, True, False]\nbool_index_array = np.array(bool_index_list)\nA[bool_index_list].shape\nA[bool_index_array].shape\n",
    "file1 = open('example.arff', \"rb\")\ndataset = arff.load(file1)\nprint(dataset)\n{u'attributes': [(u'width', u'NUMERIC'), (u'height', u'NUMERIC'), (u'color', [u'red', u'green', u'blue', u'yellow', u'black'])], u'relation': u'foo', u'description': u'', u'data': [[5.0, 3.25, u'blue'], [4.5, 3.75, u'green'], [3.0, 4.0, u'red']]}\n\ndataset = arff.load('eg.arff')\nfor row in dataset:\n    x = row.color\n    print(x)\nblue\ngreen\nred\n",
    "import numpy as np\n\nn = 5\nlena_image = np.ones(shape=(n, n))\nlena_image[range(n), range(n)] = 0\nprint lena_image\n\n[[ 0.  1.  1.  1.  1.]\n [ 1.  0.  1.  1.  1.]\n [ 1.  1.  0.  1.  1.]\n [ 1.  1.  1.  0.  1.]\n [ 1.  1.  1.  1.  0.]]\n",
    ">>> pd.lib.scalar_compare(np.array([None]), None, operator.ne)\narray([ True], dtype=bool)\n"
   ]
  },
  {
   "questions": [
    "Checking broadcastable : According documentation (https://docs.scipy.org/doc/numpy/reference/ufuncs.html), broadcastable conditions true: implement , having trouble understanding 2nd 3rd rule. Not answer expecting, making .",
    "Cannot array floats : 'm having answer easily explained. 'm struggling array floats ( multiply, add etc) :",
    "Understanding ndarray shapes: 'm numpy having trouble understanding shapes decided. An array form ( ,) while form ( , ). Moreover, ( ,) adding vector changes ( , , ). Intuitively, feel - dimensional. Could anyone understand 's happening exactly?",
    "Cannot Find Correct Working Directory Spyder: 'm having trouble working directory Spyder console. 'm xlsx array, keep . 've changed Run Directory preferences correct . screenshot Spyder console Sorry really newbie really dont go here.",
    "loopless 3D matrix multiplication : looking operation (numpy). Matrix multiply AB = C, C M R matrix. Essentially M N layer (R ) matrix multiplied independently N vector B. sure -liner. been tensordot(), giving answers expect. been programming Igor Pro nearly 10 years, now pages .",
    "add D array -numpy? [duplicate]: already answer here: add D array D array : D array: expected : advance!",
    "Using '' '' copy numpy : numpy : merge single array, did : case input . Now 5 input instead . confused case? 5 expected :",
    "Creating smaller array larger array , based : numpy array ( ) reduce smaller array, based specific 2nd (ie < .5). Based answer Asagen below, here script:",
    "Replace array reference : replace ' ' using 'ref' : : No change. expected array 9 12 replaced . 's fastest ?",
    "Covariance : numpy X X. =(m,n) vector y y. =(m, ), calculate covariance X y wihtout using ? expect (m, ) ( ,m)."
   ],
   "code": [
    "In [101]: import numpy as np\n\nIn [102]: a = np.zeros((3, 1, 5))\n\nIn [103]: b = np.zeros((4, 5))\n\nIn [104]: all((m == n) or (m == 1) or (n == 1) for m, n in zip(a.shape[::-1], b.shape[::-1]))\nOut[104]: True\n\nIn [105]: b = np.zeros((5, 3))\n\nIn [106]: all((m == n) or (m == 1) or (n == 1) for m, n in zip(a.shape[::-1], b.shape[::-1]))\nOut[106]: False\n",
    " a = np.array(all_data, dtype=float)\n",
    "In [1]: arr = np.array([[[5, 10, 15], [20, 25, 30], [35, 40, 45]], [1,2,4,3]])\nIn [2]: arr\nOut[2]: array([[[5, 10, 15], [20, 25, 30], [35, 40, 45]], \n               [1, 2, 4, 3]\n              ], dtype=object)   # adjusted format\nIn [3]: arr.dtype\nOut[3]: dtype('O')\nIn [4]: arr.shape\nOut[4]: (2,)\nIn [5]: arr[0]\nOut[5]: [[5, 10, 15], [20, 25, 30], [35, 40, 45]] # 3 element list of lists\nIn [6]: arr[1]\nOut[6]: [1, 2, 4, 3]  # 4 element list of numbers\n\nIn [7]: arr = np.array([[[5, 10, 15], [20, 25, 30], [35, 40, 45]], [1,2,4]] )\nIn [8]: arr\nOut[8]: \narray([[[5, 10, 15], [20, 25, 30], [35, 40, 45]],\n       [1, 2, 4]\n      ], dtype=object)\nIn [9]: arr.shape\nOut[9]: (2, 3)\nIn [10]: arr[0,0]\nOut[10]: [5, 10, 15]\n\nIn [11]: arr = np.array([[[5, 10, 15], [20, 25, 30], [35, 40, 45]], [[1,2,4], [3,4,2], [1,2,4]]] )\nIn [12]: arr\nOut[12]: \narray([[[ 5, 10, 15],\n        [20, 25, 30],\n        [35, 40, 45]],\n\n       [[ 1,  2,  4],\n        [ 3,  4,  2],\n        [ 1,  2,  4]]])\nIn [13]: arr.shape\nOut[13]: (2, 3, 3)\n\nIn [1]: np.__version__\nOut[1]: '1.13.1'\nIn [2]: np.array([[[5, 10, 15], [20, 25, 30], [35, 40, 45]], [1,2,4,3]])\nOut[2]: array([list([[5, 10, 15], [20, 25, 30], [35, 40, 45]]), list([1, 2, 4, 3])], dtype=object)\n\nIn [3]: np.array([[[5, 10, 15], [20, 25, 30], [35, 40, 45]], [1,2,4]] )\nOut[3]: \narray([[list([5, 10, 15]), list([20, 25, 30]), list([35, 40, 45])],\n       [1, 2, 4]], dtype=object)\n\nIn [11]: np.array([[[5, 10, 15], np.array([20, 25, 30]), (35, 40, 45)], [None,2,'astr']] )\nOut[11]: \narray([[list([5, 10, 15]), array([20, 25, 30]), (35, 40, 45)],\n       [None, 2, 'astr']], dtype=object)\nIn [12]: [type(x) for x in _.flat]\nOut[12]: [list, numpy.ndarray, tuple, NoneType, int, str]\n",
    "import os\nos.chdir('C:/Users/mypath') # Change your working directory to your .xlsx file location\n\nos.getcwd()\n",
    "import numpy as np\n\nD,M,N,R = 1,2,3,4\nA = np.random.rand(M,N,R)\nB = np.random.rand(N,D,R)\n\nprint np.einsum('mnr,ndr->mdr', A, B).shape\n",
    ">>> np.vstack((b, np.transpose(a[:,2])))\narray([[ 1.        ,  2.        ,  3.        ],\n       [ 0.14942441,  0.75303451,  0.64617275]])\n",
    "merg_arr = np.concatenate([array1, array2, array3, array4, array5], axis=0)\n\narrays = (array1, array2, array3, array4, array5)\nlength_sum = sum(len(arr) for arr in arrays)\nmerge_arr = np.zeros((length_sum, 4,100,100), dtype=arrays[0].dtype)\nstart = 0\nfor arr in arrays:\n    end = start + len(arr)\n    merge_arr[start:end] = arr\n    start = end\n",
    "foo = np.random.uniform(0,1,20).reshape(10,2)\nbar = foo[foo[:,1]<0.5]\n",
    "data[np.in1d(data, ref).reshape(data.shape)] = -1\n",
    "np.sum((A - A.mean(0))*(B - B.mean(0)),0)/B.size\n\nnp.dot((B - B.mean(0)).T,(A - A.mean(0)))/B.size\n"
   ]
  },
  {
   "questions": [
    "numpy arange: \u201cprecise\u201d array floats?: short, encounter : reality, cause series since simulations allow positive inputs. sort around : pain. Practically 't . basic . There's gotta missing here. By , using .7.13.",
    "Using numpy avoid loops - combinatorics: There's got pythonic : 'm sure using simplify somehow, 'm sure . !",
    "len() compared __len__ numpy array: going here? check length? , considers length: using .7. numpy .8. . .",
    "Get strings array: array numpy : array 'b', 'c', 'd' : later . using .7. folks",
    "replace numpy?: function , replaces replaces next , previous won't go back 's original form.",
    "Manipulating Numpy array: Using sum adjacent : here : sum here. , , : . sum . inbuilt numpy function ? sum : + 7 = 9",
    "Arrays numpy: floats . : 't change integer, floats.",
    "numpy print index certain : Given numpy array index certain , say 63 There possibility duplicated missing did got iterable array, dtype int32 etc. ?",
    "Numpy max along axis: Am missing here? expect np.max snippet [ , 4]... pointers.",
    "numpy show positive numbers : numpy go numbers greater .... Then numpy print column1 postive numbers found column2 ever associated . When print l results column1 showing column2(column2 filtered)"
   ],
   "code": [
    ">>> start = -1\n>>> for i in range(1000):\n...    start += 0.001\n>>> start\n8.81239525796218e-16\n\n>>> x = np.arange(-1., 0.001, 0.01)\n>>> x[-1]\n8.8817841970012523e-16\n\n>>> x = 0.01 * np.arange(-100, 0.1)\n>>> x[-1]\n0.0\n\n>>> def safe_arange(start, stop, step):\n...    return step * np.arange(start / step, stop / step)\n\n>>> x = safe_arange(-1, 0.001, 0.01)\n>>> x[-1]\n0\n\n>>> val = -0.99\n>>> print('{0:.20f}'.format(val))\n-0.98999999999999999112\n",
    "import itertools\nr = np.arange(100)\nresults = []\nfor (i,j,k,l) in itertools.product(r,repeat=4):\n    if f(i,j,k,l) < 5.0:\n         results.append(f(i,j,k,l))\n\n[ f(i,j,k,l) for (i,j,k,l) in itertools.product(r,repeat=4) if f(i,j,k,l) < 5.0 ]\n",
    "import numpy as np\n\ndef make_ary(item):\n    if not isinstance(item, list):\n        ary = np.array([item])\n    else:\n        ary = np.array(item)\n        ary = ary.ravel()\n    return ary\n\na = [1,2,3]\nb = 3\nc = [ [1] , [2] ,[3] ]\n\n\n>> make_ary(a)\narray([1, 2, 3])\n\n>> make_ary(b)\narray([3])\n\n>> make_ary(c)\narray([1, 2, 3])\n",
    "In [61]: myarray = np.array(['a', 'b', 'c', 'd', 'e', 'f'])\n\nIn [62]: search = np.array(['b', 'c', 'd'])\n\nIn [63]: np.searchsorted(myarray, search)\nOut[63]: array([1, 2, 3])\n\nIn [64]: myarray = np.array(['a', 'd', 'b', 'e', 'c', 'f'])\n\nIn [65]: search = np.array(['b', 'c', 'd'])\n\nIn [67]: sidx = np.argsort(myarray)\n\nIn [69]: sidx[np.searchsorted(myarray, search, sorter=sidx)]\nOut[69]: array([2, 4, 1])\n",
    "def CramersRule(A,b):\n    for c in range (n):\n        detA1 = la.det(A)\n        temp = np.array(A[:,c])\n        A[:,c] = b.transpose()\n        print A\n        x = la.det(A)/detA1\n        print (\"X%d: \")%(c+1),x\n        A[:,c]=temp.transpose()\n",
    "np.bincount(a[:,1], weights=a[:,0])\n\narray([ 0.,  9.,  4.])\n\nnp.bincount(a[:,1], weights=a[:,0])[np.unique(a[:,1])]\n\narray([9.,  4.])\n\nind = rd(a[:,1], method = 'dense').astype(int) - 1 # ranking begins from 1, we need from 0\nsums = np.bincount(ind, weights=a[:,0])\n\nzip(np.unique(a[:,1]), sums) \n",
    "for x in matriztiempo:\n\nfor i, x in enumerate(matriztiempo):\n\nfor x in xrange(matriztiempo.shape[0]):\n    for y in xrange(matriztiempo.shape[1]):\n        if matrizvelocidades[x,y] != 0:\n            matriztiempo[x,y] /= matrizvelocidades[x,y]\n        else:\n            matriztiempo[x,y] = 0\n\nmatriztiempo /= matrizvelocidades\n\ngood_mask = (matrizvelocidades != 0)\nbad_mask = numpy.logical_not(good_mask)\n\nmatriztiempo[good_mask] /= matrizvelocidades[good_mask]\nmatriztiempo[bad_mask] = 0.0\n\nbad_mask = (matrizvelocidades == 0)\n",
    "In [30]: np.concatenate(idx)\nOut[30]: array([1, 2, 1])\n\nIn [31]: np.concatenate(idx).tolist()\nOut[31]: [1, 2, 1]\n",
    "In [464]: a.argmax()\nOut[464]: 3\nIn [465]: np.unravel_index(3,(2,2))\nOut[465]: (1, 1)\nIn [466]: a[1,:]\nOut[466]: array([0, 4])\n\nIn [467]: a[np.unravel_index(a.argmax(), a.shape)[0], :]\nOut[467]: array([0, 4])\n\nIn [537]: np.linalg.norm(a,axis=1)\nOut[537]: array([ 2.23606798,  4.        ])\nIn [538]: np.argmax(_)\nOut[538]: 1\nIn [539]: a[_,:]\nOut[539]: array([0, 4])\n",
    "xx = x[x[:,0]>0,:]\n"
   ]
  },
  {
   "questions": [
    "access entire sub array numpy?: store images results multi dimensional array. Consider below m images 3x4, now access , m[:, :, ]. produced wrong results. Can please correct access sub array.",
    "Slicing multidimensional numpy array obtain vector: 'm create vector selecting relevant multidimensional array. returns Now 'm vectorize operation. To , logical thing returns Can anybody explain going here obtain intended ? advance",
    "Accessing array : handling multidimensional 'm having problems accessing . 'm red pixels picture 8 within array. 's",
    "Appending successive dataframe: create bidimensional numpy array. : . dimensions array : ( , ). ? : prints: . access specific element array? : returns:",
    "Sum along axis numpy array: understand ndarray.sum(axis=) . axis axis . case dimensions( axes) its difficult interpret below . axes array ( , ,5), 5 . look array whole, (both array ). Can anyone please explain sum array axes(dimensions).",
    "Rotating images 90 degrees multidimensional NumPy array: numpy array (7,4,100,100) means 7 images 100x100 depth 4. rotate images 90 degrees. : changes array (4,7,100,100) desired. ?",
    "access ith NumPy multidimensional array?: Suppose : test[ ] gets ith array (eg [ , ]). access ith ? (eg [ , , 5]). Also, expensive operation?",
    "access ith NumPy multidimensional array?: Suppose : test[ ] gets ith array (eg [ , ]). access ith ? (eg [ , , 5]). Also, expensive operation?",
    "represent \u201c:\u201d numpy: slice multidimensional ndarray dimension slice . Lets say we ndarray (6,7,8). Sometimes slice 1st dimension [:, ,4], sometimes third [ , ,:]. symbol represent \":\"? generate index array.",
    "update dimension array h5py?: store dimensional array hdf5 troubles update . normal dim array. dim array?"
   ],
   "code": [
    ">>> a = numpy.random.random((3, 4, 3))\n>>> a\narray([[[ 0.2585421 ,  0.6096753 ,  0.70295892],\n        [ 0.50408344,  0.37075371,  0.30463057],\n        [ 0.76298221,  0.67466292,  0.53305787],\n        [ 0.63844013,  0.45100157,  0.1346955 ]],\n\n       [[ 0.54268873,  0.31534909,  0.40414511],\n        [ 0.87335605,  0.81278098,  0.12953214],\n        [ 0.64353518,  0.22347   ,  0.63712407],\n        [ 0.02646421,  0.56478202,  0.57160074]],\n\n       [[ 0.36965073,  0.796066  ,  0.7289024 ],\n        [ 0.47232785,  0.43087964,  0.873769  ],\n        [ 0.12393581,  0.63266617,  0.0935309 ],\n        [ 0.62007608,  0.77474674,  0.28507152]]])\n>>> a[0]\narray([[ 0.2585421 ,  0.6096753 ,  0.70295892],\n       [ 0.50408344,  0.37075371,  0.30463057],\n       [ 0.76298221,  0.67466292,  0.53305787],\n       [ 0.63844013,  0.45100157,  0.1346955 ]])\n",
    ">>> P[np.arange(n), x, y]\narray([ 0, 23, 41])\n",
    "r.flatten()[:8]\n",
    "In [1]: result = np.empty\nIn [2]: result\nOut[2]: <function numpy.core.multiarray.empty>\n\nIn [3]: np.append(result, [1,2,3])\nOut[3]: array([<built-in function empty>, 1, 2, 3], dtype=object)\n\nIn [4]: result.item((1,2))\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\n<ipython-input-4-51f2b4be4f43> in <module>()\n----> 1 result.item((1,2))\n\nAttributeError: 'builtin_function_or_method' object has no attribute 'item'\n\nIn [5]: np.shape(result)\nOut[5]: ()\nIn [6]: np.array(result)\nOut[6]: array(<built-in function empty>, dtype=object)\n\nresult = []\nresult.append([1,2,3])\nresult.append([4,5,6])\n\nIn [7]: result = np.empty((0,3),int)\nIn [8]: result\nOut[8]: array([], shape=(0, 3), dtype=int32)\nIn [9]: result = np.append(result,[1,2,3])\nIn [10]: result\nOut[10]: array([1, 2, 3])\nIn [11]: result = np.append(result,[4,5,6])\nIn [12]: result\nOut[12]: array([1, 2, 3, 4, 5, 6])\n\nIn [15]: result = []\nIn [16]: result.append([1,2,3])\nIn [17]: result.append([4,5,6])\nIn [18]: result\nOut[18]: [[1, 2, 3], [4, 5, 6]]\nIn [19]: result = np.array(result)\nIn [20]: result\nOut[20]: \narray([[1, 2, 3],\n       [4, 5, 6]])\n\nIn [21]: result[1,2]\nOut[21]: 6\nIn [22]: result.item((1,2))\nOut[22]: 6\n\nIn [23]: np.source(np.append)\nIn file: /usr/local/lib/python3.5/dist-packages/numpy/lib/function_base.py\n\ndef append(arr, values, axis=None):\n    \"\"\"\n    ...\n    \"\"\"\n    arr = asanyarray(arr)\n    if axis is None:\n        if arr.ndim != 1:\n            arr = arr.ravel()\n        values = ravel(values)\n        axis = arr.ndim-1\n    return concatenate((arr, values), axis=axis)\n",
    ">>> arr = np.arange(0,30).reshape(2,3,5)\n>>> arr.sum(axis=0, keepdims=True)\narray([[[15, 17, 19, 21, 23],\n        [25, 27, 29, 31, 33],\n        [35, 37, 39, 41, 43]]])\n\n>>> arr.shape\n(2, 3, 5)\n\n>>> arr.sum(axis=0).shape\n(3, 5)  # the first entry (index = axis = 0) dimension was removed \n\n>>> arr.sum(axis=1).shape\n(2, 5)  # the second entry (index = axis = 1) was removed\n\n>>> arr.sum(axis=(0, 1))\narray([75, 81, 87, 93, 99])\n>>> arr.sum(axis=(0, 1)).shape\n(5, )  # first and second entry is removed\n",
    "from scipy.ndimage import rotate\nfrom scipy.misc import imread, imshow\n\nimg = imread('raven.jpg')\n\nrotate_img = rotate(img, 90)\n\nimshow(rotate_img)\n",
    ">>> test[:,0]\narray([1, 3, 5])\n\n>>> test[1,:]\narray([3, 4])\n",
    ">>> test[:,0]\narray([1, 3, 5])\n\n>>> test[1,:]\narray([3, 4])\n",
    "import numpy as np\nA = np.arange(9).reshape(3, -1)\n\n# extract the 2nd column\nA[:, 1]\n\n# equivalently we can do\ncslice = slice(None) # represents the colon\nA[cslice, 1]\n",
    "In [2]: fh = h5py.File('dummy.h5','a')\nIn [6]: fh['random'].value\nOut[6]: \narray([[0, 1],\n       [2, 3]])\nIn [8]: fh['random'][0][0] = 6\nIn [9]: fh['random'].value\nOut[9]: \narray([[0, 1],\n       [2, 3]])\nIn [10]: fh['random'][0,0] = 6\nIn [11]: fh['random'].value\nOut[11]: \narray([[6, 1],\n       [2, 3]])\n"
   ]
  },
  {
   "questions": [
    "Extract colored numpy : features colored curve. extract index higher pixel curve. , quite slow (fis , magic RGB color): thing faster?",
    "Extract pixel coordinates paste : returning pixels coordinates red color now extract paste those pixels . paste pixel coordinates? Please ask clear.",
    "extract special numpy R: stored bed numpy : usually, job R numpy? better stored bed extract special lines ? thanks .",
    "Extract information Numpy Array [closed]: information stored structure array dtype , , y, cnt. extract 1st repeated cnt parameter:",
    "Fastest create numpy whose range: create numpy array store coordinates pixels numpy ridiculous couldn't anything yet.",
    "working yml files opencv: load yml ? used : print , detail etc. pixel . , pixel information contained pixel?",
    "PyOpenGL numpy texture appears solid color: 'm numpy OpenGl textures pygame. pixel taken texture instead random pattern ( ) random color .",
    "Removing white space colon: bunch numbers white spaces colons remove . As seen forum function .strip.split() well achieve . removing white space colon go? Using posted Lorenzo : Although :",
    "10 traces figure color ?: 10 traces color , trace extension .numpy., mean 10 files: trace: According must put ? order ? advance.",
    "Printing numpy array indicies: print numpy preceeded . print : extract index printed separated comma similar ?"
   ],
   "code": [
    "mask = (f == magic).all(-1)\n\n(f == magic).all(-1).argmax(0)\n",
    "# \u4f7f\u7528 cv2.bitwise_and \u63a9\u6a21\u64cd\u4f5c\uff0c\u7136\u540e\u4f7f\u7528 np.where \u83b7\u53d6\u5750\u6807\nres = cv2.bitwise_and(img,img,mask = mask)\nres_gray = cv2.cvtColor(res, cv2.COLOR_BGR2GRAY)\nys,xs = np.where(res_gray>0)\npts = [(x,y) for x,y in zip(xs,ys)]\n\n## \u590d\u5236-\u7c98\u8d34\u5230\u5176\u4ed6\u7a7a\u767d\u7684\u5730\u65b9\nempty = np.zeros_like(img)\nmask_c = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\nimaskc = mask_c>0\nempty[imaskc] = img[imaskc]\n",
    ">>> t[:,0]\narray([b'chr1', b'chr1', b'chr1', b'chrX', b'chrX', b'chrX'], \n      dtype='|S9')\n>>> mask = t[:,0]==b'chr1'\n>>> mask\narray([ True,  True,  True, False, False, False], dtype=bool)\n>>> t[mask]\narray([[b'chr1', b'2488152', b'2488153'],\n       [b'chr1', b'2488397', b'2488398'],\n       [b'chr1', b'2491262', b'2491417']], \n      dtype='|S9')\n",
    "print data[np.unique(data[:,4],return_index=True)[1]]\n\n#[[41641  1428     0     3  2554]\n# [44075  1428     0     3  2555]\n# [44901  1428     1     3  2556]\n# [45377  1428     0     3  2557]\n# [48056  1428     0     3  2558]]\n",
    ">>> data=np.indices((512,512)).swapaxes(0,2).swapaxes(0,1)\n>>> data.shape\n(512, 512, 2)\n\n>>> data[5,0]\narray([5, 0])\n>>> data[5,25]\narray([ 5, 25])\n\n>>> a=np.ones((3,3))\n>>> ind=np.indices((2,1))\n>>> a[ind[0],ind[1]]=0\n>>> a\narray([[ 0.,  1.,  1.],\n       [ 0.,  1.,  1.],\n       [ 1.,  1.,  1.]])\n\nnp.mgrid[0:512,0:512].swapaxes(0,2).swapaxes(0,1)\n\n>>> a=np.arange(0,512)\n>>> x,y=np.meshgrid(a,a)\n>>> ind=np.dstack((y,x))\n>>> ind.shape\n(512, 512, 2)\n\n>>> ind[5,0]\narray([5, 0])\n",
    "import yaml\n\nwith codecs.open('your.yml', 'r', encoding='utf8') as f:\n     yml_dict = yaml.safe_load(f)\n",
    "#draw rectangle\nglTranslatef(300,200,0)\nglBegin(GL_QUADS)\n\nglTexCoord(0,0)\nglVertex2f(0,0)\n\nglTexCoord(0,1)\nglVertex2f(0,height)\n\nglTexCoord(1,1)\nglVertex2f(width,height)\n\nglTexCoord(1,0)\nglVertex2f(width,0)\n\nglEnd()\nglFlush()\n",
    "train = []\nwith open('/Users/sushant.moon/Downloads/dexter_train.data') as f:\n    list = f.read().split()\n    for x in list:\n        data = x.split(':')\n        train.append([int(data[0]),int(data[1])])\n\n# this part becomes redundant as i have already converted str to int before i append data to train\nsize_of_train = np.shape(train) \nfor i in range(size_of_train[0]): \n    for j in range(size_of_train[1]): \n        train[i][j] = int(train[i][j])\n",
    "import matplotlib.pyplot as plt \nimport numpy as np\nimport matplotlib\n\n# Read in list of files. You might want to look into os.listdir()\ntraces=[list of filepaths to your .npy files]\n\n# Create figure \nfig=plt.figure()\nfig.show()\nax=fig.add_subplot(111)\n\n# Grab colormap\ncmap = matplotlib.cm.get_cmap('jet')\n\n# Loop through traces and plot them\nfor j,trace in enumerate(traces):\n\n    # Load file\n    dataArray= np.load(trace)\n\n    # Grab color\n    c=cmap(float(j)/len(traces))\n\n    # Plot\n    ax.plot(dataArray.T,color=c)\n\nplt.show()\n",
    ">>> for index, val in np.ndenumerate(a):\n...     print '{}, {}, {}'.format(index[0], index[1], val)\n...\n0, 0, 0\n0, 1, 1\n0, 2, 2\n1, 0, 3\n1, 1, 4\n1, 2, 5\n"
   ]
  },
  {
   "questions": [
    "PIL: TypeError: src numpy array, neither scalar: :",
    ", Numpy arrey : numpy array here's : :",
    "TypeError: src numpy array: Error Displayed Traceback (most recent call last): Code",
    "TypeError: src numpy array, neither scalar. No stream: contours streaming drone detect contours gutter . sure fix . appreciated.",
    "TypeError: dst numpy array, neither scalar - resize jpg : 'm resize further perspective treatments 'm . here's ... shows .",
    "numpy array dataframe: numpy array dataframe? : :",
    "itertools.chain numpy array?: c numpy array, reshape further calculations.",
    "numpy re arrangement: numpy array : :",
    "TypeError: length converted scalars while showing: : : fix ?",
    "ValueError: string float: '62,6': dataframe numpy array: piece : Where ?"
   ],
   "code": [
    "gray = cv2.cvtColor(np.asarray(image), cv2.COLOR_BGR2GRAY)\n",
    "x = np.array([[20, 20],[20, 20]], int32)\n",
    "morphOps(np.array(list(threshold)))\n",
    "import cv2\nimport numpy as np\n\ncam = cv2.VideoCapture('tcp://192.168.1.1:5555')\nif not cam.isOpened():\n    print(\"VideoCapture failed to open\")\n\nwhile True:\n    ret, frame = cam.read()\n\n    if ret == False:\n        print(\"frame empty\")\n        break\n\n    img_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n    ret, thresh = cv2.threshold(img_gray, 127, 255,0)\n    contours,hierarchy = cv2.findContours(thresh,2,1)\n    cnt = contours[0]\n\n    hull = cv2.convexHull(cnt,returnPoints = False)\n    defects = cv2.convexityDefects(cnt,hull)\n\n    for i in range(defects.shape[0]):\n        s,e,f,d = defects[i,0]\n        start = tuple(cnt[s][0])\n        end = tuple(cnt[e][0])\n        far = tuple(cnt[f][0])\n        cv2.line(img,start,end,[0,255,0],2)\n        cv2.circle(img,far,5,[0,0,255],-1)\n\n   cv2.imshow('img',frame)\n   cv2.waitKey(0)\n\ncv2.destroyAllWindows()\n",
    "cv2.resize(src = img, dsize = (height, width), interpolation = interpolation)\n\ncv2.resize(img, (height, width), interpolation = interpolation)\n",
    "In [85]: pd.DataFrame({'test':test.tolist(), 'test2':test2.tolist()})\nOut[85]: \n     test   test2\n0  [1, 2]  [2, 4]\n1  [2, 3]  [2, 5]\n",
    "In [36]: ll=range(100)\nIn [53]: a=ll[0:20]    \nIn [54]: b=ll[22:40]\nIn [55]: c=ll[42:60]\n\nIn [56]: len(list(itertools.chain(a,b,c)))\nOut[56]: 56\n\nIn [57]: np.array(list(itertools.chain(a,b,c)))\nOut[57]: \narray([ 0,  1,  2,  3,  4,  5,...., 59])\n\nIn [58]: np.fromiter(itertools.chain(a,b,c),int)\nOut[58]: \narray([ 0,  1,  2,  3,  4,  5, ... 58, 59])\n\nIn [59]: np.concatenate((a,b,c))\nOut[59]: \narray([ 0,  1,  2,  3,  4,  5, ... 52, 53, 54,\n       55, 56, 57, 58, 59])\n\nIn [62]: 10**(la/100.)\nOut[62]: \narray([ 1.        ,  1.02329299,  1.04712855,  1.07151931,  1.0964782 ,\n        1.12201845,  1.14815362,  1.17489755,  1.20226443,  1.23026877,\n        ...\n        3.4673685 ,  3.54813389,  3.63078055,  3.71535229,  3.80189396,\n        3.89045145])\n\n np.array((b1, b2, b3, b4, b5, b6))\n",
    "arr.reshape(36, 128, 512)\n\narr.reshape(128, 512, 36).transpose(2, 0, 1)\n\nnp.rollaxis(arr.reshape(128, 512, 36), -1)\n\narr = np.arange(128*512*4*9).reshape(128,512,4,9)\n\narr.reshape(128, 512, 36).transpose(2, 0, 1)\n\n>>> arr.reshape(128, 512, 36).transpose(2, 0, 1).shape\n(36, 128, 512)\n\nIn [61]: arr = np.arange(2*2*3*4).reshape(2,2,3,4)\n\nIn [62]: arr\nOut[62]: \narray([[[[ 0,  1,  2,  3],\n         [ 4,  5,  6,  7],\n         [ 8,  9, 10, 11]],\n\n        [[12, 13, 14, 15],\n         [16, 17, 18, 19],\n         [20, 21, 22, 23]]],\n\n\n       [[[24, 25, 26, 27],\n         [28, 29, 30, 31],\n         [32, 33, 34, 35]],\n\n        [[36, 37, 38, 39],\n         [40, 41, 42, 43],\n         [44, 45, 46, 47]]]])\n\nIn [70]: arr[0,0,...]\nOut[70]: \narray([[ 0,  1,  2,  3],\n       [ 4,  5,  6,  7],\n       [ 8,  9, 10, 11]])\n\nIn [66]: arr.reshape(12,2,2)[:,0,0]\nOut[66]: array([ 0,  4,  8, 12, 16, 20, 24, 28, 32, 36, 40, 44])\n\nIn [68]: arr.reshape(2,2,12).transpose(2, 0, 1)[:,0,0]\nOut[68]: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n",
    "import numpy as np\nimport matplotlib.pyplot as plt\n\ndef f(x):\n    return np.int(x)\nf2 = np.vectorize(f)\nx = np.arange(1, 15.1, 0.1)\nplt.plot(x, f2(x))\nplt.show()\n",
    "dataset = myset.replace(',','.', regex=True).values\n\ndataset = pd.read_csv('file', decimal=',')\n"
   ]
  },
  {
   "questions": [
    "Setting increasing numpy around defined diagonal: best create ( numpy array) , diagonal - remaining increasing , n. , n = array look : n = 4: etc. create array zeros diagonal - : = numpy.zeros((n,n)) numpy.fill_diagonal( ,- ) n = give: 's increasing numbers, shown ? Would iterate ? Or better approach ? advance.",
    "create 0x0 Numpy array?: create ( .e. ndim = , = ( , )) numpy.ndarray float?",
    "looking 3D version numpy.linalg.norm: 'm looking build- function . compute frobenius norm 3D array. current approach : too slow . ideas? advance...",
    "Create int & DateTime : create ( numpy array ) takes datetime objects types ? , : best create initialize ? far, using np.empty, np.zeros, comprehension, similar : , populate seem assign simpler :",
    "Setting numpy based multiple criteria: numpy array zero equivalent . Lets consider array multiple [ , , 8] . single element 's single integer. ?",
    "Filling array zeros numpy: last ? creating multidimensional array ? Output: creating copies, happening ? Output: understand filled zeros, specifying , third? Thank advance. Google, word questions.",
    "Create ( numpy.array) named ( numpy.array) [duplicate]: already answer here: name , construct type inside . ? numpy array? Desired",
    ": Fill Numpy Array triplets: lot database under ( , y, ) triplet form. create dynamically 2d numpy array setting coords ( ,y) array. instance : resulting array : 'm numpy, numpy ? , approach advice ?",
    "Numpy array change regions: looking replacing zones array, create b = numpy.zeros((12,12)). change its =numpy.aray([[ , ],[ , ]]) left upper corner indexed [ : , : ]. When specify b[ : , : ] = : 's thing ?",
    "Numpy optimization: function assigns depending condition. dataset usually range 30 50k. sure correct numpy 's 5k numbers, gets really slow. better faster ?"
   ],
   "code": [
    "def set_matrix(n):\n    out = np.full((n,n),-1)\n    off_diag_mask = ~np.eye(n,dtype=bool)\n    out[off_diag_mask] = np.arange(n*n-n)\n    return out\n\nIn [23]: set_matrix(3)\nOut[23]: \narray([[-1,  0,  1],\n       [ 2, -1,  3],\n       [ 4,  5, -1]])\n\nIn [24]: set_matrix(4)\nOut[24]: \narray([[-1,  0,  1,  2],\n       [ 3, -1,  4,  5],\n       [ 6,  7, -1,  8],\n       [ 9, 10, 11, -1]])\n",
    ">>> import numpy as NP\n>>> a = NP.empty( shape=(0, 0) )\n>>> a\n    array([], shape=(0, 0), dtype=float64)\n\n>>> a.shape\n    (0, 0)\n>>> a.size\n    0\n",
    "x = np.random.randn(100, 100, 100)\nprint np.allclose(np.linalg.norm(x), np.sqrt(np.sum(np.square(x))))\n# True\n",
    "In [17]: import numpy as np\n\nIn [18]: np.array([[[datetime.now(),np.zeros(2)] for x in range(10)]])\nOut[18]: \narray([[[datetime.datetime(2014, 8, 7, 23, 45, 12, 151489),\n         array([ 0.,  0.])],\n        [datetime.datetime(2014, 8, 7, 23, 45, 12, 151560),\n         array([ 0.,  0.])],\n        [datetime.datetime(2014, 8, 7, 23, 45, 12, 151595),\n         array([ 0.,  0.])],\n        [datetime.datetime(2014, 8, 7, 23, 45, 12, 151619),\n         array([ 0.,  0.])],\n        [datetime.datetime(2014, 8, 7, 23, 45, 12, 151634),\n         array([ 0.,  0.])],\n        [datetime.datetime(2014, 8, 7, 23, 45, 12, 151648),\n         array([ 0.,  0.])],\n        [datetime.datetime(2014, 8, 7, 23, 45, 12, 151662),\n         array([ 0.,  0.])],\n        [datetime.datetime(2014, 8, 7, 23, 45, 12, 151677),\n         array([ 0.,  0.])],\n        [datetime.datetime(2014, 8, 7, 23, 45, 12, 151691),\n         array([ 0.,  0.])],\n        [datetime.datetime(2014, 8, 7, 23, 45, 12, 151706),\n         array([ 0.,  0.])]]], dtype=object)\n",
    ">>> a = np.array([[1, 2, 3], [4, 8, 6], [7, 8, 9]])\n>>> np.in1d(a, [1, 2, 8])\narray([ True,  True, False, False,  True, False, False,  True, False], dtype=bool)\n>>> a[np.in1d(a, [1, 2, 8]).reshape(a.shape)] = 0\n>>> a\narray([[0, 0, 3],\n       [4, 0, 6],\n       [7, 0, 9]])\n",
    "  0---0\n /   /|\n0---0 0\n|   |/\n0---0\n\n0---0\n|   |\n0---0\n\n  0---0\n /   /\n0---0\n\n  0\n /|\n0 0\n|/\n0\n",
    "x = [1, 2, 3, 4]\nx += [5, 6]\n>>> [1, 2, 3, 4, 5, 6]\n\nx = np.array([1, 2, 3, 4])\nx = np.concatenate((x, np.array([5, 6])))\n>>> np.array([1, 2, 3, 4, 5, 6])\n",
    "import numpy as np\n\na = np.array([(0,0,8),(0,1,5),(0,2,3),\n              (1,0,4),(1,1,0),(1,2,0),\n              (2,0,1),(2,1,2),(2,2,5)])\n\n# Maximum Y and X coordinates\nymax = a[:, 0].max()\nxmax = a[:, 1].max()\n\n# Target array\ntarget = np.zeros((ymax+1, xmax+1), a.dtype)\n\ntarget[a[:, 0], a[:, 1]] = a[:, 2]\n\n>>> target\narray([[8, 5, 3],\n       [4, 0, 0],\n       [1, 2, 5]])\n\ndefault_value = -1\ntarget = np.full((ymax+1, xmax+1), default_value, a.type)\n",
    ">>> b[0:2,0:2] = a\n>>> b\narray([[ 1.,  2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n       [ 2.,  3.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])\n\n +---+---+---+---+---+\n | H | e | l | p | A |\n +---+---+---+---+---+\n 0   1   2   3   4   5\n-5  -4  -3  -2  -1\n",
    "matrix = np.random.randn(L,k+1)\n\nmatrix[matrix > value]\n"
   ]
  },
  {
   "questions": [
    "CSV text array NumPy?: Very coding write program CSV NumPy array . struggling perform operations CSV keep messages ( similar): 'm sure TextIOWrapper . !",
    "create array C++ similar 's numpy array?: converting program C++ format. array format. best create C++ functioning similar boxes array?",
    "Repeat array times (numpy): Let numpy array : cleaner produce array repeated times: Do think simpler ?",
    "Repeat array times (numpy): Let numpy array : cleaner produce array repeated times: Do think simpler ?",
    "Divide ndarray its own : numpy ndarray: vector operation divide ndarray ( 's own index + )? Result .",
    "sort numpy according its ?: numpy array : sort according its , descending order. : ?",
    "Find element numpy ndarray unknown : easy pull item ndarray array? . Given array: assuming array * *4. interested minimizing memory cpu requirements .",
    "normalize array NumPy?: norm NumPy array. More specifically, looking equivalent version function skearn numpy? function situation v vector.",
    "normalize array NumPy?: norm NumPy array. More specifically, looking equivalent version function skearn numpy? function situation v vector.",
    "Performing operations NumPy arrray masking along diagonal operations: perform operations nothing diagonal calculated diagonal avoid NaN , retained zero diagonal responses"
   ],
   "code": [
    "import numpy as np\ndata = np.genfromtxt('csvfile.csv', delimiter=',')\n\nimport pandas as pd\ndata = pd.read_csv('csvfile.csv')  # this creates a DataFrame\ndata_np = np.array(data)  # this creates a numpy array from the DataFrame\n",
    "#include <vector>\n#include <memory>\n#include <cstddef>\n#include <cstdio>\n\nclass NDArray {\n    std::vector<size_t> m_dims, m_strides;\n    std::unique_ptr<float[]> m_buf;\n\n    public:\n        NDArray(std::vector<size_t> dims):\n            m_dims{std::move(dims)}\n        {\n            m_strides.resize(m_dims.size());\n            size_t stride = 1;\n            for (int i = m_dims.size() - 1; i >= 0; -- i) {\n                m_strides[i] = stride;\n                stride *= m_dims[i];\n            }\n            m_buf.reset(new float[stride]);\n        }\n\n        float& operator[] (std::initializer_list<size_t> idx) {\n            size_t offset = 0;\n            auto stride = m_strides.begin();\n            for (auto i: idx) {\n                offset += i * *stride;\n                ++ stride;\n            }\n            return m_buf[offset];\n        }\n};\n\nint main() {\n    NDArray arr({2, 3});\n    arr[{1, 2}] = 3;\n    arr[{1, 1}] = 2;\n    printf(\"%g\\n\", arr[{1, 2}]);\n}\n",
    "In [1]: import numpy as np\n\nIn [2]: A = np.array([1, 2, 3, 4, 5])\n\nIn [3]: np.repeat(A,2)\nOut[3]: array([1, 1, 2, 2, 3, 3, 4, 4, 5, 5])\n",
    "In [1]: import numpy as np\n\nIn [2]: A = np.array([1, 2, 3, 4, 5])\n\nIn [3]: np.repeat(A,2)\nOut[3]: array([1, 1, 2, 2, 3, 3, 4, 4, 5, 5])\n",
    "myarray/(np.arange(myarray.shape[-1])+1)\n\nIn [244]: myarray\nOut[244]: \narray([[[ 1.,  2.,  3.],\n        [ 1.,  2.,  3.]],\n\n       [[ 4.,  5.,  6.],\n        [ 4.,  5.,  6.]]])\n\nIn [245]: myarray/(np.arange(myarray.shape[-1])+1)\nOut[245]: \narray([[[ 1. ,  1. ,  1. ],\n        [ 1. ,  1. ,  1. ]],\n\n       [[ 4. ,  2.5,  2. ],\n        [ 4. ,  2.5,  2. ]]])\n",
    "import numpy as np\narr[np.lexsort((-1*arr[:,1], arr[:,0]))]\n\narray([[1, 52.53, 1, 6],\n       [1, 52.52, 52, 2],\n       [1, 52.51, 12, 0],\n       [2, 52.53, 6, 33],\n       [2, 52.52, 75, 76],\n       [2, 52.51, 20, 0],\n       [3, 52.53, 0, 13],\n       [3, 52.52, 39, 68],\n       [3, 52.51, 84, 0],\n       [4, 52.51, 1, 0]], dtype=object)\n",
    "arr.ravel()[0]\n\nIn [15]: np.may_share_memory(arr.flatten(),arr)\nOut[15]: False # Not sharing memory means a copy\n\nIn [16]: np.may_share_memory(arr.ravel(),arr)\nOut[16]: True # Sharing memory means a view\n\nnp.take(arr,0) # Input array is arr, 0 is the index position\n",
    "import numpy as np\nfrom sklearn.preprocessing import normalize\n\nx = np.random.rand(1000)*10\nnorm1 = x / np.linalg.norm(x)\nnorm2 = normalize(x[:,np.newaxis], axis=0).ravel()\nprint np.all(norm1 == norm2)\n# True\n",
    "import numpy as np\nfrom sklearn.preprocessing import normalize\n\nx = np.random.rand(1000)*10\nnorm1 = x / np.linalg.norm(x)\nnorm2 = normalize(x[:,np.newaxis], axis=0).ravel()\nprint np.all(norm1 == norm2)\n# True\n",
    "import numpy as NP\nA = NP.random.random_integers(0, 9, 16).reshape(4, 4)\ndg = NP.r_[ [NP.nan] * 4 ]  # proper syntax is 'nan' not 'NaN'\ndg = NP.diag(dg)\nA += dg                     # a 4x4 array w/ NaNs down the main diagonal\nNP.sum(A, axis=1)           # doesn't work, gives: array([ NaN,  NaN,  NaN,  NaN])  \nfrom numpy import ma as MA\nAm = **MA.masked_invalid**(A)\nNP.sum(Am, axis=1)         # now it works (treats 'nan' as 0)\n\nNP.nan_to_num(A)\nMA.masked_equal(A, 0)\n\nMA.fix_invalid(A)\n"
   ]
  },
  {
   "questions": [
    "Specifying parameter ( ) multidimensional array certain ?: 've created program, figure define (outermost) function's parameter takes card numbers multidimensional array consists exactly 16 , ultimately stating either \"Valid\" \"Invalid\". stuff inside def validation( ) , 've tested before actually making said function, specify function [aka program basically ] takes multidimensional array 16 . 'm pretty sure lines regarding len( ) != 16 part , we wanted card [aka 16 digits] , wanted validation(([[ , , , ,4,5,6,7,8,9, , , , ,4,5],[ , , ,4,5,6,7,8,9, , , , ,4,5,6]]) 'm plagued : \"Card exactly 16 digits. Try again\" instead program properly running returning states Valid Invalid respective card",
    "Numpy: create lists: create , ( Numpy Pandas ideally): [[ , , , ,4,5],[ , , ,4,5],[ , ,4,5],[ ,4,5],[4,5],[5]]. Anyone idea quick achive ?"
   ],
   "code": [
    "assert np.all((x >= 0) & (x <= 9))\n\ndef validation(x):\n    x = np.asanyarray(x)\n    assert x.ndim == 2, \"input must be 2D\"\n    assert x.shape[1] == 16, \"input must have 16 columns\"\n    assert np.issubdtype(x.dtype, np.integer), \"input must be integers\"\n    assert np.all((x >= 0) & (x <= 9))\n    checkDig = x[:, -1]\n    xx = x[:, 1:-1:2] * 2\n    yy = x[:, :-1:2]\n    sumDig = np.sum(xx, axis=1) + np.sum(yy, axis=1) + checkDig\n    return ['Invalid' if s % 10 else 'Valid' for s in sumDig]\n\ndef validation(x):\n    x = np.array(x, copy=True, subok=True)\n    assert x.ndim == 2, \"input must be 2D\"\n    assert x.shape[1] == 16, \"input must have 16 columns\"\n    assert np.issubdtype(x.dtype, np.integer), \"input must be integers\"\n    assert np.all((x >= 0) & (x <= 9))\n    y = x[1:-1:2]\n    x[1:-1:2] = ((2 * y) // 10) + ((2 * y) % 10)\n    sumDig = np.sum(x, axis=1)\n    return ['Invalid' if s % 10 else 'Valid' for s in sumDig]\n",
    ">>> [range(i,6) for i in range(6)]\n[[0, 1, 2, 3, 4, 5], [1, 2, 3, 4, 5], [2, 3, 4, 5], [3, 4, 5], [4, 5], [5]]\n"
   ]
  },
  {
   "questions": [
    "Arbitrary N dimensional repeat N dimensional numpy array: Say N dimensional array Note N = 6, keep arbitrary discussion. Then perform multiple axis operations -- course subjectively -- problematically \"collapse\" ( described here ) dimensions along those computed. Say axes computation Thus tuple's length belongs [ ,N]. As might guessed, , say, np.mean its input. E.g. while homemade , follows incidentally der stands \"derived\". numpy builtin manner accomplish N dimensional repeat? Performance concerns, import timeit As expected ~ .5% slower hpaulj's.",
    "calculations numpy array: array filled ( ) zeros (rest ). pretty much MS excel using numpy, meaning put rest calculations based . MWE: expected : resulting : appreciated."
   ],
   "code": [
    "In [139]: shape=(2,3,4,5)\nIn [140]: x=np.arange(np.prod(shape)).reshape(shape)\nIn [141]: m=x.mean(axis=2, keepdims=True)\nIn [142]: m.shape\nOut[142]: (2, 3, 1, 5)\n\nIn [144]: m1=np.broadcast_to(m,shape)\nIn [145]: m1.shape\nOut[145]: (2, 3, 4, 5)\n\nIn [146]: m1.strides\nOut[146]: (120, 40, 0, 8)\n\nIn [148]: m2=np.repeat(m, shape[2], axis=2)\nIn [149]: m2.shape\nOut[149]: (2, 3, 4, 5)\nIn [150]: m2.strides\nOut[150]: (480, 160, 40, 8)\n",
    ">>> a = np.ones(20, dtype=np.int8).reshape(4,5)\n>>> a[:, 0] = b\n>>> a\narray([[1, 1, 1, 1, 1],\n       [2, 1, 1, 1, 1],\n       [3, 1, 1, 1, 1],\n       [4, 1, 1, 1, 1]], dtype=int8)\n>>> np.cumsum(a, axis=1)\narray([[1, 2, 3, 4, 5],\n       [2, 3, 4, 5, 6],\n       [3, 4, 5, 6, 7],\n       [4, 5, 6, 7, 8]])\n\n>>> a\narray([[1, 0, 0, 0, 0],\n       [2, 0, 0, 0, 0],\n       [3, 0, 0, 0, 0],\n       [4, 0, 0, 0, 0]], dtype=int8)\n\n>>> for column in a[:, 1:]:\n...   print(column)\n... \n[0 0 0 0]\n[0 0 0 0]\n[0 0 0 0]\n[0 0 0 0]\n\na[:, column] = column[0]+1\n\n>>> b = np.array([1, 2, 3, 4])\n>>> np.column_stack([b+i for i in range(5)])\narray([[1, 2, 3, 4, 5],\n       [2, 3, 4, 5, 6],\n       [3, 4, 5, 6, 7],\n       [4, 5, 6, 7, 8]])\n"
   ]
  },
  {
   "questions": [
    "Panel , variation according certain condition: stata user switch having codes. panel ( panel much bigger , illustrate ). calculate variation jobs quarter three year before look Check id year 2010 thir quarter calculation must made id present 2007Q2 2007Q3. stata , bys id: gen jobs_variation jobs/jobs[_n 12]- fecha[_n 12]==fecha 12",
    "Pandas Set Data indexes condition: Having trouble setting indexes condition . 's proper ? Also, , df.index serve purpose. Please assume represents DataFrame/Series. using .19.",
    "Plotting lengths: . One raw signal length (1000, ) smooth signal length (100,). visually represent smooth signal represents raw signal. Since length, . matplotlib? !",
    "solve equation variables : , solve equation z variables ( y having 50 , ). calculate : However calculate y's ; y's again , until 50 z, 50 . Then save 50 . fat calculating 50 z's 1st 1st y, 2nd 2nd y . ideas?",
    "calculate hamming distance 1d 2d : 1d array 100, B 2d array (50000, 100). calculate hamming distance B, X 50000. : 'd skip faster?",
    "Select last id panel np. : select last position id check variable fecha, variable assign year quarter, bigger 252, np."
   ],
   "code": [
    "df['jobs_variation'] = df.groupby(['id', 'quarter']).jobs\\\n                               .apply(lambda x: x / x.shift(3) - 1)\n\ndf\n\n    id  year  quarter  fecha  jobs  jobs_variation\n0    1  2007        1    220    10             NaN\n1    1  2007        2    221    12             NaN\n2    1  2007        3    222    12             NaN\n3    1  2007        4    223    12             NaN\n4    1  2008        1    224    12             NaN\n5    1  2008        2    225    13             NaN\n6    1  2008        3    226    14             NaN\n7    1  2008        4    227     9             NaN\n8    1  2009        1    228    12             NaN\n9    1  2009        2    229    15             NaN\n10   1  2009        3    230    18             NaN\n11   1  2009        4    231    15             NaN\n12   1  2010        1    232    15        0.500000\n13   1  2010        2    233    16        0.333333\n14   1  2010        3    234    17        0.416667\n15   1  2010        4    235    18        0.500000\n16   2  2007        1    220    10             NaN\n17   2  2007        4    223    12             NaN\n18   2  2008        1    224    12             NaN\n19   2  2008        2    225    13             NaN\n20   2  2008        3    226    14             NaN\n21   2  2008        4    227     9             NaN\n22   2  2009        1    228    12             NaN\n23   2  2009        2    229    15             NaN\n24   2  2009        3    230    18             NaN\n25   2  2009        4    231    15             NaN\n26   2  2010        1    232    15        0.500000\n27   2  2010        2    233    16             NaN\n28   2  2010        3    234    20             NaN\n29   2  2010        4    235    18        0.500000\n",
    "import pandas\n\ndf = pandas.DataFrame([{'val1': 30, 'val2': 20}, {'val1': 40, 'val2': 20}, \n                       {'val1': 50, 'val2': 10}])\nprint df\n\n   val1  val2\n0    30    20\n1    40    20\n2    50    10\n\n# Set data\nrow_selection = (df['val2'] == 20) & df.index.isin([1, 2])\ndf['val1'][row_selection] = 1\nprint df\n\n   val1  val2\n0    30    20\n1     1    20\n2    50    10\n",
    "x1 = np.linspace(0, 1, 1000)\nx2 = np.linspace(0, 1, 100)\n\nplt.plot(x1, raw)\nplt.plot(x2, smooth)\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nnp.random.seed(2015)\n\nraw = (np.random.random(1000) - 0.5).cumsum()\nsmooth = raw.reshape(-1,10).mean(axis=1)\n\nx1 = np.linspace(0, 1, 1000)\nx2 = np.linspace(0, 1, 100)\nplt.plot(x1, raw)\nplt.plot(x2, smooth)\nplt.show()\n",
    "for i in range(len(x)):\n    words = []\n    z = y-x[i]\n    words.append(str(x[i]))\n    words.append(\", \".join((str(_z) for _z in z)))\n    outfile.write(\": \".join(words))\n    outfile.write(\"\\n\")\n\nwords = []\nwords.append(str(x[i]) ...\n",
    "np.count_nonzero(A != B, axis=1)\n\nA = np.array([1,2])\nB = np.array([[1,2],[3,2],[1,3],[2,4]])\n\nnp.count_nonzero(A != B, axis=1)\n# array([0, 1, 1, 2])\n",
    "df.drop_duplicates(['id'],keep='last').fecha.gt(252)\nOut[213]: \n4     False\n9     False\n15    False\nName: fecha, dtype: bool\n\ndf['fechatest']=df.drop_duplicates(['id'],keep='last').fecha.gt(252)\ndf.fillna(False)\nOut[216]: \n    id     clae6  year  quarter  fecha  fecha_dif2  position  fechatest\n0    1  475230.0  2007        1    220          -1         1      False\n1    1  475230.0  2007        2    221          -1         2      False\n2    1  475230.0  2007        3    222          -1         3      False\n3    1  475230.0  2007        4    223          -1         4      False\n4    1  475230.0  2008        1    224          -1         5      False\n5    2  475230.0  2007        1    220          -1         1      False\n6    2  475230.0  2007        2    221          -1         2      False\n7    2  475230.0  2007        3    222          -1         3      False\n8    2  475230.0  2007        4    223          -1         4      False\n9    2  475230.0  2008        1    224          -1         5      False\n10   3  475230.0  2010        1    232          -1         1      False\n11   3  475230.0  2010        2    233          -1         2      False\n12   3  475230.0  2010        3    234          -1         3      False\n13   3  475230.0  2010        4    235          -1         4      False\n14   3  475230.0  2011        1    236          -1         5      False\n15   3  475230.0  2011        2    237          -1         6      False\n"
   ]
  },
  {
   "questions": [
    "Format Data Statsmodels Linear Regression: multivariate linear regression using Statsmodels , 've been having bit mental roadblock organize . default Boston dataset : linear regression model : raw space separated : been arrange here: Does anyone experience format similar Boston dataset easily preform regression model? instance, setting feature_names correspond . several lines raw reference:",
    "Elementwise elif function using : definition Now obviously perfectly feed b using loops, however takes forever ( 've simplified definition wee bit) experience passing array speed . modify accept . 've used () () commands must using wrong function spits rather array . An desired :",
    "LinearRegression Predict- ValueError: matrices aligned: 've been searching google 't figure 'm wrong. 'm pretty scikit stocks 'm \"ValueError: matrices aligned\" predict. 've nesting . Making array numpy. Anything google idea 'm here. mean why happening?",
    "multivariate linear regression inputs fitting: working machine learning project multivariate linear regression model here train.csv contains Col1,Col2,Expected contain input \"Col1\" \"Col2\" records while y putput \"Expected\" records . manged put input Col1 cannot put Col2 . save Col1 Col2 fitted linear regression later?",
    "create Linear Regression Model split dataset?: 've split training testing plan train Linear Regression model check performance using testing split. current : proper using Linear Regression model external .csv?"
   ],
   "code": [
    "import pandas as pd\nimport statsmodels.api as sm\n\ndf = pd.read_csv('data.txt', sep='\\s+', thousands=',')\nX = df.loc[:, 'cycles':'page-faults']\ny = df['Power']\nmodel = sm.OLS(y, X).fit()\n\nOLS Regression Results                            \n==============================================================================\nDep. Variable:                  Power   R-squared:                       0.972\nModel:                            OLS   Adj. R-squared:                  0.932\nMethod:                 Least Squares   F-statistic:                     24.56\nDate:                Fri, 10 Nov 2017   Prob (F-statistic):            0.00139\nTime:                        22:09:47   Log-Likelihood:                -21.470\nNo. Observations:                  12   AIC:                             56.94\nDf Residuals:                       5   BIC:                             60.33\nDf Model:                           7                                         \nCovariance Type:            nonrobust                                         \n====================================================================================\n                       coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------------\ncycles            1.287e-07   5.11e-08      2.518      0.053   -2.66e-09     2.6e-07\ninstructions     -7.083e-09   4.21e-07     -0.017      0.987   -1.09e-06    1.07e-06\ncache-references -1.625e-06   2.48e-06     -0.656      0.541   -7.99e-06    4.74e-06\ncache-misses      3.222e-06   5.24e-06      0.615      0.566   -1.03e-05    1.67e-05\nbranches          1.281e-07    2.6e-06      0.049      0.963   -6.55e-06    6.81e-06\nbranch-misses    -1.625e-05    1.2e-05     -1.357      0.233    -4.7e-05    1.45e-05\npage-faults          0.0016      0.002      0.924      0.398      -0.003       0.006\n==============================================================================\nOmnibus:                        2.485   Durbin-Watson:                   1.641\nProb(Omnibus):                  0.289   Jarque-Bera (JB):                0.787\nSkew:                           0.606   Prob(JB):                        0.675\nKurtosis:                       3.326   Cond. No.                     1.92e+06\n==============================================================================\n\nWarnings:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The condition number is large, 1.92e+06. This might indicate that there are\nstrong multicollinearity or other numerical problems.'\n",
    "def myfunc(a, b):\n    return np.where(a < b*10, a*2, -a)    \n\nIn [48]: a = np.array([1, 5, 50, 500])\n\nIn [49]: b = 1\n\nIn [50]: myfunc(a, b)\nOut[50]: array([   2,   10,  -50, -500])\n\ndef myfunc(a, b):\n    return np.where(a > b*10, a*2, -a)\n\nIn [52]: myfunc(a, b)\nOut[52]: array([  -1,   -5,  100, 1000])\n",
    "In [19]:\n\nM=model.fit(close[0][:-1].reshape(-1,1), close[0][1:].reshape(-1,1))\nIn [31]:\n\nM.predict(close[0][-20:].reshape(-1,1))\nOut[31]:\narray([[ 90.92224274],\n       [ 94.41875811],\n       [ 93.19997275],\n       [ 94.21895723],\n       [ 94.31885767],\n       [ 93.030142  ],\n       [ 90.76240203],\n       [ 91.29187436],\n       [ 92.41075928],\n       [ 89.0940647 ],\n       [ 85.10803717],\n       [ 86.90624508],\n       [ 89.39376602],\n       [ 90.59257129],\n       [ 91.27189427],\n       [ 91.02214318],\n       [ 92.86031126],\n       [ 94.25891741],\n       [ 94.45871828],\n       [ 92.65052033]])\n",
    "x = data[['Col1', 'Col2']]\n",
    "from sklearn.linear_model import LinearRegression\n\nmodel = LinearRegression()\n\nX_train, y_train = training_set[x_vars], training_set[y_var]\nX_test, y_test = testing_test[x_vars], testing_test[y_var]\n\nmodel.fit(X_train, y_train)\n\npredictions = model.predict(X_test)\n"
   ]
  },
  {
   "questions": [
    "Taking logarithm : Im quite programming ( ) create variable logarithm ( imported excel ). solutions site, keep . latest AttributeError: 'str' object attribute 'log'. already dropped \"numbers', still strings integers ( case, 'int(neighborhood)' ). now: 'm : Could someone please?",
    "AttributeError: 'OLSResults' object attribute 'norm_resid': When : latest version OLS, attribute norm_resid . ideas ?",
    "AttributeError: 'module' object attribute 'lowercase': think 'm having troubles importing pylab. similar occurs import numpy. syntax? 'm using python2.7 fedora18.",
    ": AttributeError: 'mpc' ( 'mpf') object attribute 'arcsin': Jacobi elliptical function mpmath, below: even pass real part function sn( .5,- ). whether making mistake. Kindly . advance.",
    "\u201cAttributeError: ' ' object attribute 'ravel'\u201d: system differential equations calculate Jacobian. below throws AttributeError: ' ' object attribute 'ravel'. missing?",
    "AttributeError: 'tuple' object attribute ' ': been writing standardize matrix function used follows: well outside class used inside : idea fix ?? P.S. KNN classification",
    "AttributeError object attribute add: machine learning using . scenario reading sql give MLP training. below: During debug query got : (6, , , , , u'F', , , , 19) Can anyone , fix give X_train, MLP accept input ?",
    "\u201cAttributeError: 'matrix' object attribute 'isocalendar'\u201d numpy : numpy matrix : matrix matrix involves week numbers instead dates. \"isocalendar()\" function , week date. used function ; : right converting date matrix datenumber matrix numpy ?",
    "Attribute float object attribute 'append': open LAS files change save LAS . las contains coordinates (X Y) ( Z elevation). Unfortunately put saving part , below, got : far array save las end :",
    "\u201cAttributeError: 'matrix' object attribute 'strftime'\u201d numpy : matrix (72000, ) dimension. matrix involves timestamps. \"strftime\" ; strftime(\"%d/%m/%y\"), order : '11/03/02'. matrix: used \"strftime\" order matrix involving timestamps matrix involving dates string types. reason, used \"strftime\" follwing: When , : right using function? timestamp matrix date string matrix?"
   ],
   "code": [
    ">>> raw_data = {'m_woz': ['abc', 'def', 1.23, 45.6, '.xyz'], \n    'recs': ['Neighborhood', 'Neighborhood', \n    'unknown', 'Neighborhood', 'whatever']}\n>>> df = pd.DataFrame(raw_data, columns = ['m_woz', 'recs'])\n>>> print(df.dtypes)\nm_woz    object\nrecs     object\ndtype: object\n\n>>> df\n  m_woz          recs\n0    42  Neighborhood\n1   def  Neighborhood\n2  1.23       unknown\n3  45.6  Neighborhood\n4  .xyz      whatever\n\n>>> neighborhood=df[df.recs==\"Neighborhood\"]\n>>> neighborhood\n\n  m_woz          recs\n0    42  Neighborhood\n1   def  Neighborhood\n3  45.6  Neighborhood\n\n>>> df_num_strings = neighborhood[neighborhood['m_woz'].\n        apply(lambda x: type(x) in (int, float))]\n\n>>> df_num_strings\n  m_woz          recs\n0    42  Neighborhood\n3  45.6  Neighborhood\n\n>>> df_float = df_num_strings['m_woz'].astype(str).astype(float)\n>>> df_float\n0    42.0\n3    45.6\n\n>>> np.log(df_float)\n0    3.737670\n3    3.819908\nName: m_woz, dtype: float64\n",
    "from scipy import stats\nfrom pandas import Series, DataFrame\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pylab as plt\nfrom sklearn import datasets, linear_model\nfrom statsmodels.formula.api import ols\n\"\"\"\nData Management\n\"\"\"\ndata = pd.read_csv(\"TestExer1-sales-round1.csv\")\nX_train = data[\"Advertising\"]\nY_train  = data[\"Sales\"]\n\n\n# use of linregregress\nmodel = ols(\"Y_train ~ X_train\", data).fit()\nprint(model.summary()) \n\nplt.plot(X_train,Y_train , 'ro')\nplt.plot(X_train, model.fittedvalues, 'b')\nplt.legend(['Sales', 'Advertising'])\nplt.ylim(0, 70)\nplt.xlim(5, 18)\nplt.hist(model.resid_pearson)\nplt.ylabel('Count')\nplt.xlabel('Normalized residuals')\n\nplt.xlabel('Temperature')\nplt.ylabel('Gas')\nplt.title('Before Insulation')\n",
    ">>> print string\n<module 'string' from '/usr/lib/python2.7/string.pyc'>\n",
    "In [10]: class Foo:\n    ...:     pass\n    ...: \n\nIn [11]: f = Foo()\n\nIn [12]: np.arcsin(f)\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\n<ipython-input-12-aa4b1a80cd4e> in <module>()\n----> 1 np.arcsin(f)\n\nAttributeError: Foo instance has no attribute 'arcsin'\n\nIn [6]: import mpmath\n\nIn [7]: y = sn(0.5, -1)\n\nIn [8]: mpmath.asin(y)\nOut[8]: mpc(real='0.52001273608158616', imag='0.0')\n\nIn [19]: y\nOut[19]: mpc(real='0.49689119041931196', imag='0.0')\n\nIn [20]: np.arcsin(float(y.real))\nOut[20]: 0.52001273608158627\n\nIn [21]: np.arcsin(complex(y))\nOut[21]: (0.52001273608158616+0j)\n\nIn [25]: import math\n\nIn [26]: math.asin(y.real)\nOut[26]: 0.5200127360815863\n",
    "return np.array([xdot, ydot])\n",
    "preprocess(numpy.array(Data))\n",
    "X_train = []\n\nfor row in cur:\n    X_train.append(row)\n\nX_train = list(cur)\n\nX_train = [[x for x in r if type(x)==int] for r in cur]\n\n[[ 6  1  1  1  2  1  0  0 19]\n [ 6  1  1  1  2  1  0  0 14]]\n",
    "df = pd.DataFrame(dates)\n\ndf[0] = pd.to_datetime(df[0])\n\ndf = df[0].apply(lambda x: x.isocalendar()[1])\n\n0    36\n1    40\n2    44\nName: 0, dtype: int64\n",
    "p=0.1\n\nimport numpy as p\n",
    "np.apply_along_axis((lambda x:[x[0].strftime(\"%d/%m/%y\")]),1,M)\n\nIn [58]: M = np.matrix([[datetime.datetime.now()]*5]).T\n\nIn [59]: M.shape\nOut[59]: (5, 1)\n\nIn [60]: np.apply_along_axis((lambda x:[x[0].strftime(\"%d/%m/%y\")]),1,M)\nOut[60]:\narray([['10/10/15'],\n       ['10/10/15'],\n       ['10/10/15'],\n       ['10/10/15'],\n       ['10/10/15']],\n      dtype='<U8')\n\nnp.apply_along_axis((lambda x:[datetime.datetime.fromtimestamp(x[0]).strftime(\"%d/%m/%y\")]),1,M)\n"
   ]
  },
  {
   "questions": [
    "Numpy Finding complex conjugate [duplicate]: already answer here: compute complex conjugate, array complex ? consisting imaginary using fast Fourier transform (fft.fft) complex conjugate element. thinking extracting imaginary bits using nparray.imag, creates \"j\" denote imaginary. appreciated.",
    "Numpy indexing [duplicate]: already answer here: deal, array bool type look . sets numpy.ndarrays unhashable types. New matrix look advance.",
    "Numpy Array Subtraction [duplicate]: already answer here: go comparing numpy create third array? write goes prints array \"c\" b say print:",
    "Numpy integer nan [duplicate]: already answer here: store NaN Numpy array integers? :",
    "Finding indexes matching numpy [duplicate]: already answer here: indexes match exactly numpy . : :",
    ": Find positive respect [duplicate]: already answer here: Let's say below : positive element o[ ] ? , looking - .14048125 most \"positive\" respect . via ?",
    "Replace element numpy using condition [duplicate]: already answer here: , array : replace b greater otherwise ? didn't .",
    "Rounding issue [duplicate]: already answer here: input : Why isn't \"success\" printed?",
    "decimals [duplicate]: already answer here: tell perform ( ) aritmetics rounding results (always) decimals?",
    "Numpy import CSV float [duplicate]: already answer here: ok, numpy loaded CSV , : array float 'm having solve numpy ?"
   ],
   "code": [
    "arr.conj()\n",
    "[[True if val in idx_arr else False for val in row] for row in tgt_arr]\n\n[[True, True, True, True, True, False, False],\n[False, False, True, False, False, True, True],\n[False, False, False, False, False, False, False]]\n",
    ">>> a = np.array([1, 2, 3, 2, 4, 1])\n>>> b = np.array([3, 4, 5, 6])\n>>> np.setdiff1d(a, b)\narray([1, 2])\n",
    "a = np.ma.array([1,2,3,4,5], dtype=int)\na[1] = np.ma.masked\nmasked_array(data = [1 -- 3 4 5],\n             mask = [False  True False False False],\n       fill_value = 999999)\n",
    "np.flatnonzero((x == y).all(1))\n# array([0, 2])\n\nnp.nonzero((x == y).all(1))[0]\n\nnp.where((x == y).all(1))[0]\n",
    ">>> o =[-0.90405713,-0.86583093,-0.14048125,3]\n>>> min(o, key=abs)\n-0.14048125\n",
    "x = np.arange(-5, 4).reshape(3, 3)\nx\n#array([[-5, -4, -3],\n#       [-2, -1,  0],\n#       [ 1,  2,  3]])\n\nb = 1; a = 0;\nnp.where(x > a, b, 0)\n#array([[0, 0, 0],\n#       [0, 0, 0],\n#       [1, 1, 1]])\n",
    "In [13]: a = np.sum([0.29, 0.59, 0.12])\n\nIn [14]: a\nOut[14]: 0.99999999999999989\n\nIn [15]: print a\n1.0\n\nIn [20]: 0.29 + 0.59\nOut[20]: 0.8799999999999999\n\nIn [22]: if round(a,1) == 1.0:\n   ....:     print('success')\n   ....:\nsuccess\n",
    "num=1.2356\nprint round(num,3)\n## Use round function and pass number of decimal places upto which you want to round\n",
    ">>> a[a=='']='0'\n>>> a2 = a.astype(np.float)\n"
   ]
  },
  {
   "questions": [
    "change range -axis datetimes MatPlotLib?: 'm graph dates -axis y axis. fine, except 't range -axis appropriate. -axis range always Jan 2012 Jan 2016, despite dates being today. even specifying xlim last date. 'm writing -django, 's relevant. here :",
    "converters numpy change string : 'm using np.loadtxt, containing 13 39 58.495, seconds. below. returns form 735927.56942703, 'm sure units terms , hours minutes... format seconds.",
    "put od dataframe 2d matrix?: dataframe , row_index, column_index. create matrix, dataframe placed relevant unknown zeros. made -cycle : slow. faster?",
    "Fitting Gaussian histogram MatPlotLib Numpy - wrong Y scaling?: written below fit Gaussian curve histogram. , although Y scaling . wrong? !",
    "exactly ?: When , expected 10 images dimensions 100x100: change arguments reshape (200, 200), recieve : ValueError: total must unchanged Why happen? Why wasn't 200x200 returned?",
    "Numpy - easier change array ?: 'd D array, staying , varying linspace. , little bulky: better ?",
    "Proper optimization calculation: Trying optimize piece numpy, wondering right approach. formula computation , matrix being lower triangular. here attempt: good efficient ?",
    "Change based range ?: dataset : change date 2016 01 06 2016 01 10 based range index( case). ? !",
    "distinguish numpy FloatingPointError exceptions?: 'm really familiar exceptions , 'm sort here. There FloatingPointError exceptions numpy: define / operation program, differ exceptions. : guess simply comparing . ?",
    "change color channel using numpy?: color channels pixels zero (ie 255, 146, ). change equal zero array , access . ? array:"
   ],
   "code": [
    "import datetime\nimport matplotlib.pyplot as plt\n\nx = [datetime.date(2014, 1, 29), datetime.date(2014, 1, 29), datetime.date(2014, 1, 29)] \ny = [2, 4, 1]\n\nfig, ax = plt.subplots()\nax.plot_date(x, y, markerfacecolor='CornflowerBlue', markeredgecolor='white')\nfig.autofmt_xdate()\nax.set_xlim([datetime.date(2014, 1, 26), datetime.date(2014, 2, 1)])\nax.set_ylim([0, 5])\n",
    "from datetime import datetime\n\nclass SecondsSinceFirst:\n    def __init__(self, default=float('nan')):\n        self.first = None\n        self.default = default\n    def __call__(self, value):\n        value = value.decode('ascii', 'ignore').strip()\n        if not value:  # no value\n            return self.default\n        try:  # specify input format here\n            current = datetime.strptime(value, \"%H:%M:%S.%f\")\n        except ValueError:  # can't parse the value\n            return self.default\n        else:\n            if self.first is not None: \n                return (current - self.first).total_seconds()\n            else:\n                self.first = current\n                return 0.0\n\n>>> from io import BytesIO\n>>> import numpy\n>>> f = BytesIO(b\"12:00:00.0 1 2\\n12:30:00.0 3 4\\n13:39:58.495 5 6\")\n>>> time, W, L = numpy.loadtxt(f, converters={0: SecondsSinceFirst()}, unpack=True)\n>>> time\n array([    0.   ,  1800.   ,  5998.495]\n",
    "df = pd.DataFrame({'value':[2,4,5],\n                   'row_index':[2,3,4],\n                   'col_index':[0,2,3]})\n\nprint (df)\n   col_index  row_index  value\n0          0          2      2\n1          2          3      4\n2          3          4      5\n\nrows = np.arange(df.row_index.max()+1)\ncols = np.arange(df.col_index.max()+1)\n\nprint (df.pivot('row_index', 'col_index', 'value')\n         .fillna(0)\n         .reindex(index=rows, columns=cols, fill_value=0))\ncol_index    0    1    2    3\nrow_index                    \n0          0.0  0.0  0.0  0.0\n1          0.0  0.0  0.0  0.0\n2          2.0  0.0  0.0  0.0\n3          0.0  0.0  4.0  0.0\n4          0.0  0.0  0.0  5.0\n\na = df.pivot('row_index', 'col_index', 'value')\n      .fillna(0)\n      .reindex(index=rows, columns=cols, fill_value=0)\n      .values\nprint (a)\n[[ 0.  0.  0.  0.]\n [ 0.  0.  0.  0.]\n [ 2.  0.  0.  0.]\n [ 0.  0.  4.  0.]\n [ 0.  0.  0.  5.]]\n\nprint (df.set_index(['row_index', 'col_index'])['value']\n         .unstack(fill_value=0)\n         .reindex(index=rows, columns=cols, fill_value=0))\n\ncol_index  0  1  2  3\nrow_index            \n0          0  0  0  0\n1          0  0  0  0\n2          2  0  0  0\n3          0  0  4  0\n4          0  0  0  5\n\n\na = df.set_index(['row_index', 'col_index'])['value']\n      .unstack(fill_value=0)\n      .reindex(index=rows, columns=cols, fill_value=0)\n      .values\nprint (a)\n [[0 0 0 0]\n [0 0 0 0]\n [2 0 0 0]\n [0 0 4 0]\n [0 0 0 5]]\n",
    "import matplotlib.pyplot as plt\nimport numpy as np\nimport matplotlib.mlab as mlab\n\narr = np.random.randn(100)\n\nplt.figure(1)\nplt.hist(arr, normed=True)\nplt.xlim((min(arr), max(arr)))\n\nmean = np.mean(arr)\nvariance = np.var(arr)\nsigma = np.sqrt(variance)\nx = np.linspace(min(arr), max(arr), 100)\nplt.plot(x, mlab.normpdf(x, mean, sigma))\n\nplt.show()\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport matplotlib.mlab as mlab\n\narr = np.random.randn(1000)\n\nplt.figure(1)\nresult = plt.hist(arr)\nplt.xlim((min(arr), max(arr)))\n\nmean = np.mean(arr)\nvariance = np.var(arr)\nsigma = np.sqrt(variance)\nx = np.linspace(min(arr), max(arr), 100)\ndx = result[1][1] - result[1][0]\nscale = len(arr)*dx\nplt.plot(x, mlab.normpdf(x, mean, sigma)*scale)\n\nplt.show()\n",
    "im = np.random.random_integers(0, 255, 40000).reshape((200, 200))\n",
    "x = np.empty((21, 2))\nx[:, 0] = 45\nx[:, 1] = np.linspace(55, 65, x.shape[0])\n",
    "np.einsum('ij,ij',t[:,None]-t, P)\n\nIn [414]: N = 5000\n     ...: P = np.random.rand(N,N)\n     ...: t = np.random.rand(N)\n     ...: out = (np.sum(P) - np.trace(P)) / np.sum(((t[np.newaxis]).T - t) * P)\n     ...: \n\n# Original method    \nIn [415]: den1 = np.sum(((t[np.newaxis]).T - t) * P)\n\n# Proposed method    \nIn [416]: den2 = np.einsum('ij,ij',t[:,None]-t, P)\n\nIn [417]: np.allclose(den1, den2)\nOut[417]: True\n\nIn [419]: %timeit np.sum(((t[np.newaxis]).T - t) *P)\n10 loops, best of 3: 86.9 ms per loop\n\nIn [420]: %timeit np.einsum('ij,ij',t[:,None]-t, P)\n10 loops, best of 3: 49.7 ms per loop\n\nIn [422]: %timeit (np.sum(P) - np.trace(P))\n100 loops, best of 3: 10.4 ms per loop\n\nIn [423]: %timeit np.sum(P)\n100 loops, best of 3: 10.4 ms per loop\n",
    "In [354]: df.loc[df.index.isin([1, 2]), 'date'] = '2016-01-10'\n\nIn [355]: df\nOut[355]: \n   index  _id  first    last        date\n0      0   11   John     Doe  2016-01-01\n1      1   12   Jane     Doe  2016-01-10\n2      2   13   Jack  Hammer  2016-01-10\n3      3   14  Peter     Dex  2016-01-10\n\ndf.loc[df.index.isin(range(1, 3)), 'date'] = '2016-01-10'\n",
    "class InvalidValueError(Exception): pass\nclass DivideByZeroError(Exception): pass\n\ndef err_handler(err, flag):\n    if flag == 8:\n        raise InvalidValueError(err)\n    if flag == 1:\n        raise DivideByZeroError(err)\n\nnp.seterrcall(err_handler)\nnp.seterr(divide='call', invalid='call')\n\ntry:\n    np.float64(0.0) / np.float64(0.0)\n    # or `np.float64(1.0) / np.float64(0.0)`\nexcept InvalidValueError:\n    # TODO\nexcept DivideByZeroError:\n    # TODO\n",
    "img[(img==zero_val).all(-1)] = new_val\n\n# Random image array\nIn [112]: img = np.random.randint(0,255,(4,5,3))\n\n# Define sample zero valued and new valued arrays\nIn [113]: zero_val = [255,146,0]\n     ...: new_val = [255,255,255]\n     ...: \n\n# Set two random points/pixels to be zero valued\nIn [114]: img[0,2] = zero_val\n\nIn [115]: img[2,3] = zero_val\n\n# Use proposed approach\nIn [116]: img[(img==zero_val).all(-1)] = new_val\n\n# Verify that new values have been assigned\nIn [117]: img[0,2]\nOut[117]: array([255, 255, 255])\n\nIn [118]: img[2,3]\nOut[118]: array([255, 255, 255])\n"
   ]
  },
  {
   "questions": [
    "Plot straight best fit log log : Have 've plotted log log now fit straight . various methods 't 'm after. Example : ideal 'straight' log log offset random fit 1d poly. : ignoring offset, deal , quite require basically plotted straight point joined whereas ' best fit' middle measure gradient . best achieve ?",
    "Dict inside dict excel export: save dict excel( 've xlsxwriter). Example: Mod1 Column ( excel) ' ' scores. follow, think must add . ideas ? Thank !",
    "- Translating best fit log : 'm best fit linear regression huge loglog . giving graph 've thought y intercept automatically. seem case. translate correct intercept?",
    "Numpy flatten RGB array: ,000 RGB images (64X64) (m, n) array. : Which : (1000, 64, 64, ) Now : : (12288000,) However, require array dimensions: (1000, 12288) achieve ?",
    "Reformat table : table script numpy : reshape format : To honest, 'm quite confused parentheses. , ] , right? ( , ), ?",
    "possibility define dtype once ?: type (eg. Float), possibility dtype defined once, ? Example: We automatically generate names?",
    "Interpolation PyLab: , y coordinates function. Example: pylab. ( ,y) shows smooth function . -Value y ? regards",
    ": . : : found numpy library needed. however change . Who ?",
    ": type( ) int\u2026 int = False: 'm quite sure 'm foolish 't figure . Now wrapping fn_abc int wrong?",
    "Create array element stores its : create 2d numpy array element tuple its . Example (4x5): create comprehension: faster achieve , maybe numpy methods?"
   ],
   "code": [
    "y_fit = polynomial(y)\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random\n\n\nx = np.linspace(1,100,10)\ny = np.log10(x) + np.log10(np.random.uniform(0,10))\n\ncoefficients = np.polyfit(np.log10(x), np.log10(y), 1)\npolynomial = np.poly1d(coefficients)\nlog10_y_fit = polynomial(np.log10(x))  # <-- Changed\n\nplt.plot(x, y, 'o-')\nplt.plot(x, 10**log10_y_fit, '*-')     # <-- Changed\nplt.yscale('log')\nplt.xscale('log')\n",
    "import xlsxwriter\n\nworkbook = xlsxwriter.Workbook('test.xlsx')\nworksheet = workbook.add_worksheet()\n\nrow = 0\ncol = 0\n\nranks = {'Mod1': {'A': 0.029999999999999999,\n                  'B': 0.050000000000000003,\n                  'C': 0.14000000000000001},\n         'Mod2': {'A': 1.029999999999999999,\n                  'B': 1.050000000000000003,\n                  'C': 1.14000000000000001}}\n\nfor model in ranks.keys():\n    worksheet.write(row, col, model)\n    row += 1\n\n    for key, value in ranks[model].items():\n        worksheet.write(row, col + 1, key)\n        worksheet.write(row, col + 2, value)\n        row += 1\n\nworkbook.close()\n\n    for category in sorted(ranks[model].keys()):\n        worksheet.write(row, col + 1, category)\n        worksheet.write(row, col + 2, ranks[model][category])\n        row += 1\n",
    "predict_logy = intercept + slope * logx\n",
    "d1, d2, d3, d4 = x_data.shape\n\nx_data_reshaped = x_data.reshape((d1, d2*d3*4))\n",
    "import numpy as np\n\na = [\n    np.array([[1, 2, 3], [4, 5, 6]]),\n    np.array([10, 11, 12, 13, 14])\n    ]\nprint(a)\n\nb = (\n    np.expand_dims(a[1], axis=1),\n    np.expand_dims(a[0].flatten(), axis=1)\n    )\n\nprint(b)\n",
    "In [126]: np.zeros((3,),np.dtype(','.join(['<f8']*4)))\nOut[126]: \narray([(0.0, 0.0, 0.0, 0.0), (0.0, 0.0, 0.0, 0.0), (0.0, 0.0, 0.0, 0.0)], \n      dtype=[('f0', '<f8'), ('f1', '<f8'), ('f2', '<f8'), ('f3', '<f8')])\n\nnp.dtype([('field_%d'%i, '<f8') for i in range(4)])\n\nnp.dtype({'formats':['f8']*4, 'names':['f%s'%i for i in range(4)]})\n\nnp.format_parser(['f8']*4,[],[]).dtype  # auto generate names\n",
    "numpy.interp(3.,y,x)  #1.5\n",
    "abc = [[x] for x in abc]\n",
    "isinstance(predict, int)\n",
    "np.moveaxis(np.indices((4,5)), 0, -1)\n\ndims = tuple(np.multiply.reduceat(np.zeros(16,int)+2, np.r_[0, np.sort(np.random.choice(16, np.random.randint(10)))]))\n# len(dims) == ?\nnp.moveaxis(np.indices(dims), 0, -1) # works\n"
   ]
  },
  {
   "questions": [
    "Index Numpy array lists : 've got strange situation. Numpy array, : indexers-- , . order index X, having : Instead : ( fails : , cannot broadcast (20,) ( ,)) 'd indexing using broadcasting, since keep clean readable... , much under hood, understand , faster ( 'll working pretty big ). Test Case:",
    "Index Numpy array lists : 've got strange situation. Numpy array, : indexers-- , . order index X, having : Instead : ( fails : , cannot broadcast (20,) ( ,)) 'd indexing using broadcasting, since keep clean readable... , much under hood, understand , faster ( 'll working pretty big ). Test Case:",
    "Index Numpy array lists : 've got strange situation. Numpy array, : indexers-- , . order index X, having : Instead : ( fails : , cannot broadcast (20,) ( ,)) 'd indexing using broadcasting, since keep clean readable... , much under hood, understand , faster ( 'll working pretty big ). Test Case:",
    "Index Numpy array lists : 've got strange situation. Numpy array, : indexers-- , . order index X, having : Instead : ( fails : , cannot broadcast (20,) ( ,)) 'd indexing using broadcasting, since keep clean readable... , much under hood, understand , faster ( 'll working pretty big ). Test Case:",
    "Average zero numpy array: 've got numpy array : expected put replace average their neighbours. hints welcome! Many thanks!",
    "numpy array numpy : 've got creating numpy array numpy . create : Desired : Real : ? final dimension array, 't initialize fixed dimension.",
    "Numpy array: assignment fails: snippet: basic idea : b, element found both , 'll assign score element scoreA scoreB. : means : working properly? resolve ?",
    "numpy array: replace nan average : 've got numpy filled mostly real numbers, few nan well. replace nans averages they ?",
    "Numpy array Table: 've got 18x18 2d numpy array ( 's confusion matrix)... / display table ipython notebook. When simply print , displays overlap-- long they take lines. library allow print array sort spreadsheet format?",
    "Indexing numpy array numpy array: Suppose 'd b index , [b] 4 instead [[ , 4], [ , 4]] probably better ?"
   ],
   "code": [
    "x_indexed = x[np.ix_(row_indices,col_indices)]\n\nIn [221]: x\nOut[221]: \narray([[17, 39, 88, 14, 73, 58, 17, 78],\n       [88, 92, 46, 67, 44, 81, 17, 67],\n       [31, 70, 47, 90, 52, 15, 24, 22],\n       [19, 59, 98, 19, 52, 95, 88, 65],\n       [85, 76, 56, 72, 43, 79, 53, 37],\n       [74, 46, 95, 27, 81, 97, 93, 69],\n       [49, 46, 12, 83, 15, 63, 20, 79]])\n\nIn [222]: row_indices\nOut[222]: [4, 2, 5, 4, 1]\n\nIn [223]: col_indices\nOut[223]: [1, 2]\n\nIn [224]: np.ix_(row_indices,col_indices) # Broadcasting of indices\nOut[224]: \n(array([[4],\n        [2],\n        [5],\n        [4],\n        [1]]), array([[1, 2]]))\n\nIn [225]: x[np.ix_(row_indices,col_indices)]\nOut[225]: \narray([[76, 56],\n       [70, 47],\n       [46, 95],\n       [76, 56],\n       [92, 46]])\n\nIn [227]: x[np.array(row_indices)[:,None],col_indices]\nOut[227]: \narray([[76, 56],\n       [70, 47],\n       [46, 95],\n       [76, 56],\n       [92, 46]])\n",
    "x_indexed = x[np.ix_(row_indices,col_indices)]\n\nIn [221]: x\nOut[221]: \narray([[17, 39, 88, 14, 73, 58, 17, 78],\n       [88, 92, 46, 67, 44, 81, 17, 67],\n       [31, 70, 47, 90, 52, 15, 24, 22],\n       [19, 59, 98, 19, 52, 95, 88, 65],\n       [85, 76, 56, 72, 43, 79, 53, 37],\n       [74, 46, 95, 27, 81, 97, 93, 69],\n       [49, 46, 12, 83, 15, 63, 20, 79]])\n\nIn [222]: row_indices\nOut[222]: [4, 2, 5, 4, 1]\n\nIn [223]: col_indices\nOut[223]: [1, 2]\n\nIn [224]: np.ix_(row_indices,col_indices) # Broadcasting of indices\nOut[224]: \n(array([[4],\n        [2],\n        [5],\n        [4],\n        [1]]), array([[1, 2]]))\n\nIn [225]: x[np.ix_(row_indices,col_indices)]\nOut[225]: \narray([[76, 56],\n       [70, 47],\n       [46, 95],\n       [76, 56],\n       [92, 46]])\n\nIn [227]: x[np.array(row_indices)[:,None],col_indices]\nOut[227]: \narray([[76, 56],\n       [70, 47],\n       [46, 95],\n       [76, 56],\n       [92, 46]])\n",
    "x_indexed = x[np.ix_(row_indices,col_indices)]\n\nIn [221]: x\nOut[221]: \narray([[17, 39, 88, 14, 73, 58, 17, 78],\n       [88, 92, 46, 67, 44, 81, 17, 67],\n       [31, 70, 47, 90, 52, 15, 24, 22],\n       [19, 59, 98, 19, 52, 95, 88, 65],\n       [85, 76, 56, 72, 43, 79, 53, 37],\n       [74, 46, 95, 27, 81, 97, 93, 69],\n       [49, 46, 12, 83, 15, 63, 20, 79]])\n\nIn [222]: row_indices\nOut[222]: [4, 2, 5, 4, 1]\n\nIn [223]: col_indices\nOut[223]: [1, 2]\n\nIn [224]: np.ix_(row_indices,col_indices) # Broadcasting of indices\nOut[224]: \n(array([[4],\n        [2],\n        [5],\n        [4],\n        [1]]), array([[1, 2]]))\n\nIn [225]: x[np.ix_(row_indices,col_indices)]\nOut[225]: \narray([[76, 56],\n       [70, 47],\n       [46, 95],\n       [76, 56],\n       [92, 46]])\n\nIn [227]: x[np.array(row_indices)[:,None],col_indices]\nOut[227]: \narray([[76, 56],\n       [70, 47],\n       [46, 95],\n       [76, 56],\n       [92, 46]])\n",
    "x_indexed = x[np.ix_(row_indices,col_indices)]\n\nIn [221]: x\nOut[221]: \narray([[17, 39, 88, 14, 73, 58, 17, 78],\n       [88, 92, 46, 67, 44, 81, 17, 67],\n       [31, 70, 47, 90, 52, 15, 24, 22],\n       [19, 59, 98, 19, 52, 95, 88, 65],\n       [85, 76, 56, 72, 43, 79, 53, 37],\n       [74, 46, 95, 27, 81, 97, 93, 69],\n       [49, 46, 12, 83, 15, 63, 20, 79]])\n\nIn [222]: row_indices\nOut[222]: [4, 2, 5, 4, 1]\n\nIn [223]: col_indices\nOut[223]: [1, 2]\n\nIn [224]: np.ix_(row_indices,col_indices) # Broadcasting of indices\nOut[224]: \n(array([[4],\n        [2],\n        [5],\n        [4],\n        [1]]), array([[1, 2]]))\n\nIn [225]: x[np.ix_(row_indices,col_indices)]\nOut[225]: \narray([[76, 56],\n       [70, 47],\n       [46, 95],\n       [76, 56],\n       [92, 46]])\n\nIn [227]: x[np.array(row_indices)[:,None],col_indices]\nOut[227]: \narray([[76, 56],\n       [70, 47],\n       [46, 95],\n       [76, 56],\n       [92, 46]])\n",
    "In [159]: def avg_func(r):\n              lavg = (r[0] + r[4])/2.0\n              ravg = (r[4] + r[-1])/2.0\n              r[1:4] = lavg\n              r[5:-1] = ravg\n              return r\n\nIn [160]: np.apply_along_axis(avg_func, 1, arr)\nOut[160]: \narray([[   1.  ,  100.5 ,  100.5 ,  100.5 ,  200.  ,  100.5 ,  100.5 ,  \n           100.5 ,    1.  ],\n       [   6.  ,    4.  ,    4.  ,    4.  ,    2.  ,    3.15,    3.15,\n           3.15,    4.3 ],\n       [   5.  ,    3.  ,    3.  ,    3.  ,    1.  ,    4.05,    4.05,\n           4.05,    7.1 ]])\n",
    "a = []\n\nwhile ...:\n    b = ... # NumPy array\n    a.append(b)\na = np.asarray(a)\n",
    "scoreA = np.array([float(1) / (i + 1) for i in range(len(a))],dtype=float)\nscoreB = np.array([0 for i in range(len(b))],dtype=float)\n",
    "import  scipy.stats as stats\nprint a\n[[ 0.93230948         nan  0.47773439  0.76998063]\n [ 0.94460779  0.87882456  0.79615838  0.56282885]\n [ 0.94272934  0.48615268  0.06196785         nan]\n [ 0.64940216  0.74414127         nan         nan]]\n\n#Obtain mean of columns as you need, nanmean is just convenient.\ncol_mean = stats.nanmean(a,axis=0)\nprint col_mean\n[ 0.86726219  0.7030395   0.44528687  0.66640474]\n\n#Find indicies that you need to replace\ninds = np.where(np.isnan(a))\n\n#Place column means in the indices. Align the arrays using take\na[inds]=np.take(col_mean,inds[1])\n\nprint a\n[[ 0.93230948  0.7030395   0.47773439  0.76998063]\n [ 0.94460779  0.87882456  0.79615838  0.56282885]\n [ 0.94272934  0.48615268  0.06196785  0.66640474]\n [ 0.64940216  0.74414127  0.44528687  0.66640474]]\n",
    "import pandas as pd\nprint pd.DataFrame(yourArray)\n",
    "a[tuple(b)] \n"
   ]
  },
  {
   "questions": [
    "Fast numpy covariance : obtain covariance array (M1, M2, N) b (N,). currently block: gets bit slow (M1, M2). speed ?",
    "Pandas: count variance pivot_table: variance add argument ddof function, wrong. ?",
    "Replace vectors 2d numpy array: numpy array (height, width, ) loaded . replace black pixels [ , , ] specific color [r, g, b]. numpy ?",
    "Normalizing numpy array: Given array, normalize sums . currently : 've questions: ) , 'm wondering 's elegant . ) type float 's int? .",
    "Broadcast array : reshape array ( , ) ( ,) : : solve .",
    "Creating numpy matrix existing matrix: numpy , . . create matrix B, taking indicated . ?",
    "Output numpy array : foll. : numpy 2d array: create text ( element per ) array ( per ). Right now, array : append ?",
    "Numpy 1D Arrays Array: files contain numpy pickled numpy.save. create array. currently using numpy.load mmap. 1D now . array?",
    "Why numpy comparison boolean array?: Why : : Instead simply False?",
    ": bin repeated : Say, numpy array : original array much bigger, 's bin group based ? :"
   ],
   "code": [
    "import numpy as np\n\nM1, M2, N = 23, 50, 117\na = np.random.uniform(-2., 2., (M1, M2, N))\nb = np.random.uniform(-1., 1., N)\n\nc = []\nfor i in range(M1):\n    for j in range(M2):\n        c.append(np.cov(a[i][j], b)[0, 1])\n\nc1 = np.reshape(c, (M1, M2))\n\nac = a - a.mean(axis=-1, keepdims=True)\nbc = (b - b.mean()) / (N-1)\n\nc2 = np.dot(ac, bc)\nc3 = np.einsum('ijk,k->ij', ac, bc)\nprint(np.allclose(c1, c2))\nprint(np.allclose(c1, c3))\n\nTrue\nTrue\n",
    "aggfunc=lambda x: np.var(x, ddof=1)\n\naggfunc='var'\n\nnp.random.seed(10)\ndf = pd.DataFrame({'ID':np.random.choice(list('def'),size=30), \n                   'domain':np.random.choice(list('abc'),size=30),\n                   'active_seconds':np.random.randint(10,size=30)})\n\nprint (df.head())\n  ID  active_seconds domain\n0  e               1      c\n1  e               7      b\n2  d               1      b\n3  d               4      b\n4  e               0      b\n\ndf1 = df.pivot_table(index='ID', \n                     columns='domain', \n                     values='active_seconds', \n                     aggfunc=lambda x: np.var(x, ddof=1))\nprint (df1)\ndomain          a          b          c\nID                                     \nd        8.333333   8.333333  10.000000\ne        8.000000  11.300000  16.333333\nf       19.000000   8.000000  24.500000\n\ndf1 = df.pivot_table(index='ID', columns='domain', values='active_seconds', aggfunc='var')\nprint (df1)\ndomain          a          b          c\nID                                     \nd        8.333333   8.333333  10.000000\ne        8.000000  11.300000  16.333333\nf       19.000000   8.000000  24.500000\n",
    "import numpy as np\norig_color = (0, 0, 0)\nreplacement_color = (r, g, b)\n\ndata[(data == orig_color).all(axis = -1)] = replacement_color\n",
    "array /= array.sum(axis=1, keepdims=True)\n\narray = array.astype(float)\n",
    "a = a.reshape(4,3) \n\nb = a[1]\n\nb = b.reshape(3,)\n",
    "import numpy as np\n\nA = np.arange(25).reshape((5,5))\n\nx = [1, 2, 4]\n\nB = A[x]\n\nprint(B)\n# [[ 5  6  7  8  9]\n# [10 11 12 13 14]\n# [20 21 22 23 24]] \n",
    "In [26]: with open('test.txt','w') as f:\n    np.savetxt(f, data.T, delimiter=',', fmt='%12s')\n    np.savetxt(f, data.T, delimiter=';', fmt='%10s') # simulate a 2nd array\n",
    ">>> import numpy as np\n>>> arrs = [np.array([1,2,3]), np.array([4,5,6]), np.array([7,8,9])]\n>>> arrs\n[array([1, 2, 3]), array([4, 5, 6]), array([7, 8, 9])]\n>>> arr2d = np.array(arrs)\n>>> arr2d.shape\n(3, 3)\n>>> arr2d\narray([[1, 2, 3],\n       [4, 5, 6],\n       [7, 8, 9]])\n",
    "In [285]: np.arange(10)==[1,2]\n/usr/local/bin/ipython3:1: DeprecationWarning: elementwise == comparison failed; this will raise an error in the future.\n  #!/usr/bin/python3\nOut[285]: False\n",
    "import pandas as pd\ndf = pd.DataFrame(x)\n\n{key: group for key, group in df.groupby(0)}\n\n{key: group.iloc[:,1:] for key, group in df.groupby(0)}\n\nimport itertools as it\n{key: list(map(list, group))\n    for key, group in it.groupby(x, lambda row: row[0])}\n\n{key: list(map(lambda a: list(a)[1:], group))\n    for key, group in it.groupby(x, lambda row: row[0])}\n\nimport more_itertools as mt\n{key: list(group) for key, group in mt.groupby_transform(\n    x, lambda row: row[0], lambda row: list(row[1:])\n)}\n"
   ]
  },
  {
   "questions": [
    "Groupby() words comma separator: DataFrame csv: : : : real , B, C, D, E words, comma separator. You ideas ?",
    "filling forward conditional : DataFrame B. Now produce C : C gets B == . Then kept coming until next == . vectorized fashion?",
    "Plot parametric mean : real d called r. : : elgant ?",
    "turn comma seperated TXT CSV machine learning: turn format TXT CSV ? sure understand? already comma -eparated . using numpy. (S&P) 500 txt files .",
    "plus/minus operator \u00b1: looking plus/minus operation . command operator, cannot command operator . Am missing ?",
    "Counting consecutive zeros Dataframe [closed]: count consecutive zeros Dataframe shown below, please",
    "Dropping contain NaN: DataFrame similar actual DataFrame contains 500 year history. : identify contain NaN: drop mentioned cases. Can anybody ?",
    "Numpy: display numbers comma separated form, ,000,000? [duplicate]: already answer here: numpy array : those numbers comma separated , .e.: 204,978 instead 204978. feasible within numpy/scipy?",
    "Pandas: Best count matches ?: dataframe : pythonic similar : exactly , several versions accomplish , too verbose. pythonic ?",
    "numpy wrong imported separating y : csv ~90k 355 . 354 correspond presence words, showing last numerical . Eg: When : :"
   ],
   "code": [
    "df2 = (df1[0].groupby([df1.index.get_level_values(0),m])\n             .apply(','.join)\n             .unstack()\n             .add_prefix('col_')\n             .rename_axis(None, 1))\nprint (df2)\n  col_0 col_1 col_2 col_3\n0     A   1,5   2,5   3,5\n1   B,C   3,5   4,5   5,5\n2     D   6,5   7,5   8,5\n3   B,E   9,5  10,5  11,5\n",
    "a = pd.DataFrame({\"A\":[0,1,0,0,1], \"B\":[50,60,40,30,40]}, index=[1,2,3,4,5])\na[\"C\"] = a.B[a.A == 1]\na = a.fillna(method=\"ffill\")\n\n   A   B   C\n1  0  50 NaN\n2  1  60  60\n3  0  40  60\n4  0  30  60\n5  1  40  40\n",
    "plt.plot(a, np.log(1 + r*a[:,None]).mean(1))\n\nIn [49]: a = np.arange(a_step-.3, a_max, a_step)\n\nIn [50]: r = np.random.random(100)\n\nIn [51]: timeit [scipy.mean(log(1+a[i]*r)) for i in range(len(a))]\n100 loops, best of 3: 5.47 ms per loop\n\nIn [52]: timeit np.log(1 + r*a[:,None]).mean(1)\n1000 loops, best of 3: 384 \u00b5s per loop\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.random.random(100)\n\na = 1.\na_max = 1.\na_step = 0.01\na = np.arange(a_step-.3, a_max, a_step)\na.shape\n#(129,)\na = a[:,None] #adds a new axis, making this a column vector, same as: a = a.reshape(-1,1)\na.shape\n#(129, 1)\n(a*r).shape\n#(129, 100)\nloga = np.log(1 + a*r)\nloga.shape\n#(129,100)\nmloga = loga.mean(axis=1) #take the mean along the 2nd axis where `a` varies\nmloga.shape\n#(129,)\n\nplt.plot(a, mloga)\nplt.show()\n\nplt.plot(a, np.log(1 + np.outer(a,r)).mean(1))\n\nr = np.exp(np.arange(1,5))\na = np.arange(5)\n\nIn [33]: r\nOut[33]: array([  2.71828183,   7.3890561 ,  20.08553692,  54.59815003])\n\nIn [34]: a\nOut[34]: array([0, 1, 2, 3, 4])\n\nIn [39]: r*a[:,None]\nOut[39]: \n# this is  2.7...         7.3...        20.08...       54.5...         # times:\narray([[   0.        ,    0.        ,    0.        ,    0.        ],   # 0\n       [   2.71828183,    7.3890561 ,   20.08553692,   54.59815003],   # 1\n       [   5.43656366,   14.7781122 ,   40.17107385,  109.19630007],   # 2\n       [   8.15484549,   22.1671683 ,   60.25661077,  163.7944501 ],   # 3\n       [  10.87312731,   29.5562244 ,   80.34214769,  218.39260013]])  # 4\n\nIn [40]: np.outer(a,r)\nOut[40]: \narray([[   0.        ,    0.        ,    0.        ,    0.        ],\n       [   2.71828183,    7.3890561 ,   20.08553692,   54.59815003],\n       [   5.43656366,   14.7781122 ,   40.17107385,  109.19630007],\n       [   8.15484549,   22.1671683 ,   60.25661077,  163.7944501 ],\n       [  10.87312731,   29.5562244 ,   80.34214769,  218.39260013]])\n\n# this is the mean of each column:\nIn [41]: (np.outer(a,r)).mean(1)\nOut[41]: array([  0.        ,  21.19775622,  42.39551244,  63.59326866,  84.79102488])\n\n# and the log of 1 + the above is:\nIn [42]: np.log(1+(np.outer(a,r)).mean(1))\nOut[42]: array([ 0.        ,  3.09999121,  3.77035604,  4.16811021,  4.4519144 ])\n",
    "import csv\n\ntxt_file = 'mytext.txt'\ncsv_file = 'mycsv.csv'\n\nin_txt = csv.reader(open(txt_file, \"r\"), delimiter=',')\nout_csv = csv.writer(open(csv_file, 'w+'))\n\nout_csv.writerows(in_txt)\n",
    "(2.1 +/- 0.05) + (0.6 +/- 0.05)    # => (2.7 +/- 0.1)\n\nfrom uncertainties import ufloat\n\nufloat(2.1, 0.05) + ufloat(0.6, 0.05)\n\nufloat(2.7, 0.07071)    # not 0.1 as I expected!\n",
    "def len_consec_zeros(a):\n    a = np.array(list(a))    # convert elements to `str`\n    rr = np.argwhere(a == '0').ravel()  # find out positions of `0`\n    if not rr.size:  # if there are no zeros, return 0\n        return 0\n\n    full = np.arange(rr[0], rr[-1]+1)  # get the range of spread of 0s\n\n    # get the indices where `0` was flipped to something else\n    diff = np.setdiff1d(full, rr)\n    if not diff.size:     # if there are no bit flips, return the \n        return len(full)  # size of the full range\n\n    # break the array into pieces wherever there's a bit flip\n    # and the result is the size of the largest chunk\n    pos, difs = full[0], []\n    for el in diff:\n        difs.append(el - pos)\n        pos = el + 1\n\n    difs.append(full[-1]+1 - pos)\n\n    # return size of the largest chunk\n    res = max(difs) if max(difs) != 1 else 0\n\n    return res\n\n# join all columns to get a string column\n\n# assuming you have your data in `df`\ndf['concated'] = df.astype(str).apply(lambda x: ''.join(x), axis=1)\ndf['consecutive_zeros'] = df.concated.apply(lambda x: len_consec_zeros(x))\n",
    "In [21]: df.dropna(axis=1, how='any')\nOut[21]:\n              A    Z\n2015-01-02  3.0  8.0\n2015-01-03  1.0  3.0\n2016-06-14  3.0  2.0\n2016-06-15  1.0  3.0\n\nIn [11]: df.loc[:, ~df.isnull().any()]\nOut[11]:\n              A    Z\n2015-01-02  3.0  8.0\n2015-01-03  1.0  3.0\n2016-06-14  3.0  2.0\n2016-06-15  1.0  3.0\n\nIn [12]: df.loc[:, df.notnull().all()]\nOut[12]:\n              A    Z\n2015-01-02  3.0  8.0\n2015-01-03  1.0  3.0\n2016-06-14  3.0  2.0\n2016-06-15  1.0  3.0\n\ndf.loc[:, df.tail(5).notnull().all()]\n",
    ">>> d = np.array([1, 13, 141, 2345, 51923, 691247])\n>>> np.array2string(d, formatter={'int_kind': lambda x: '{:,}'.format(x)})\n'[1 13 141 2,345 51,923 691,247]'\n\n>>> ' '.join('{:,}'.format(x) for x in d)\n'1 13 141 2,345 51,923 691,247'\n",
    "from itertools import product\n\nIn [291]: cats = ['{0[0]}{0[1]}'.format(tup) for tup in product([0,1], [0,1])]\n\nIn [292]: pd.Categorical((df.actual.astype(str)+df.prediction.astype(str)),\n                         categories=cats) \\\n            .value_counts()\nOut[292]:\n00    3\n01    0\n10    2\n11    1\ndtype: int64\n\nIn [298]: df.groupby(df.columns.tolist()).size().reset_index()\nOut[298]:\n   actual  prediction  0\n0       0           0  3\n1       1           0  2\n2       1           1  1\n",
    "d['total']\n\nd[0]\n\nimport numpy as np\n\nd = np.genfromtxt('data', dtype=None, delimiter=',', skiprows=1)\nprint(d.shape)\n# (3, 5)\nprint(d)\n# [[ 1  0  0  1 30]\n#  [ 0  1  1  1 28]\n#  [ 1  1  0  1 55]]\n\nprint(d[:,-1])\n# [30 28 55]\n\nprint(d[:,:-1])\n# [[1 0 0 1]\n#  [0 1 1 1]\n#  [1 1 0 1]]\n"
   ]
  },
  {
   "questions": [
    "Efficient looping using index array: index array unique sequential , : corresponding array: index array sequential order, index array order ( .e. , , , , 4...) corresponding ( .e. , 100, 200, 300, 400). reason aren't order 'm subdividing edges, means edges added end index array (using vstack), rather inserted index array appropriate point. pseudocode ( printing ), : producing: memory sensitive ( 'm guessing numpy. ) better practice reorder before looping, performance cost looping order?",
    "index array: (1080,1920, ) stored numpy array index using index array (6, ). below runs, however dimensions ( ,6, ), expect. answers here. Can anyone understand whats wrong (6, ) array?",
    "Efficient count unique array numpy/scipy : scipy array, e.g. count occurrences unique element array. , array , occurrence [ , , ], occurrences [ , , ] occurrence [ , , ]. One thought : better/ efficient ? thanks.",
    "Efficient swapping numpy array: Assuming we matrix , matrix (c1, r1), (c2, r2) we swap: pythonic : However, slow swappings. efficient swap numpy array? advance.",
    "numpy: unique colors : img: On pixel (100, 100) nice color: Now : many colors , enumerate ? idea numpy.unique(), somehow using wrong.",
    "ValueError: Couldn't broadcast input array (51) (51, ): : 's showing last . understand why issue. verified separately issues.",
    "numpy array array : np array : array: array index (array ), array index (array ) array index third (array ) expected : looking numpy . As , prefer comprehension lists."
   ],
   "code": [
    "value_array[index_array.argsort()]\n\nIn [129]: value_array\nOut[129]: array([   0,  400,  200,  500,  600,  100,  300,  700, 800])\n\nIn [130]: index_array\nOut[130]: array([0, 4, 2, 5, 6, 1, 3, 7, 8])\n\nIn [131]: value_array[index_array.argsort()]\nOut[131]: array([   0,  100,  200,  300,  400,  500,  600,  700, 800])\n\ndef assign_unique_seq(value_array, index_array):\n    out = np.empty_like(value_array)\n    out[index_array] = value_array\n    return out\n\nIn [152]: value_array = np.random.randint(0,1000000,(100000))\n\n# Create unique and sequential indices array\nIn [153]: index_array = np.random.permutation(len(value_array))\n\nIn [154]: %timeit value_array[index_array.argsort()]\n100 loops, best of 3: 7.84 ms per loop\n\nIn [155]: %timeit assign_unique_seq(value_array, index_array)\n1000 loops, best of 3: 240 \u00b5s per loop\n",
    "A = inPix[2darray[:,0],2darray[:,1]]\n",
    ">>> from collections import Counter\n>>> c = Counter([(0,0,1), (1,1,1), (1,1,1), (1,0,1)])\n>>> c\nCounter({(1, 1, 1): 2, (0, 0, 1): 1, (1, 0, 1): 1})",
    "c1 = np.array(<all the \"c1\" values>, dtype=int)\nr1 = np.array(<all the \"r1\" values>, dtype=int)\nc2 = np.array(<all the \"c2\" values>, dtype=int)\nr2 = np.array(<all the \"r2\" values>, dtype=int)\nA[c1, r1], A[c2, r2] = A[c2, r2], A[c1, r1]\n\nc1, r1 = np.array([ np.arange(10), np.arange(10) ])\nc2, r2 = np.array([ [2,4,6,8,0,1,3,5,7,9], [9,1,6,8,2,2,2,2,7,0] ])\nA = np.empty((15,15))\n\ndef get_chunk_boundry(c1, r1, c2, r2):\n    a1 = c1 + 1j * r1\n    a2 = c2 + 1j * r2\n    set1 = set()\n    set2 = set()\n    for i, (x1, x2) in enumerate(zip(a1, a2)):\n        if x1 in set2 or x2 in set1:\n            return i\n        set1.add(x1); set2.add(x2)\n    return len(c1)\n\nwhile len(c1) > 0:\n    i = get_chunk_boundry(c1, r1, c2, r2)\n    c1b = c1[:i]; r1b = r1[:i]; c2b = c2[:i]; r2b = r2[:i]\n    print 'swapping %d elements' % i\n    A[c1b,r1b], A[c2b,r2b] = A[c2b,r2b], A[c1b,r1b]\n    c1 = c1[i:]; r1 = r1[i:]; c2 = c2[i:]; r2 = r2[i:]\n",
    "set( tuple(v) for m2d in img for v in m2d )\n",
    "Y_train[k]=(x.dot(beta_1)+(np.roll(x,1,axis=0)).dot(beta_2))[:,None]\n",
    "list_arr[np.arange(list_arr.shape[0]),indices_array,:]\n\nIn [16]: list_arr\nOut[16]: \narray([[[ 1,  2,  3],\n        [ 4,  5,  6],\n        [ 7,  8,  9]],\n\n       [[10, 20, 30],\n        [40, 50, 60],\n        [70, 80, 90]],\n\n       [[15, 25, 35],\n        [45, 55, 65],\n        [75, 85, 95]]])\n\nIn [17]: indices_array\nOut[17]: array([1, 0, 2])\n\nIn [18]: list_arr[np.arange(list_arr.shape[0]),indices_array,:]\nOut[18]: \narray([[ 4,  5,  6],\n       [10, 20, 30],\n       [75, 85, 95]])\n"
   ]
  },
  {
   "questions": [
    "reshape 3D 1D ? [duplicate]: already answer here: written dimensional , dimensional.",
    "missing dimension numpy [duplicate]: already answer here: difference (why dimension missing case):",
    "matlab ? [duplicate]: already answer here: write operation matlab (numpy). repmat(sum( , ), ,20);",
    "Efficient create numbers? [duplicate]: already answer here: most efficient create n ?",
    "Different iterators giving answers [duplicate]: already answer here: difference cons defined",
    "Concatenate numpy [duplicate]: already answer here: written append numpy : However, produces : On :",
    "To_CSV unique [duplicate]: already answer here: When : :",
    "append matrix side side [duplicate]: already answer here: having . : ?",
    "Convert matlab statement [duplicate]: already answer here: matlab statement : advance",
    "Remove duplicate numpy array [duplicate]: already answer here: remove duplicate dimensional numpy array? answer follows: , remove \"duplicate\" ."
   ],
   "code": [
    "originl_list = [[[1,2,3], [1,2,3]], [[1,2,3], [1,2,3]]]\nfinal_list = []\n\ndef method1():\n    for i in lst1:\n        for j in i:\n            for k in j:\n                final_list.append(k)\n\n    print(final_list)\n\n\ndef method2():\n    [final_list.append(k) for i in originl_list for k in i for j in k]\n\n    print(final_list)\n",
    ">>> a = np.zeros((2))\narray([ 0.,  0.])\n>>> a.shape\n(2,)\n>>> a.ndim\n1\n\n>>> b = np.zeros((2,2))\narray([[ 0.,  0.],\n       [ 0.,  0.]])\n>>> b.shape\n(2,2)\n>>> b.ndim\n2\n\n>>> c = np.zeros((2,2,2))\narray([[[ 0.,  0.],\n        [ 0.,  0.]],\n\n       [[ 0.,  0.],\n        [ 0.,  0.]]])\n>>> c.shape\n(2,2,2)\n>>> c.ndim\n3\n\n>>> d = np.zeros((2,2,2,2))\narray([[[[ 0.,  0.],\n         [ 0.,  0.]],\n\n        [[ 0.,  0.],\n         [ 0.,  0.]]],\n\n\n       [[[ 0.,  0.],\n         [ 0.,  0.]],\n\n        [[ 0.,  0.],\n         [ 0.,  0.]]]])\n>>> d.shape\n(2,2,2,2)\n>>> d.ndim\n4\n",
    "import numpy as np\nnp.tile(np.sum(data, axis=1), 1, 20)\n",
    "number = 1\nelements = 1000\n\nthelist = [number] * elements\n\n>>> [1] * 10\n[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n\nIn [23]: a = [[0]] * 10\n\nIn [24]: a\nOut[24]: [[0], [0], [0], [0], [0], [0], [0], [0], [0], [0]]\n\nIn [25]: a[0][0] = 1\n\nIn [26]: a\nOut[26]: [[1], [1], [1], [1], [1], [1], [1], [1], [1], [1]]\n",
    "for i in range(0,3): cons.append({'fun':lambda x, i=i: np.dot(A[i],x)})\n",
    "td_X = np.concatenate([td_XP, td_XN],axis=1)\n\ntd_X = np.concatenate([[[1,2,3,7],[4,5,6,8]],[[1,2,3],[4,5,6]]],axis=1)\n\narray([[1, 2, 3, 7, 1, 2, 3],\n       [4, 5, 6, 8, 4, 5, 6]])\n\ntd_X = np.concatenate([td_XP, td_XN],axis=0)\n\ntd_X = np.concatenate([[[1,2,3],[4,5,6]],[[1,2,7],[4,5,8]]],axis=0)\n\narray([[1, 2, 3],\n       [4, 5, 6],\n       [1, 2, 7],\n       [4, 5, 8]])\n",
    "df = pd.DataFrame({'a':[1,2,3,4,5,6],'b':['a','a','b','c','c','b']})\n\ng = df['b'].unique()\n\narray(['a', 'b', 'c'], dtype=object)\n\nIn [22]: s = pd.Series(g)\n\nIn [23]: s\nOut[23]: \n0    a\n1    b\n2    c\ndtype: object\n\nIn [24]: s.to_csv('file.csv')\n",
    "np.hstack((A, B))\n\nnp.c_[A, B]\n",
    "import numpy as np\n\nlam = np.where(np.abs(a)>tol)[0][0]-1\n\n>> b = [-4,6,-7,-2,8];\n>> tol = 6;\n>> find(abs(b)>tol,1,'first')-1\nans =\n     2\n\nIn [23]: a = np.array([-4,6,-7,-2,8])\n\nIn [24]: tol = 6\n\nIn [25]: np.where(np.abs(a)>tol)[0][0]-1\nOut[25]: 1 # 1 lesser than MATLAB vesion because of 0-based indexing\n\nIn [40]: np.argmax(np.abs(a)>tol)-1\nOut[40]: 1\n",
    "import numpy as np\n\ndata = np.array([[1,8,3,3,4],\n                 [1,8,9,9,4],\n                 [1,8,3,3,4]])\n\n>>> uniques\narray([1, 3, 4, 8, 9])\n\nnew_array = [tuple(row) for row in data]\nuniques = np.unique(new_array)\n\n>>> uniques\narray([[1, 8, 3, 3, 4],\n       [1, 8, 9, 9, 4]])\n"
   ]
  },
  {
   "questions": [
    "Python_Pandas: datetime fall under certain date duration, create specific : From below df, dates meet below criteria, add certain newly added called 'staffNumber': IF 'date' falls under 6/ /2016~9/22/2016 THAN create . IF 'date' falls under 9/23/2016~10/28/2016 THAN create . IF 'date' falls under 10/29/2016~11/4/2016 THAN create usually before ask . However, couldn't think approach. looked using np. & .isin links: . numpy function datetime . Using 'isin' date . Pandas conditional creation series/dataframe appreciated!",
    "numpy/ : add based ?: , long : { , ,7,9,...}. numpy / : append additional taking depending whether leftmost found ( yes). , looping ? 've approaches success. Much appreciated! P.S. numpy goes array correspond index numpy inner array.",
    "numpy: iterate nested array: Im iterate nested (numpy) using np.nditer(). Converted nested ints nested numpy array. , yielding; calculate mean nested sub- ... 's working correctly. ... kinda flattens nested array point nested sub- instead . nditer ? pointer greatly appreciated!",
    "control dimension broadcast tensorflow?: center several means several sets centered . (4, ) .e. four 3D vectors: centers ( 3D vectors): center once per mu. numpy write : tensorflow? Bulk numpy appreciated!"
   ],
   "code": [
    "#convert to datetimes if necessary\ndf['date'] = pd.to_datetime(df['date'])\nb = pd.to_datetime(['2016-06-01','2016-09-22','2016-10-28','2016-11-04'])\nl = range(1,4)\ndf['new'] = pd.cut(df['date'], bins=b, labels=l, include_lowest=True)\nprint (df)\n        date  score new\n0 2016-06-01      9   1\n1 2016-09-22      8   1\n2 2016-10-28      8   2\n3 2016-11-04     10   3\n4 2016-06-29      6   1\n5 2016-10-01      7   2\n6 2016-06-15      7   1\n7 2016-07-29      7   1\n8 2016-11-01      6   3\n\n#change first date to 2016-05-31\nb = pd.to_datetime(['2016-05-31','2016-09-22','2016-10-28','2016-11-04'])\nl = range(1,4)\n\ndf['new'] = np.array(l)[b.searchsorted(df['date'].values) - 1]\nprint (df)\n        date  score  new\n0 2016-06-01      9    1\n1 2016-09-22      8    1\n2 2016-10-28      8    2\n3 2016-11-04     10    3\n4 2016-06-29      6    1\n5 2016-10-01      7    2\n6 2016-06-15      7    1\n7 2016-07-29      7    1\n8 2016-11-01      6    3\n",
    "selected_indices = [1,3,7,9]   \n\n# set index as col1, since that seems to be the point of column1\ndf.set_index('col1')\n\n# define col3 value as 0 or 1 based on selected_indices list\ndf['col3'] = 0\ndf['col3'].loc[selected_indices] = 1\n",
    ">>> import numpy as np\n>>> nested_list = [[1,2,3],[2,3,4],[3,4,5],[4,5,6]]\n>>> np.array(nested_list)\narray([[1, 2, 3],\n       [2, 3, 4],\n       [3, 4, 5],\n       [4, 5, 6]])\n>>> np.array(nested_list).mean(axis=1)\narray([ 2.,  3.,  4.,  5.])\n>>> np.array(nested_list).mean(axis=0)\narray([ 2.5,  3.5,  4.5])\n",
    "centered_data = tf.substract(data, mu)\n"
   ]
  },
  {
   "questions": [
    "slicing numpy array nth : Having below, slice (e.g. 3rd ) [ , , ..., 1338, 1312, 1502, , ...] Looking most efficient , thanks!",
    "slicing numpy array nth : Having below, slice (e.g. 3rd ) [ , , ..., 1338, 1312, 1502, , ...] Looking most efficient , thanks!",
    "Slicing numpy array : 's wrong below? slice array( fifth ). Please . TypeError: must integers, tuple.",
    "slicing numpy/scipy: array : 's most efficient slice 1x2 array \" \"? .e., thanks.",
    "More elegant defining numpy array: 'm looking elegant/neat create numpy array numbers [1e , 2e , 3e , ..., 1e0, 2e0, 3e0, ..., 1e3, 2e3, 3e3, ..., 8e3, 9e3, 1e4] best come",
    "zero 3d numpy array?: 3d numpy array, . deminsions elemnts equal , .e. ( [ ]) = ( , ), ( [ ]) = ( ,4), etc. zero most efficient . ? thanks!",
    "insert dimensions array dimension using Numpy: Let's say we c = [ [ , , B, C], [ , D, E, F] ] combing & b achieve ? amounts 1st level children both b.",
    "Numpy sum subarrays pairs : Suppose . series index pairs (a1, b1), (a2, b2) ... ( , bn) obtain sums those pairs. .e. terms , 's most efficient ? !",
    "create fill numpy array array?: create numpy array [ , , ], axis array, [ , , ]? invalid : Resulting array : Could course filling , thought may shortcut:",
    "create fill numpy array array?: create numpy array [ , , ], axis array, [ , , ]? invalid : Resulting array : Could course filling , thought may shortcut:"
   ],
   "code": [
    "arr[...,n]\n\narr[...,n].ravel()\n\nIn [317]: arr\nOut[317]: \narray([[[[2, 1, 2],\n         [0, 2, 3],\n         [1, 0, 1]],\n\n        [[0, 2, 0],\n         [3, 1, 2],\n         [3, 3, 1]]],\n\n\n       [[[2, 0, 0],\n         [0, 2, 3],\n         [3, 3, 1]],\n\n        [[2, 0, 1],\n         [2, 3, 0],\n         [3, 3, 2]]]])\n\nIn [318]: arr[...,2].ravel()\nOut[318]: array([2, 3, 1, 0, 2, 1, 0, 3, 1, 1, 0, 2])\n",
    "arr[...,n]\n\narr[...,n].ravel()\n\nIn [317]: arr\nOut[317]: \narray([[[[2, 1, 2],\n         [0, 2, 3],\n         [1, 0, 1]],\n\n        [[0, 2, 0],\n         [3, 1, 2],\n         [3, 3, 1]]],\n\n\n       [[[2, 0, 0],\n         [0, 2, 3],\n         [3, 3, 1]],\n\n        [[2, 0, 1],\n         [2, 3, 0],\n         [3, 3, 2]]]])\n\nIn [318]: arr[...,2].ravel()\nOut[318]: array([2, 3, 1, 0, 2, 1, 0, 3, 1, 1, 0, 2])\n",
    ">>> arr= numpy.array([ [1, 2, 3], [ 4, 5, 6], [ 7, 8, 9] ])\n>>> arr\narray([[1, 2, 3],\n       [4, 5, 6],\n       [7, 8, 9]])\n>>> arr[1:2, 1]\narray([5])\n\n>>> arr.tolist()\n[[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n>>> arr.tolist()[1:2, 1]\nTraceback (most recent call last):\n  File \"<ipython-input-23-4a441cf2eaa9>\", line 1, in <module>\n    arr.tolist()[1:2, 1]\nTypeError: list indices must be integers, not tuple\n",
    "\n>>> from numpy import array\n>>> a = array([[1,2,3],[3,4,5],[4,5,6]])\n>>> a[:,1:]\narray([[2, 3],\n       [4, 5],\n       [5, 6]])\n",
    "np.array([x*(10**y) for y in range(-1,5)  for x in range(1,10)])[:-8]\n\narray([  1.00000000e-01,   2.00000000e-01,   3.00000000e-01,\n         4.00000000e-01,   5.00000000e-01,   6.00000000e-01,\n         7.00000000e-01,   8.00000000e-01,   9.00000000e-01,\n         1.00000000e+00,   2.00000000e+00,   3.00000000e+00,\n         4.00000000e+00,   5.00000000e+00,   6.00000000e+00,\n         7.00000000e+00,   8.00000000e+00,   9.00000000e+00,\n         1.00000000e+01,   2.00000000e+01,   3.00000000e+01,\n         4.00000000e+01,   5.00000000e+01,   6.00000000e+01,\n         7.00000000e+01,   8.00000000e+01,   9.00000000e+01,\n         1.00000000e+02,   2.00000000e+02,   3.00000000e+02,\n         4.00000000e+02,   5.00000000e+02,   6.00000000e+02,\n         7.00000000e+02,   8.00000000e+02,   9.00000000e+02,\n         1.00000000e+03,   2.00000000e+03,   3.00000000e+03,\n         4.00000000e+03,   5.00000000e+03,   6.00000000e+03,\n         7.00000000e+03,   8.00000000e+03,   9.00000000e+03,\n         1.00000000e+04])\n\nnp.ravel(np.power(10.0, np.arange(-1,5))[:,np.newaxis]*np.arange(1,10))[:-8]\n\narray([  1.00000000e-01,   2.00000000e-01,   3.00000000e-01,\n         4.00000000e-01,   5.00000000e-01,   6.00000000e-01,\n         7.00000000e-01,   8.00000000e-01,   9.00000000e-01,\n         1.00000000e+00,   2.00000000e+00,   3.00000000e+00,\n         4.00000000e+00,   5.00000000e+00,   6.00000000e+00,\n         7.00000000e+00,   8.00000000e+00,   9.00000000e+00,\n         1.00000000e+01,   2.00000000e+01,   3.00000000e+01,\n         4.00000000e+01,   5.00000000e+01,   6.00000000e+01,\n         7.00000000e+01,   8.00000000e+01,   9.00000000e+01,\n         1.00000000e+02,   2.00000000e+02,   3.00000000e+02,\n         4.00000000e+02,   5.00000000e+02,   6.00000000e+02,\n         7.00000000e+02,   8.00000000e+02,   9.00000000e+02,\n         1.00000000e+03,   2.00000000e+03,   3.00000000e+03,\n         4.00000000e+03,   5.00000000e+03,   6.00000000e+03,\n         7.00000000e+03,   8.00000000e+03,   9.00000000e+03,\n         1.00000000e+04])\n",
    "A = np.array(map(np.array, [ [[1,2],[3,4]], [[1,2,3],[4,5,6],[7,8,9]] ] ))\n\n>>> A\narray([[[1 2]\n [3 4]], [[1 2 3]\n [4 5 6]\n [7 8 9]]], dtype=object)\n\nfor sub_array in A:\n    sub_array[...] = 0\n\n>>> A\narray([[[0 0]\n [0 0]], [[0 0 0]\n [0 0 0]\n [0 0 0]]], dtype=object)\n",
    "In[13]:\nnp.hstack([a.reshape((2,1)), b])\n\nOut[13]: \narray([['1', 'A', 'B', 'C'],\n       ['2', 'D', 'E', 'F']], \n      dtype='<U11')\n\nIn[14]:\nnp.hstack([a[:,None], b])\n\nOut[14]: \narray([['1', 'A', 'B', 'C'],\n       ['2', 'D', 'E', 'F']], \n      dtype='<U11')\n",
    "c = numpy.r_[0, A.cumsum()][indices]\nsums = c[:,1] - c[:,0]\n",
    "import numpy as np\n\nnp.tile(np.arange(1, 4), [2, 2, 1])\n",
    "import numpy as np\n\nnp.tile(np.arange(1, 4), [2, 2, 1])\n"
   ]
  },
  {
   "questions": [
    "concatenate matrices interleaved [duplicate]: already answer here: D concatenate interleaving Initial ( ( , 8) ): Result ( 6x8): series reshapes, couldn't figure !",
    "Saving matrix ' header [duplicate]: already answer here: . When save . headers save. Could u please guide ?",
    "elegant iterate count sequence [duplicate]: already answer here: Let's DataFrame : counting occurrence reset count comes . : : results: fine, little slow larger sets repeated. Would faster elegant ?",
    "create matrices names inside [duplicate]: already answer here: create matrices 1x5: matriz1, matriz2 matriz3, + j, . Can someone ?",
    "Syntax print [duplicate]: already answer here: Why receive syntax printing string ?",
    "load float+ string table [duplicate]: already answer here: table contains both floats strings. When 'm load np.loadtxt( .txt), got fix .",
    "- Transposing ( length) using numpy fails [duplicate]: already answer here: When contains length transposition : , case contains length: fails. ?",
    "Find occurence index keep [duplicate]: already answer here: ndarray content: Now 'd keep element multiple . Would : achieve numpy?",
    "- numpy reshape mean? [duplicate]: already answer here: common Machine learning pipelines. ? never understood meaning '- ' reshape. An exact solid explanation. answers pls ?",
    "enumerate array numpy [duplicate]: already answer here: function behaves enumerate, numpy . Currently using function: better ? E.g. inbuilt function ( couldn't ), definition faster ."
   ],
   "code": [
    "np.column_stack((a, b)).reshape(-1, a.shape[1])\n\n#array([[107, 115, 132, 138, 128, 117, 121, 135],\n#       [ 25,  28,  28,  25,  23,  21,  20,  18],\n#       [149, 152, 151, 143, 146, 149, 149, 148],\n#       [  3,   3,   2,   2,  10,  12,  12,   1],\n#       [152, 142, 146, 141, 143, 148, 149, 153],\n#       [  1,   0,   2,   0,   0,   0,   0,   1]])\n\nnp.concatenate((a, b), axis=1).reshape(-1, a.shape[1])\n",
    "df.to_csv(\"your_file_path_here\")\n",
    "a['count_check'] =  a.apply(lambda x: x.groupby((~x.astype(bool)).cumsum()).cumsum())\n\n    instance  count_check\n0          1            1\n1          1            2\n2          1            3\n3          0            0\n4          0            0\n5          0            0\n6          1            1\n7          1            2\n8          1            3\n9          1            4\n10         0            0\n11         1            1\n12         1            2\n13         1            3\n14         1            4\n15         1            5\n16         0            0\n17         0            0\n18         1            1\n19         1            2\n",
    "name= 'matriz%d'%i        # assign a string\nname= np.zeros((1,5))     # assign an array\n\nadict = {}\nfor i in range(3):\n   name= 'matriz%d'%i\n   adict[name] = np.zeros((1,5))\n\nalist = [np.zeros((1,5)) for i in range(3)]\n\nfor i,A in enumerate(alist):  # iteration with index\n    A[:] = i+np.arange(5)\nfor a in alist:   # simple iteration\n    print(a)\n",
    "print(\"Hello World\")\n",
    "np.loadtxt(fname, dtype=[('col1_name', '|S10'), ('col2_name', float)])\n",
    "from itertools import zip_longest\n\nl = [[1, 2, 3], [4, 5]]\nr = [list(filter(None,i)) for i in zip_longest(*l)]\nprint(r)\n# [[1, 4], [2, 5], [3]]\n",
    "x = np.array([\n    [0, 1],\n    [0, 5],\n    [1, 7],\n    [2, 9],\n    [2, 4],\n    [2, 4],\n    [3, 8],\n    [4, 2],\n    [4, 7],\n])\n\nidx = numpyp.unique(x[:,0], return_index=True)[1]\n\nx[idx]\n",
    "A.reshape(-1, 28*28)\n",
    ">>> for (x, y), element in np.ndenumerate(np.array([[i for i in \"egg\"] for j in range(3)])):\n...     print(x, y, element)\n... \n(0L, 0L, 'e')\n(0L, 1L, 'g')\n(0L, 2L, 'g')\n(1L, 0L, 'e')\n(1L, 1L, 'g')\n(1L, 2L, 'g')\n(2L, 0L, 'e')\n(2L, 1L, 'g')\n(2L, 2L, 'g')\n"
   ]
  },
  {
   "questions": [
    "combine numpy reshape [duplicate]: already answer here: numpy matrix B. 1000 6, : B 1000x6 : create 3D matrix: 1000x6x2, : create empty 1000x6x2 matrix C, iterate matrix B assign C . wondering elegant combine B, reshape matrix C? !",
    "combine numpy form array [duplicate]: already answer here: numpy (4, , ). combine array (8, , ) minimum lines ? Not changing put together top B bottom.",
    "both diagonals matrix? [duplicate]: already answer here: Lets say 's numpy matrix . Finding diagonal easy, its . With matrix: Using : opposite diagonal? matrix :",
    "Convert numpy array (n, ) (n,) [duplicate]: already answer here: numpy array (n, ) (n,). having iterate array?",
    "numpy string array int array [duplicate]: already answer here: numpy.ndarray int? : . place blank ''",
    "index numpy array? [duplicate]: already answer here: Given numpy matrix (5, ), index vector b (5,), entry index vector , create vector c based its index vector b.",
    "Generate array pairs numpy vectors [duplicate]: already answer here: easy Numpy generate array pairs 1D numpy (vectors) looping? input: : wondering function similar :",
    "Find indexes numpy [duplicate]: already answer here: numpy array : finding indexes \" \" np. ( == \" \") fine. indexes \" \" \"B\"? used: didn't .",
    "test distinct numpy [duplicate]: already answer here: numpy, nice idiomatic testing distinct 2d array? thought . ,",
    "combine numpy element element? [duplicate]: already answer here: 'm sure proper terminology combine resulting array paired item item B: numpy accomplishing generate build whole array?"
   ],
   "code": [
    "C = np.dstack((A, B))\n\nimport numpy as np\nA = np.arange(6000).reshape(1000,6)\nB = np.arange(6000).reshape(1000,6)\n\u200b\nC = np.dstack((A, B))\n\nC.shape\n# (1000, 6, 2)\n\nC = np.stack((A,B), axis=-1)\n\nC.shape\n# (1000, 6, 2)\n",
    "numpy.concatenate((A, B))\n",
    ">>> a = np.array([[0, 3, 6], [0, 4, 9], [0, 1, 9]])\n>>> a.strides\n(24, 8)\n\n>>> a.strides[0] + a.strides[1]\n32\n>>> a.strides[0] - a.strides[1]\n16\n\n>>> np.ndarray(shape=min(a.shape), dtype=a.dtype, buffer=a, \n...            offset=0, strides=a.strides[0]+a.strides[1])\narray([0, 4, 9])\n>>> np.ndarray(shape=min(a.shape), dtype=a.dtype, buffer=a, \n...            offset=a.strides[1] * (a.shape[1] - 1),\n...            strides=a.strides[0]+a.strides[1])\narray([6, 4, 0])\n",
    ">>> x = np.array([[[0], [1], [2]]])\n>>> x.shape\n(1, 3, 1)\n>>> np.squeeze(x).shape\n(3,)\n>>> np.squeeze(x, axis=(2,)).shape\n(1, 3)\n",
    "import numpy as np\n\na = np.array([['-0.99', '', '0.56', '0.56', '-2.02', '-0.96']])\na[a == ''] = 0.0\na = a.astype(np.float)\n\n[[-0.99  0.    0.56  0.56 -2.02 -0.96]]\n\na = a.tolist()\n\n[[-0.99, 0.0, 0.56, 0.56, -2.02, -0.96]]\n",
    "c = a[np.arange(5), b]\n",
    "from itertools import product\n\nc = list(product(a, b))\n\nc == [(1, 4), (1, 5), (1, 6), (2, 4), (2, 5), (2, 6), (3, 4), (3, 5), (3, 6)]\n",
    "x = np.array(x)\nnp.where((x=='A') | (x=='B'))\nOut: (array([0, 1, 2, 3, 6], dtype=int64),)\n\nnp.where(np.logical_or(x=='A', x=='B'))\nOut: (array([0, 1, 2, 3, 6], dtype=int64),)\n",
    "(np.corrcoef(M)==1).sum()==M.shape[0]\n\n\nIn [66]:\n\nM = np.random.random((5,8))\nIn [72]:\n\n(np.corrcoef(M)==1).sum()==M.shape[0]\nOut[72]:\nTrue\n\nlen(set(map(tuple,M)))==len(M)\n\nIn [99]:\n\n%%timeit\n\nb = np.ascontiguousarray(M).view(np.dtype((np.void, M.dtype.itemsize * M.shape[1])))\n_, idx = np.unique(b, return_index=True)\n\nunique_M = M[idx]\n\nunique_M.shape==M.shape\n10000 loops, best of 3: 54.6 \u00b5s per loop\nIn [100]:\n\n%timeit len(set(map(tuple,M)))==len(M)\n10000 loops, best of 3: 24.9 \u00b5s per loop\n",
    "[(x,y) for x in A for y in B]\n"
   ]
  },
  {
   "questions": [
    "Converting Mathematica - arccos sqrt: attempting Mathematica expression . Somehow, Mathematica easily deal negative square root, argument arcsec being outside domain. Can someone expression ? Or least tell Mathematica ( 'm less familiar ) handles issues? Mathematica expression ( . 100) expression When R < rs ( course region interested ), undefined arccos, nonsense square root. tips helpful!",
    "- py expression eval - Passing numpy ndarray: using py expression eval library evaluating expression. However: throws : pass array :",
    "Numpy : einsum expression mean alternative?: understand expression ( [200, ] array) : write using numpy.einsum?",
    "numerical expression sympy: sympy giving expression: sympy give numerical coefficients. ? .evalf N() didn't .",
    "Code expression : 'm expression 'm having difficulty. far wanted advice. Am right track? suggestions?",
    "- numpy mgrid reshape: Can someone explain ? Can someone explain exactly np.mgrid[ :8, :6] part exactly T.reshape(- , ) part ? good job!",
    "savetxt save last : Can someone please explain? script save well . running print cannot save . why?",
    "Find index numpy array : Can someone explain why occurs? case whose numpy ndarray objects search index particular ndarray obj. Simplest Example: Why l index , b?",
    "Converting np array float complex: numpy array float type, extern function needs complex type. When .view(np.complex), real used complex , messing further calculations, .e.: command ?",
    "appending numpy array booleans: Can someone explain ? [True, False] ?"
   ],
   "code": [
    "f[R_, rs_, p0_] := \n   Which[R >= rs,\n           (p0 rs^2 (Sqrt[(R - rs) (R +rs)]\n           (-2 R rs + Pi (R - rs) (R + rs)) - \n           2 (R^3 - 2 R rs^2) ArcSec[R/rs]))/\n           R ((R - rs) (R + rs))^(3/2)),\n         R < rs,\n           (p0 rs^2 ( Sqrt[(rs - R ) (R + rs)]\n           (-2 R rs + Pi (R - rs) (R + rs)) - \n           2 (R^3 - 2 R rs^2) Log[rs/R + Sqrt[(rs/R)^2 - 1]]))/\n           (-R ((rs - R) (R + rs))^(3/2) )]\n\n  LogLogPlot[f[R, 1, 10], {R, 0.1, 100}]\n\nLimit[(p0 rs^2 (Sqrt[(R - rs) (R +  rs)] (-2 R rs + \\[Pi] (R - rs) (R + rs)) \n  2 (R^3 - 2 R rs^2)   ArcSec[R/rs]))/  (R ((R - rs) (R + rs))^(3/2)) , \n   R -> rs,  Assumptions -> {p0 > 0, R > 0, rs > 0}]\n\n%/. {rs->1,p0->10}\n",
    "parser.ops1['sin'] = np.sin\nparser.parse('sin(x)').evaluate({'x':a})\n\narray([ 0.84147098,  0.90929743,  0.14112001])\n\nparser.ops2['^'] = np.power\nparser.parse('x^2').evaluate({'x':a})\n\narray([1, 2, 3])\n",
    "A[...,None,:]*A[...,None]\n\nIn [71]: A = np.random.rand(3,4,5,6)\n\nIn [72]: np.allclose(np.einsum('...i,...j->...ij',A,A), A[...,None,:]*A[...,None])\nOut[72]: True\n\nIn [76]: A = np.random.rand(20000,2)\n\nIn [77]: %timeit np.einsum('...i,...j->...ij',A,A)\n1000 loops, best of 3: 207 \u00b5s per loop\n\nIn [78]: %timeit A[...,None,:]*A[...,None]\n1000 loops, best of 3: 364 \u00b5s per loop\n\nIn [79]: A = np.random.rand(200,200)\n\nIn [80]: %timeit np.einsum('...i,...j->...ij',A,A)\n100 loops, best of 3: 12.1 ms per loop\n\nIn [81]: %timeit A[...,None,:]*A[...,None]\n100 loops, best of 3: 9.74 ms per loop\n",
    "from scipy.integrate import quad\nfrom numpy import *\nfrom sympy import *\n\nx = Symbol('x')\n\n#The function we are required to approximate\nf1 = -1.0*x\nf2 = 1.0*x\n\n\nphi_0= 1.0\nphi_1 = 2.0*x\nphi_2 = 4.0*x*x-1\n\nw = 1.0*sqrt(1.0-x*x)\n\n#compute the coefficient\n\nlf10 = lambdify((x,), f1*phi_0*w, 'numpy')\nlf11 = lambdify((x,), f1*phi_1*w, 'numpy')\nlf12 = lambdify((x,), f1*phi_2*w, 'numpy')\n\nlf20 = lambdify((x,), f2*phi_0, 'numpy')\nlf21 = lambdify((x,), f2*phi_1, 'numpy')\nlf22 = lambdify((x,), f2*phi_2, 'numpy')\n\nc_0 = quad(lf10, -1, 0)[0] + quad(lf20, 0, 1)[0]\nc_1 = quad(lf11, -1, 0)[0] + quad(lf21, 0, 1)[0]\nc_2 = quad(lf12, -1, 0)[0] + quad(lf22, 0, 1)[0]\n\nprint c_0, c_1, c_2\n# 0.833333333333 0.273967584968 0.7\n",
    "# near the top of the file\n# you probably did some kind of `from somewhere import *`.\n# most people like to only import specific names and/or do imports like this,\n# to make it clear where your functions are coming from.\nimport numpy as np\n\ncentered = x - mu\nprec = np.linalg.inv(Sigma)\nE = np.exp(-.5 * np.dot(centered.T, np.dot(prec, centered)))\n",
    "In [11]: np.mgrid[0:2,0:3]\nOut[11]:\narray([[[0, 0, 0],\n        [1, 1, 1]],\n\n       [[0, 1, 2],\n        [0, 1, 2]]])\n\nIn [12]: np.mgrid[0:2,0:3].T  # (matrix) transpose\nOut[12]:\narray([[[0, 0],\n        [1, 0]],\n\n       [[0, 1],\n        [1, 1]],\n\n       [[0, 2],\n        [1, 2]]])\n\nIn [13]: np.mgrid[0:2,0:3].T.reshape(-1, 2)  # reshape to an Nx2 matrix\nOut[13]:\narray([[0, 0],\n       [1, 0],\n       [0, 1],\n       [1, 1],\n       [0, 2],\n       [1, 2]])\n",
    "import numpy\n\na = ([1,2,3,4,5])\nb = ([6,7,8,9,10])\n\nout = []\n\nfor i,j in zip(a,b):\n   print i,j\n   out.append( (i,j) )\n\nnumpy.savetxt('test.txt',out)\n",
    "[np.array_equal(b,x) for x in l].index(True)\n",
    "In [6]: b = a.astype(complex)\nIn [7]: b\nOut[7]: array([ 1.+0.j,  2.+0.j,  3.+0.j])\n\nIn [8]: b.dtype\nOut[8]: dtype('complex128')\n",
    "x = np.array([[[1],[2],[3]], [[4],[5],[6]]])\nx[...,0]\n# outputs: array([[1, 2, 3],\n#       [4, 5, 6]])\nx[..., False] # same thing\n\na = np.array([[1, 2], [3, 4]])\na[..., [True, True]]  # = [[2,2],[4,4]]\n\na[..., [1,1]] # = [[2,2],[4,4]]\n\nb = array([[1,2,3],[4,5,6]])\nb[...,[2,2]] # = [[3,3],[5,5]]\n"
   ]
  },
  {
   "questions": [
    "implement Perceptron ?: follow book Daume http://ciml.info/dl/v0_99/ciml v0_99 ch04.pdf (page 43). To fit model vanilla perceptron using numpy using sciki learn library. algorithm book we implement model practice? far learned labels: appreciated!!",
    "implement Averaged Perceptron ( Scikit learn): fit binary classification using Averaged Perceptron model. followed instructions book Daume (http://ciml.info/dl/v0_99/ciml v0_99 ch04.pdf) (Page 53 averaged perceptron). implementation: However, When test inaccurate predictions. here: produce : : predict label : Testing : Question best fix , . talking implementation numpy scikit, advanced package. remains: we implement averaged perception numpy ?",
    "Pip install Zipline - Issue fortran compiler: install zipline module , numpy scipy both date, pip, still fortran compiler - greatly appreciated!",
    "Difference numpy : , : difference , give: As array well? Sorry amateur - greatly appreciated!",
    "Matplotlib griddata fails: write function makes contour text ( numpy array) formatted \" , y, z\". However, griddata interpolate , \"type\" : function: converting , y, z regular lists tolist() , didn't . greatly appreciated!",
    "global name 'sqrt' defined: 've created function, potential( ,K,B,N), ,K,B numpy N integer. 'm test function iPython keep \"global name 'sqrt' defined\". 's look : 've using math import * seem . suggestions greatly appreciated!",
    "cell matrix : huge matrix saved savetxt numpy library. Now single cell matrix e.g : really slow many index. reading useless lines ?",
    "particular cell ?: panda dataframe. NaN entire , expected below: Using numpy below :",
    "kmeans L1 distance : Given NxM feature vectors numpy matrix. routine cluster Kmeans algorithm using L1 distance (Manhattan distance)?",
    "take .txt files graph using ?: 'm figure take text files filled comma seperated their point average. 's roughly files: : clue go here . greatly appreciated!"
   ],
   "code": [
    "#!python\n# -*- coding: utf-8 -*-#\n\"\"\"\nPerceptron Algorithm.\n\n@author: Bhishan Poudel\n\n@date:  Oct 31, 2017\n\n\"\"\"\n# Imports\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom numpy.linalg import norm\nimport os, shutil\nnp.random.seed(100)\n\ndef read_data(infile):\n    data = np.loadtxt(infile)\n    X = data[:,:-1]\n    Y = data[:,-1]\n\n    return X, Y\n\ndef plot_boundary(X,Y,w,epoch):\n    try:\n        plt.style.use('seaborn-darkgrid')\n        # plt.style.use('ggplot')\n        #plt.style.available\n    except:\n        pass\n\n    # Get data for two classes\n    idxN = np.where(np.array(Y)==-1)\n    idxP = np.where(np.array(Y)==1)\n    XN = X[idxN]\n    XP = X[idxP]\n\n    # plot two classes\n    plt.scatter(XN[:,0],XN[:,1],c='b', marker='_', label=\"Negative class\")\n    plt.scatter(XP[:,0],XP[:,1],c='r', marker='+', label=\"Positive class\")\n    # plt.plot(XN[:,0],XN[:,1],'b_', markersize=8, label=\"Negative class\")\n    # plt.plot(XP[:,0],XP[:,1],'r+', markersize=8, label=\"Positive class\")\n    plt.title(\"Perceptron Algorithm iteration: {}\".format(epoch))\n\n    # plot decision boundary orthogonal to w\n    # w is w2,w1, w0  last term is bias.\n    if len(w) == 3:\n        a  = -w[0] / w[1]\n        b  = -w[0] / w[2]\n        xx = [ 0, a]\n        yy = [b, 0]\n        plt.plot(xx,yy,'--g',label='Decision Boundary')\n\n    if len(w) == 2:\n        x2=[ w[0],  w[1],  -w[1],  w[0]]\n        x3=[ w[0],  w[1],   w[1], -w[0]]\n\n        x2x3 =np.array([x2,x3])\n        XX,YY,U,V = list(zip(*x2x3))\n        ax = plt.gca()\n        ax.quiver(XX,YY,U,V,scale=1, color='g')\n\n    # Add labels\n    plt.xlabel('X')\n    plt.ylabel('Y')\n\n    # limits\n    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n    plt.xlim(x_min,x_max)\n    plt.ylim(y_min,y_max)\n\n    # lines from origin\n    plt.axhline(y=0, color='k', linestyle='--',alpha=0.2)\n    plt.axvline(x=0, color='k', linestyle='--',alpha=0.2)\n    plt.grid(True)\n    plt.legend(loc=1)\n    plt.show()\n\n    # Always clost the plot\n    plt.close()\n\n\ndef predict(X,w):\n    return np.sign(np.dot(X, w))\n\ndef plot_contour(X,Y,w,mesh_stepsize):\n    try:\n        plt.style.use('seaborn-darkgrid')\n        # plt.style.use('ggplot')\n        #plt.style.available\n    except:\n        pass    \n    # Get data for two classes\n    idxN = np.where(np.array(Y)==-1)\n    idxP = np.where(np.array(Y)==1)\n    XN = X[idxN]\n    XP = X[idxP]\n\n    # plot two classes with + and - sign\n    fig, ax = plt.subplots()\n    ax.set_title('Perceptron Algorithm')\n    plt.xlabel(\"X\")\n    plt.ylabel(\"Y\")\n    plt.plot(XN[:,0],XN[:,1],'b_', markersize=8, label=\"Negative class\")\n    plt.plot(XP[:,0],XP[:,1],'y+', markersize=8, label=\"Positive class\")\n    plt.legend()\n\n    # create a mesh for contour plot\n    # We first make a meshgrid (rectangle full of pts) from xmin to xmax and ymin to ymax.\n    # We then predict the label for each grid point and color it.\n    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n\n    # Get 2D array for grid axes xx and yy  (shape = 700, 1000)\n    # xx has 700 rows.\n    # xx[0] has 1000 values.\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, mesh_stepsize),\n                         np.arange(y_min, y_max, mesh_stepsize))\n\n    # Get 1d array for x and y axes\n    xxr = xx.ravel()  # shape (700000,)\n    yyr = yy.ravel()  # shape (700000,)\n\n    # ones vector\n    # ones = np.ones(xxr.shape[0]) # shape (700000,)\n    ones = np.ones(len(xxr)) # shape (700000,)\n\n    # Predict the score\n    Xvals  = np.c_[ones, xxr, yyr]\n    scores = predict(Xvals, w)\n\n    # Plot contour plot\n    scores = scores.reshape(xx.shape)\n    ax.contourf(xx, yy, scores, cmap=plt.cm.Paired)\n    # print(\"xx.shape = {}\".format(xx.shape))               # (700, 1000)\n    # print(\"scores.shape = {}\".format(scores.shape))       # (700, 1000)\n    # print(\"scores[0].shape = {}\".format(scores[0].shape)) # (1000,)\n\n    # show the plot\n    plt.savefig(\"Perceptron.png\")\n    plt.show()\n    plt.close()\n\ndef perceptron_sgd(X, Y,epochs):\n    \"\"\"\n    X: data matrix without bias.\n    Y: target\n    \"\"\"\n    # add bias to X's first column\n    ones = np.ones(X.shape[0]).reshape(X.shape[0],1)\n    X1 = np.append(ones, X, axis=1)\n\n\n    w = np.zeros(X1.shape[1])\n    final_iter = epochs\n\n    for epoch in range(epochs):\n        print(\"\\n\")\n        print(\"epoch: {} {}\".format(epoch, '-'*30))\n\n        misclassified = 0\n        for i, x in enumerate(X1):\n            y = Y[i]\n            h = np.dot(x, w)*y\n\n            if h <= 0:\n                w = w + x*y\n                misclassified += 1\n                print('misclassified? yes  w: {} '.format(w,i))\n\n            else:\n                print('misclassified? no  w: {}'.format(w))\n                pass\n\n        if misclassified == 0:\n            final_iter = epoch\n            break\n\n    return w, final_iter\n\ndef gen_lin_separable_data(data, data_tr, data_ts,data_size):\n    mean1 = np.array([0, 2])\n    mean2 = np.array([2, 0])\n    cov = np.array([[0.8, 0.6], [0.6, 0.8]])\n    X1 = np.random.multivariate_normal(mean1, cov, size=int(data_size/2))\n    y1 = np.ones(len(X1))\n    X2 = np.random.multivariate_normal(mean2, cov, size=int(data_size/2))\n    y2 = np.ones(len(X2)) * -1\n\n\n    with open(data,'w') as fo, \\\n         open(data_tr,'w') as fo1, \\\n         open(data_ts,'w') as fo2:\n        for i in range( len(X1)):\n            line = '{:5.2f} {:5.2f} {:5.0f} \\n'.format(X1[i][0], X1[i][1], y1[i])\n            line2 = '{:5.2f} {:5.2f} {:5.0f} \\n'.format(X2[i][0], X2[i][1], y2[i])\n            fo.write(line)\n            fo.write(line2)\n\n        for i in range( len(X1) - 20):\n            line = '{:5.2f} {:5.2f} {:5.0f} \\n'.format(X1[i][0], X1[i][1], y1[i])\n            line2 = '{:5.2f} {:5.2f} {:5.0f} \\n'.format(X2[i][0], X2[i][1], y2[i])\n            fo1.write(line)\n            fo1.write(line2)\n\n        for i in range((len(X1) - 20), len(X1) ):\n            line = '{:5.2f} {:5.2f} {:5.0f} \\n'.format(X1[i][0], X1[i][1], y1[i])\n            line2 = '{:5.2f} {:5.2f} {:5.0f} \\n'.format(X2[i][0], X2[i][1], y2[i])\n            fo2.write(line)\n            fo2.write(line2)\n\ndef main():\n    \"\"\"Run main function.\"\"\"\n\n    # generate linearly separable data\n    data = 'data.txt'\n    data_tr = 'data_train.txt'\n    data_ts = 'data_test.txt'\n    data_size = 200\n    gen_lin_separable_data(data, data_tr, data_ts,data_size)\n\n    # read data\n    epochs = 20\n    X_train, Y_train = read_data(data_tr)\n    X_test, Y_test = read_data(data_ts)\n\n    # fit perceptron \n    w, final_iter = perceptron_sgd(X_train,Y_train,epochs)\n    print('w = ', w)\n\n    plot_boundary(X_test,Y_test,w,final_iter)\n\n    # contour plot\n    mesh_stepsize = 0.01\n    plot_contour(X_test,Y_test,w,mesh_stepsize)\n\nif __name__ == \"__main__\":\n    main()\n",
    "#!python\n# -*- coding: utf-8 -*-#\n\"\"\"\nPerceptron Algorithm.\n\n@author: Bhishan Poudel\n\n@date:  Oct 31, 2017\n\n\"\"\"\n# Imports\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom numpy.linalg import norm\nimport os, shutil\nnp.random.seed(100)\n\ndef read_data(infile):\n    data = np.loadtxt(infile)\n    X = data[:,:-1]\n    Y = data[:,-1]\n\n    return X, Y\n\ndef plot_boundary(X,Y,w,epoch):\n    try:\n        plt.style.use('seaborn-darkgrid')\n        # plt.style.use('ggplot')\n        #plt.style.available\n    except:\n        pass\n\n    # Get data for two classes\n    idxN = np.where(np.array(Y)==-1)\n    idxP = np.where(np.array(Y)==1)\n    XN = X[idxN]\n    XP = X[idxP]\n\n    # plot two classes\n    plt.scatter(XN[:,0],XN[:,1],c='b', marker='_', label=\"Negative class\")\n    plt.scatter(XP[:,0],XP[:,1],c='r', marker='+', label=\"Positive class\")\n    # plt.plot(XN[:,0],XN[:,1],'b_', markersize=8, label=\"Negative class\")\n    # plt.plot(XP[:,0],XP[:,1],'r+', markersize=8, label=\"Positive class\")\n    plt.title(\"Perceptron Algorithm iteration: {}\".format(epoch))\n\n    # plot decision boundary orthogonal to w\n    # w is w2,w1, w0  last term is bias.\n    if len(w) == 3:\n        a  = -w[0] / w[1]\n        b  = -w[0] / w[2]\n        xx = [ 0, a]\n        yy = [b, 0]\n        plt.plot(xx,yy,'--g',label='Decision Boundary')\n\n    if len(w) == 2:\n        x2=[ w[0],  w[1],  -w[1],  w[0]]\n        x3=[ w[0],  w[1],   w[1], -w[0]]\n\n        x2x3 =np.array([x2,x3])\n        XX,YY,U,V = list(zip(*x2x3))\n        ax = plt.gca()\n        ax.quiver(XX,YY,U,V,scale=1, color='g')\n\n    # Add labels\n    plt.xlabel('X')\n    plt.ylabel('Y')\n\n    # limits\n    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n    plt.xlim(x_min,x_max)\n    plt.ylim(y_min,y_max)\n\n    # lines from origin\n    plt.axhline(y=0, color='k', linestyle='--',alpha=0.2)\n    plt.axvline(x=0, color='k', linestyle='--',alpha=0.2)\n    plt.grid(True)\n    plt.legend(loc=1)\n    plt.show()\n    plt.savefig('img/iter_{:03d}'.format(int(epoch)))\n\n    # Always clost the plot\n    plt.close()\n\n\ndef predict(X,w):\n    return np.sign(np.dot(X, w))\n\ndef plot_contour(X,Y,w,mesh_stepsize):\n    try:\n        plt.style.use('seaborn-darkgrid')\n        # plt.style.use('ggplot')\n        #plt.style.available\n    except:\n        pass    \n    # Get data for two classes\n    idxN = np.where(np.array(Y)==-1)\n    idxP = np.where(np.array(Y)==1)\n    XN = X[idxN]\n    XP = X[idxP]\n\n    # plot two classes with + and - sign\n    fig, ax = plt.subplots()\n    ax.set_title('Perceptron Algorithm')\n    plt.xlabel(\"X\")\n    plt.ylabel(\"Y\")\n    plt.plot(XN[:,0],XN[:,1],'b_', markersize=8, label=\"Negative class\")\n    plt.plot(XP[:,0],XP[:,1],'y+', markersize=8, label=\"Positive class\")\n    plt.legend()\n\n    # create a mesh for contour plot\n    # We first make a meshgrid (rectangle full of pts) from xmin to xmax and ymin to ymax.\n    # We then predict the label for each grid point and color it.\n    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n\n    # Get 2D array for grid axes xx and yy  (shape = 700, 1000)\n    # xx has 700 rows.\n    # xx[0] has 1000 values.\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, mesh_stepsize),\n                         np.arange(y_min, y_max, mesh_stepsize))\n\n    # Get 1d array for x and y axes\n    xxr = xx.ravel()  # shape (700000,)\n    yyr = yy.ravel()  # shape (700000,)\n\n    # ones vector\n    # ones = np.ones(xxr.shape[0]) # shape (700000,)\n    ones = np.ones(len(xxr)) # shape (700000,)\n\n    # Predict the score\n    Xvals  = np.c_[ones, xxr, yyr]\n    scores = predict(Xvals, w)\n\n    # Plot contour plot\n    scores = scores.reshape(xx.shape)\n    ax.contourf(xx, yy, scores, cmap=plt.cm.Paired)\n    # print(\"xx.shape = {}\".format(xx.shape))               # (700, 1000)\n    # print(\"scores.shape = {}\".format(scores.shape))       # (700, 1000)\n    # print(\"scores[0].shape = {}\".format(scores[0].shape)) # (1000,)\n\n    # show the plot\n    plt.savefig(\"Perceptron.png\")\n    plt.show()\n    plt.close()\n\ndef perceptron_sgd(X, Y,epochs):\n    \"\"\"\n    X: data matrix without bias.\n    Y: target\n    \"\"\"\n    # add bias to X's first column\n    ones = np.ones(X.shape[0]).reshape(X.shape[0],1)\n    X1 = np.append(ones, X, axis=1)\n\n\n    w = np.zeros(X1.shape[1])\n    final_iter = epochs\n\n    for epoch in range(epochs):\n        print(\"\\n\")\n        print(\"epoch: {} {}\".format(epoch, '-'*30))\n\n        misclassified = 0\n        for i, x in enumerate(X1):\n            y = Y[i]\n            h = np.dot(x, w)*y\n\n            if h <= 0:\n                w = w + x*y\n                misclassified += 1\n                print('misclassified? yes  w: {} '.format(w,i))\n\n            else:\n                print('misclassified? no  w: {}'.format(w))\n                pass\n\n        if misclassified == 0:\n            final_iter = epoch\n            break\n\n    return w, final_iter\n\ndef aperceptron_sgd(X, Y,epochs):    \n    # initialize weights\n    w = np.zeros(X.shape[1] )\n    u = np.zeros(X.shape[1] )\n    b = 0\n    beta = 0\n\n    # counters    \n    final_iter = epochs\n    c = 1\n    converged = False\n\n    # main average perceptron algorithm\n    for epoch in range(epochs):\n        # initialize misclassified\n        misclassified = 0\n\n        # go through all training examples\n        for  x,y in zip(X,Y):\n            h = y * (np.dot(x, w) + b)\n\n            if h <= 0:\n                w = w + y*x\n                b = b + y\n\n                u = u+ y*c*x\n                beta = beta + y*c\n                misclassified += 1\n\n        # update counter regardless of good or bad classification        \n        c = c + 1\n\n        # break loop if w converges\n        if misclassified == 0:\n            final_iter = epoch\n            converged = True\n            print(\"Averaged Perceptron converged after: {} iterations\".format(final_iter))\n            break\n\n    if converged == False:\n        print(\"Averaged Perceptron DID NOT converged.\")\n\n    # prints\n    # print(\"final_iter = {}\".format(final_iter))\n    # print(\"b, beta, c , (b-beta/c)= {} {} {} {}\".format(b, beta, c, (b-beta/c)))\n    # print(\"w, u, (w-u/c) {} {} {}\".format(w, u, (w-u/c)) )\n\n\n    # return w and final_iter\n    w = w - u/c\n    b = np.array([b- beta/c])\n    w = np.append(b, w)\n\n    return w, final_iter\n\ndef main():\n    \"\"\"Run main function.\"\"\"\n\n    X, Y = read_data('data.txt') # X is without bias\n    max_iter = 20\n    w, final_iter = aperceptron_sgd(X,Y,max_iter)\n    print('w = ', w)\n\n    plot_boundary(X,Y,w,final_iter)\n\n    # contour plot\n    mesh_stepsize = 0.01\n    plot_contour(X,Y,w,mesh_stepsize)\n\nif __name__ == \"__main__\":\n    main()\n",
    "    Collecting numpy==1.9.2\n/Library/Python/2.7/site-packages/pip-7.1.2-py2.7.egg/pip/_vendor/requests/packages/urllib3/util/ssl_.py:90: InsecurePlatformWarning: A true SSLContext object is not available. This prevents urllib3 from configuring SSL appropriately and may cause certain SSL connections to fail. For more information, see https://urllib3.readthedocs.org/en/latest/security.html#insecureplatformwarning.\n  InsecurePlatformWarning\n  Using cached numpy-1.9.2-cp27-none-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\nInstalling collected packages: numpy\n  Found existing installation: numpy 1.10.1\n    Uninstalling numpy-1.10.1:\n\n    OSError: [Errno 13] Permission denied: '/Library/Python/2.7/site-packages/numpy-1.10.1.dist-info/DESCRIPTION.rst'\n",
    "diffs = array1 - array2\n\ndiffs == array([ 0.1,  0.2,  0.3])\n",
    "if not len(x)==len(y)==len(z):\n    raise TypeError(\"inputs x,y,z must all be 1D arrays of the same length\")\n\n# Check input arguments.\nx = np.asanyarray(x, dtype=np.float64)\ny = np.asanyarray(y, dtype=np.float64)\nz = np.asanyarray(z, dtype=np.float64)\nif x.shape != y.shape or x.shape != z.shape or x.ndim != 1:\n    raise ValueError(\"x, y and z must be equal-length 1-D arrays\")\n",
    "import numpy as np\n",
    "with open('fname.m') as f:\n    for _ in range(i):\n         line = f.next()\n    cell = line.split()[j]\n",
    "ZEROS = np.zeros((4,4), dtype=np.int)\n\ndf = pd.DataFrame(ZEROS,  columns=['A1','B1','C1','D1'])\ndf.iat[2,3] = 32\ndf\n\n   A1  B1  C1  D1\n0   0   0   0   0\n1   0   0   0   0\n2   0   0   0  32\n3   0   0   0   0\n",
    "    import random\n    #Manhattan Distance\n    def L1(v1,v2):\n      if(len(v1)!=len(v2):\n        print \u201cerror\u201d\n        return -1\n      return sum([abs(v1[i]-v2[i]) for i in range(len(v1))])\n\n    # kmeans with L1 distance. \n    # rows refers to the NxM feature vectors\n    def kcluster(rows,distance=L1,k=4):# Cited from Programming Collective Intelligence \n        # Determine the minimum and maximum values for each point\n        ranges=[(min([row[i] for row in rows]),max([row[i] for row in rows])) for i in range(len(rows[0]))]\n\n        # Create k randomly placed centroids\n        clusters=[[random.random( )*(ranges[i][1]-ranges[i][0])+ranges[i][0] for i in range(len(rows[0]))] for j in range(k)]\n\n        lastmatches=None\n        for t in range(100):\n            print 'Iteration %d' % t\n            bestmatches=[[] for i in range(k)]\n            # Find which centroid is the closest for each row\n            for j in range(len(rows)):\n                row=rows[j]\n                bestmatch=0\n                for i in range(k):\n                    d=distance(clusters[i],row)\n                    if d<distance(clusters[bestmatch],row): \n                        bestmatch=i\n                bestmatches[bestmatch].append(j)\n            ## If the results are the same as last time, this is complete\n            if bestmatches==lastmatches:\n                break\n            lastmatches=bestmatches\n\n            # Move the centroids to the average of their members\n            for i in range(k):\n                avgs=[0.0]*len(rows[0])\n                if len(bestmatches[i])>0:\n                    for rowid in bestmatches[i]:\n                        for m in range(len(rows[rowid])):\n                            avgs[m]+=rows[rowid][m]\n                    for j in range(len(avgs)):\n                        avgs[j]/=len(bestmatches[i])\n                    clusters[i]=avgs\n        return bestmatches\n",
    "average = numpy.column_stack((y,y2)).mean(axis=1)\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nx1, y1 = np.loadtxt('C:\\\\Users\\\\user\\\\Desktop\\\\data\\\\input_temperature1.txt', delimiter=',', unpack=True)\nplt.plot(x1,y1, color='Blue', label='Input temperature 1')\n\nx2, y2 = np.loadtxt('C:\\\\Users\\\\user\\\\Desktop\\\\data\\\\input_temperature2.txt', delimiter=',', unpack=True)\nplt.plot(x2,y2,color='Red', label='Input temperature 2')\n\naverage = numpy.column_stack((y1,y2)).mean(axis=1)\nplt.plot(x2,average,color='green', label='Average Temperature')\n\nplt.xlabel('x')\nplt.ylabel('y')\nplt.title('Temperature Comparison Plot')\nplt.legend()\nplt.show()\n"
   ]
  },
  {
   "questions": [
    "` .dot(M).dot( .T) ` native numpy?: vector matrix compution great follows: 'd perform transform had many , : fails Z (sensibly) ends (99x99). 'd (99x1) (1x99), calculated, : calculate Z2 directly numpy, instead using iteration?",
    "Flatten y matrix repeat -vector: vector matrix y y[ ] = [f( [ ]),f( [ ]),f( [ ])...] experimental f . flatten y vectors y[ ] = f( [ ]). 's 'm using now: cleaner/faster ?",
    "count nonzero array ?: array follows: 'd determine sum index [ ] . , here 'd . 'm bounds . ideas?",
    "append vector matrix : append vector matrix . append concatenate methods didn't answer. previously working Matlab used : using numpy? thanks",
    "Flatten numpy array: solving ODE follows: : 'd single dimensional array follows: ?",
    "Converting : function follows .csv store array. 'm simply .tsv form. far : However, call : : causing issue fix ?",
    "faster results?: : y. calculate correlation coefficient follows: answer correct. However, better faster ways using numpy / scipy.",
    "Recursion: IIR filter `scipy.lfilter`: Given : calculate vector y follows: Where alpha equals .03, case. Can scipy.lfilter?. Similar here, case starting throwing off. attempt: results :",
    "Use delimiters numpy: save nx3 array np.savetxt(' .dat', X, delimiter='-'). Now comes clue: Instead using '-' '-' , ';' : fast easy ? Kind regards",
    "overplot scatter ?: vectors 've put matplotlib.scatter(). Now 'd linear fit . ? 've using scikitlearn np.scatter."
   ],
   "code": [
    "(x.dot(M) * x).sum(axis=1)\n\nr = 1000\nc = 10000\nx = np.ones((r, c)) # rxc\nM = np.ones((c, c)) # cxc square\n\n%timeit (x.dot(M) * x).sum(axis=1) \n>> 1 loop, best of 3: 1.59 s per loop\n%timeit np.array([row.dot(M).dot(row.T) for row in x])\n>> 1 loop, best of 3: 41.9 s per loop\n",
    "x = x.repeat(y.shape[1])\n",
    "# if the array contains only 0 and 1\na[:,3].sum()\n# 2\n\n# if the array can have other values besides 0 and 1\nnp.count_nonzero(a[:,3])\n# 2\n",
    "import numpy as np\nm = np.zeros((10, 4))\nv = np.ones((10, 1))\nc = np.c_[m, v]\n\narray([[ 0.,  0.,  0.,  0.,  1.],\n       [ 0.,  0.,  0.,  0.,  1.],\n       [ 0.,  0.,  0.,  0.,  1.],\n       [ 0.,  0.,  0.,  0.,  1.],\n       [ 0.,  0.,  0.,  0.,  1.],\n       [ 0.,  0.,  0.,  0.,  1.],\n       [ 0.,  0.,  0.,  0.,  1.],\n       [ 0.,  0.,  0.,  0.,  1.],\n       [ 0.,  0.,  0.,  0.,  1.],\n       [ 0.,  0.,  0.,  0.,  1.]])\n\nIn [7]: np.r_[1:5, 2]\nOut[7]: array([1, 2, 3, 4, 2])\n\nIn [8]: np.c_[m, 0:10]\nOut[8]:\narray([[ 0.,  0.,  0.,  0.,  0.],\n       [ 0.,  0.,  0.,  0.,  1.],\n       [ 0.,  0.,  0.,  0.,  2.],\n       [ 0.,  0.,  0.,  0.,  3.],\n       [ 0.,  0.,  0.,  0.,  4.],\n       [ 0.,  0.,  0.,  0.,  5.],\n       [ 0.,  0.,  0.,  0.,  6.],\n       [ 0.,  0.,  0.,  0.,  7.],\n       [ 0.,  0.,  0.,  0.,  8.],\n       [ 0.,  0.,  0.,  0.,  9.]])\n",
    "print(xplotval.flatten())\n\nprint(np.transpose(xplotval))\n",
    "traindata = list(np.array(p.read_table('train.tsv'))[:,2])\n          # ^ here\n\ntraindata = np.array(p.read_table('train.tsv'))[:,2]\n\nm, n = traindata.shape\n",
    "xx = x.reshape(2,-1).T  # faster, minor issue though\nyy = y.reshape(2,-1).T\nresults = [pearsonr(a,b)[0] for a,b in zip(xx,yy)]\nresults = np.array(results).reshape(x.shape[1:])\n\nnp.array([... for .. in ...]) \n\ndef pearsonr2(a,b):\n    # stats.pearsonr adapted for\n    # x and y are (N,2) arrays\n    n = x.shape[1]\n    mx = x.mean(1)\n    my = y.mean(1)\n    xm, ym = x-mx[:,None], y-my[:,None]\n    r_num = np.add.reduce(xm * ym, 1)\n    r_den = np.sqrt(stats.ss(xm,1) * stats.ss(ym,1))\n    r = r_num / r_den\n    r = np.clip(r, -1.0, 1.0)\n    return r\n\nprint pearsonr2(xx,yy)\n\ndef pearsonr_flex(a,b, axis=1):\n    # stats.pearsonr adapted for\n    # x and y are (N,2) arrays\n    n = x.shape[axis]\n    mx = x.mean(axis, keepdims=True)\n    my = y.mean(axis, keepdims=True)\n    xm, ym = x-mx, y-my\n    r_num = np.add.reduce(xm * ym, axis)\n    r_den = np.sqrt(stats.ss(xm, axis) * stats.ss(ym, axis))\n    r = r_num / r_den\n    r = np.clip(r, -1.0, 1.0)\n    return r\n\npearsonr_flex(xx, yy, 1)\npreasonr_flex(x, y, 0)\n",
    "zi = lfiltic([a], [1, -b], y=[x[0]])\n\ny, zo = lfilter([a], [1, -b], x, zi=zi)\n\nIn [37]: x\nOut[37]: array([ 3.,  1.,  2.,  0., -1.,  2.])\n\nIn [38]: y\nOut[38]: \narray([ 3.        ,  2.94      ,  2.9118    ,  2.824446  ,  2.70971262,\n        2.68842124])\n\nIn [39]: true_y\nOut[39]: \narray([ 3.        ,  2.94      ,  2.9118    ,  2.824446  ,  2.70971262,\n        2.68842124])\n",
    "import numpy as np\nM = np.arange(4*3).reshape(4, 3)\nnp.savetxt(\"arange.mat\", M, fmt=\"%i-%i;%i\")\n\n0-1;2\n3-4;5\n6-7;8\n9-10;11\n",
    "import numpy as np\nimport matplotlib.pyplot as plt\n\n# sample data\nx = np.arange(10)\ny = 5*x + 10 \n\n# fit with np.polyfit\nm, b = np.polyfit(x, y, 1)\n\nplt.plot(x, y, '.')\nplt.plot(x, m*x + b, '-')\n"
   ]
  },
  {
   "questions": [
    "Can ndarray store datetime float?: numpy datastructure store datetime float ?",
    "format numpy array format?: numpy array : format : ?",
    "numpy.ndarray object date object: numpy.ndarray object Could anyone please tell date object",
    "Reshaping numpy array custom : numpy array; reshape array ?",
    "Check numpy array sorted: numpy array check sorted.",
    "Converting datatime.datetime float: ; : basically datetime.datetime timestamp, dtype = float.",
    "Numpy array dictionary: numpy array dictionary",
    "remove numpy array NaN element?: numpy array : remove array nan element?",
    "Convert variable datetime.timedelta numpy.timedelta64: variable 's datetime.timedelta numpy.timedelta64?",
    "delete element np. array appropriate element?: numpy array delete : ever :"
   ],
   "code": [
    "import numpy as np\nx = np.array([(np.datetime64('2017-01-30'), 1.0),\n              (np.datetime64('2017-01-31'), 2.0)],\n              dtype=[('datetime', 'datetime64[D]'), ('number', 'f8')])\n\n>>> x['datetime']\narray(['2017-01-30', '2017-01-31'], dtype='datetime64[D]')\n>>> x['number']\narray([ 1.,  2.])\n>>> x['datetime'][0] + 5\nnumpy.datetime64('2017-02-04')\n>>> x['number'][1] + 5\n7.0\n",
    "a = [[0.04393, 0.0, 0.0], [0.04393, 0.005, 0.0], [0.04393, 0.01, 0.0],[0.04393, 0.015, 0.0]]\nb = [ (tuple(a1),) for a1 in a]\n",
    "import datetime as dt\nimport numpy as np\n\nx = np.array([[ 2016., 1., 1.], [ 2016., 12., 31.]])\n\nstring = [dt.datetime(*el).strftime('%Y-%m-%d') for el in x.astype(int)]\nstring\n['2016-01-01', '2016-12-31']\n\ndatetime = np.array(datetime, dtype='datetime64[D]')\ndatetime\narray(['2016-01-01', '2016-12-31'], dtype='datetime64[D]')\n",
    ">>> arr = np.array([[-0.17433028, -0.20116786, -0.17599097, -0.1907735, 0.27599955, -0.16071874], [-0.21809219, -0.20256139, -0.15900832, -0.18323743, -0.26910328,  0.78731642]])\n\n>>> arr.transpose()\narray([[-0.17433028, -0.21809219],\n       [-0.20116786, -0.20256139],\n       [-0.17599097, -0.15900832],\n       [-0.1907735 , -0.18323743],\n       [ 0.27599955, -0.26910328],\n       [-0.16071874,  0.78731642]])\n",
    "np.diff(a)>=0\n\nimport numba\n@numba.jit\ndef is_sorted(a):\n    for i in range(a.size-1):\n         if a[i+1] < a[i] :\n               return False\n    return True\n",
    "import datetime as dt\n\ntimes = np.array([\n    dt.datetime(2014, 2, 1, 0, 0, 0, 100000),\n    dt.datetime(2014, 2, 1, 0, 0, 0, 300000),\n    dt.datetime(2014, 2, 1, 0, 0, 0, 500000),\n])\n\n# get a datetime that is equal to epoch\nepoch = dt.datetime(1970, 1, 1)\n\nfor t in [(d - epoch).total_seconds() for d in times]:\n    print('%.6f' % t)\n\n1391212800.100000\n1391212800.300000\n1391212800.500000\n",
    "a = numpy.array([['5.1', '3.5', '1.4', '0.2', 'Setosa'],\n                 ['4.9', '3.0', '1.4', '0.2', 'Versicolor']])\nb = {tuple(x[:-1]) : x[-1] for x in a}\n\n{('5.1', '3.5', '1.4', '0.2'): 'Setosa', ('4.9', '3.0', '1.4', '0.2'): 'Versicolor'}\n",
    "y = x[~np.isnan(x[:, 0])]\n",
    "array([datetime.timedelta(1)], dtype=\"timedelta64[ms]\")[0]\n",
    "[X_test[:i] + X_test[i+1:] for i in range(len(X_test))]\n"
   ]
  },
  {
   "questions": [
    "gradually write amounts memory?: performing signal processing task dataset images, converting images feature vectors certain structure (number_of_transforms, width, height, depth). feature vectors ( coefficients ) too keep memory once, writing np.mmap, : purpose, downside: load coefficients certain \" \" ( transform tested hyperparameters) later analysis, somehow reconstruct original (number_of_transforms, width, height, depth), bound messy. cleaner (preferable numpy compatible) , allowing retain structure type transform feature vectors, while still intermittently writing results transform disk?"
   ],
   "code": [
    "coefficients = numpy.lib.format.open_memmap(\n    output_location, dtype=np.float32, mode=\"w+\",\n    shape=(n_samples, number_of_transforms, width, height, depth))\n\ncoefficients = numpy.lib.format.open_memmap(output_location)\n"
   ]
  },
  {
   "questions": [
    "Splitting matrix multiplication: below computation : : compute vector [ 5, 5, 5] & [11, 11, 11] individually instead computing within matrix dot product ? 'm sure . 've accessing single X returns : Update : 'm attempting compute [ 5, 5, 5] [11, 11, 11] both, ? Update : modifying X leaving weights ?",
    "Fastest compute matrix multiplication: compute matrix multiplication follows: computation C takes 10 minutes. improve ? Update",
    "Splitting matrix multiplication using einsum: matrix calculate similarity matrix matrix due memory limitation split calculation. Lets assume : taken smaller matrix They : n1,n2,m1,m2 been calculated follows: (df frame) :",
    "Printing matrix numpy, : matrix. missing? :",
    "Multidimensional matrix multiplication : matrix dimension 500x2000x30 matrix B dimension 30x5. You think 500 instances 2000x30 matrix dimension 500x2000x30. multiply 1x2000x30 matrix B obtain matrix 1x2000x5. .e. X B give matrix dimension 500x2000x5 Obviously looping 500 times matrix efficient achieve ? Edit: Both B numpy",
    "Create matrix : n ^n matrix distinct? , n = itertools tuples. those matrix?",
    "3D Matrix multiplication numpy theano: matrix (5,7, ) matrix B (5, ,8). multiply C = .B, C (5,7,8). means submatrix (7, ) matrix multiplied submatrix ( ,8) matrix B respectively. multiply 5 times. simplest using numpy: using ? equivalent Theano using scan?",
    "Initializing matrix random range - : initialize matrix random (say .01)? : specify range random numbers ( .01)?",
    "concatenated matrix multiplication: suggestions fast multiply * diag(e) * ^T * f dense matrix vectors e, f? now. ,",
    "Partial sum : matrix sum subset matrix , lists imp_list bath_list. 'm right now: appears slow. better perform sum?"
   ],
   "code": [
    "import numpy as np\n\nweights = np.array([[1,2] , [3,4]])\nX = np.array([[1,1,1] , [2,2,2]])\nfor row_vec in weights:\n    print(np.dot(row_vec , X))\n\n[5 5 5]\n[11 11 11]\n\nprint(np.dot(weights[0] , X))  # -> [5 5 5]\n\nprint(np.dot(weights[1] , X))  # -> [11 11 11]\n",
    "import dask\nimport dask.array\n\nA = dask.array.random.random((1, 3000, 300000), chunks=1024)\nB = dask.array.random.random((50, 1, 300000), chunks=1024)\n\nC = A * B\n\ndask.array.to_hdf5('myfile.hdf5', '/C', C)\n\npip install dask[array]\npip instal h5py\n\nfor i in B.shape[0]:\n    C = A * B[i, ...]  # do not save this result but rather use and discard it immediately\n",
    "similarity_matrix = np.empty((N,M),dtype=float)\n\npartial_matrix = np.einsum...\n",
    "print numpy.matrix(...)\n\nimport numpy as np\n\nprint np.matrix(...)\n",
    "np.dot(A, B)\n\n dot(a, b)[i,j,k,m] = sum(a[i,j,:] * b[k,:,m])\n",
    ">>> np.matrix(list(itertools.product([0,1],repeat = 2)))\nmatrix([[0, 0],\n        [0, 1],\n        [1, 0],\n        [1, 1]])\n",
    "C = numpy.einsum('ijk,ikl->ijl', A, B)\n\nC = numpy.matmul(A,B)\n\nC = theano.tensor.batched_dot(A, B)\n",
    "# 0 to 0.001\nA = numpy.random.rand(2,3) * 0.01\n\n# 0.75 to 1.5\nmin = 0.75\nmax = 1.5\nA = ( numpy.random.rand(2,3) * (max - min) ) + min\n\nA = numpy.random.uniform(low=0.75, high=1.5, size=(2,3) )\n",
    "In [95]: a\nOut[95]: \narray([[1, 2, 3],\n       [4, 5, 6],\n       [7, 8, 9]])\n\nIn [96]: e\nOut[96]: array([-1,  2,  3])\n\nIn [97]: f\nOut[97]: array([5, 4, 1])\n\nIn [98]: a.dot(np.diag(e)).dot(a.T).dot(f)\nOut[98]: array([ 556, 1132, 1708])\n\nIn [99]: np.einsum('ij,j,jk,k', a, e, a.T, f)\nOut[99]: array([ 556, 1132, 1708])\n\nIn [100]: np.einsum('ij,j,kj,k', a, e, a, f)\nOut[100]: array([ 556, 1132, 1708])\n",
    "K[np.ix_(imp_list, bath_list)].sum()\n\nK = np.arange(1000000).reshape(1000, 1000)\nimp_list = range(100)  # [0, 1, 2, ..., 99]\nbath_list = range(200) # [0, 1, 2, ..., 199]\n\ndef method1():\n    s = 0\n    for i in imp_list:\n        for j in bath_list:\n            s += K[i,j]\n    return s\n\ndef method2():\n    return K[np.ix_(imp_list, bath_list)].sum()\n\ndef method3():\n    return K[:100, :200].sum()\n\nIn [80]: method1() == method2() == method3()\nOut[80]: True\n\nIn [91]: %timeit method1()\n10 loops, best of 3: 9.93 ms per loop\n\nIn [92]: %timeit method2()\n1000 loops, best of 3: 884 \u00b5s per loop\n\nIn [93]: %timeit method3()\n10000 loops, best of 3: 34 \u00b5s per loop\n"
   ]
  },
  {
   "questions": [
    "fix convergence ? statsmodels: pertains statsmodels its general linear model class. Whenever array endogenous variable order magnitude apart, GLM converge throws exception. coded mean. , exception last . Why ? GLM converge? Are alternatives?",
    "'s difference (4,) (4, ) Numpy?: ndarray B, (4,) (4, ). When calculate cosine distance using , throws exceptions complains objects aligned Does anyone ideas ? !",
    "Unpacking array : variable (1000L, 3L) coordinates: unpack ? :",
    "- numpy too long prints weird?: When print array ( square) panel, format appears show weird. 19 won't square , puts last element onto next . When 18 , 's fine. 'm sure numpy issue platform ( Enthought Canopy). anything 19 print ? Output:",
    "Index ( bounds) accessing element array: 'm access element 2d created csv . print fine. When access array certain element ( .e. ' ' ' ' 5) throws : anyone great",
    "Using numpy.array dimensions: array dimensions numpy, throws exception: Are workarounds ? reasons why numpy allow creating ?",
    "Finding average variable objects : iterate group objects their mean most efficent ? uses (except perhaps loops Numpy) wondering whether better . At moment, : better ?",
    "numpy array: accessing element : throws exception: marked below. Why ? col_sig_squared array . Why 't access . Tried bunch things sure why syntax wrong. 'm its intricacies, appreciated.",
    "NaN TensorFlow: implementing regression model using TensorFlow always keep Nan variable. Below runs Nan. When command: program throws exception shown below: missing trivial here. Just pair eyes look . .",
    "Convert numpy matrix array: Are alternative better ways numpy matrix array ?"
   ],
   "code": [
    "    model = sm.GLM(actual, data1, formula=fml1,\n                   family=sm.families.Tweedie(link_power=1.1))\n\n    def callback(x):\n        x[x < 0] = 0\n\n    result = model.fit(method='newton', disp=True, start_params=np.ones(6),\n                       callback=callback)\n\nmodel = sm.GLM(actual, data1, formula=fml1,\n               family=sm.families.Tweedie(link_power=1.1))\nresult = model.fit(method='cg', disp=True, start_params=0.1 * np.ones(6))\n",
    ">>> import numpy as np\n>>> a = np.arange(4).reshape(4,1)\n>>> a\narray([[0],\n       [1],\n       [2],\n       [3]])\n>>> a.ravel()\narray([0, 1, 2, 3])\n>>> a.squeeze()\narray([0, 1, 2, 3])\n>>> a[:,0]\narray([0, 1, 2, 3])\n>>>\n>>> a[:,0].shape\n(4,)\n",
    "x, y, z = data.T\n",
    "numpy.set_printoptions(linewidth=200)\n",
    "import numpy\n\ndef create_alldata(whichfile):\n    return numpy.genfromtxt(whichfile)                     \n",
    "/*\n * There are several places in the code where an array of dimensions\n * is allocated statically.  This is the size of that static\n * allocation.\n *\n * The array creation itself could have arbitrary dimensions but all\n * the places where static allocation is used would need to be changed\n * to dynamic (including inside of several structures)\n */\n\n#define NPY_MAXDIMS 32\n#define NPY_MAXARGS 32\n",
    "import numpy as np\nscores, ratings = np.array([(t.score, t.rating) for t in text_collection]).T\n\nprint 'average score: ', np.mean(scores)\nprint 'average rating: ', np.mean(ratings)\nprint 'average positive score: ', np.mean(scores[scores > 0])\nprint 'average negative score: ', np.mean(scores[scores < 0])\n\nif np.count_nonzero(scores < 0):\n    print 'average negative score: ', np.mean(scores[scores < 0])\n",
    "col_sig_squared = [np.zeros(shape=(1,6), dtype=int)]\n\ncol_sig_squared = np.zeros(shape=(1,6), dtype=int)\n",
    "graph = tf.Graph()\nwith graph.as_default():\n    ...\n    initializer = tf.contrib.layers.xavier_initializer()\n    var1 = tf.Variable(initializer(var1_shape)\n    ...\n",
    "a = array.array('f',np.ravel(b))\n\nIn [107]: b\nOut[107]: \nmatrix([[ 1.,  2.,  3.],\n        [ 4.,  5.,  6.]], dtype=float16)\n\nIn [108]: array.array('f',np.ravel(b))\nOut[108]: array('f', [1.0, 2.0, 3.0, 4.0, 5.0, 6.0])\n"
   ]
  },
  {
   "questions": [
    "Pandas Dataframe, MOVE Specific Cell Value cell Another specific Columns ( ): copy under allergy three languages. Dataframes move specific cell English french dutch underneath . After 's been copied, delete English. Note: Index languages below. They go order French, English, Dutch, French, English, Dutch . Values typical responses under allergy note (Brackets they located excel) again summarise, copy specific cell English Dutch French Rows. edit: several however 'd change Column B Column D excel . 'd Columns remain . thus ignored. .e anything after Column D. Desired : (Brackets they located excel) Afterwards, Should look b d changed, excel. Final :"
   ],
   "code": [
    "df.loc[french,'allergy (column)'] = df.loc[english,allergy ( COLUMN D)]\n\ndf.drop('english',0,inplace=True)\n"
   ]
  },
  {
   "questions": [
    "Reading printing specific answer: text called CJ.txt containing (z mub) 31 . (( write important part program)). define call \"r\" reach appropriate answer : print r[25]. r[25]=mub[25]*z[25] Another r[ ], 31 obtained similar . creating array easy hard, important . appreciate your attention.",
    "Reading blocks text array: been killing day/night cannot seem come . Basically, text containing vector (generated C++ program) doubles. array spectrogram. : Each block separated lines within text . : However, seem lot generated. Anyone ideas solve ? P.S. block . However, shorten , included sample.",
    "Read specific lines text numpy array: txt he format: lines 4 6 numpy array. far 've got: reads required lines element, numbers separate separate . around ?",
    "remove specific element ?: remove element using B array IDs, specific scalar ID 'C' matlab : : delete box completely . ? numpy.",
    "Selecting numpy array specific < : numpy similar structure: Now 'd subset array those 3rd < 15. boolean : However cannot boolean indexing : Probably transform subset array, maybe -built function straight forward selecting specific array?",
    "sample # specific class ?: sample \" \" class \"labels\" . : ) sample ALL class (4 ) ) Then sample previous dataframe sure must better .",
    "Reading Multiple tiff files folder: folder containing 10K tiff files, import files using predictive modelling. thanks NK",
    "Use . () . (): here : several posts . () . () still 't really clearly explain fix . why wrote sure fix .",
    "Read text files long text : text : Now 40x1 matrix, 36x1 matrix separately, 40x36 matrix. Could anyone offer ? Regards Barack",
    "savetxt header: add header text 'm writing array : np.savetxt(' .txt', array, header = str(dimension)) default adds # front header. anyway rid ?"
   ],
   "code": [
    "z,mub=np.genfromtxt('CJ.txt',unpack=True) # opening the text file\nr = []\nfor i in range(len(z)): # This means from 0 to 31\n    r.append(mub[i]*z[i])  # need a function similar to this\n\nprint(r[5],r[31],r[2],r[12]) #and other r\n",
    "raw_text = \"\"\"-18.2258 -18.3581 -18.7323 -19.2183 -19.8016 -20.6132 -21.8101 -22.5386 -21.8071    \n-20.9063 -20.4136 -20.3022 -20.3428 -20.4091 -20.6703 -21.0293 -21.5167 -22.1915    \n-23.0438 -23.9086 -24.5955 -26.2508 -26.0188 -22.2163 -19.933 -18.6816 -18.1048\n-18.0222 18.3233 -19.0456 -20.3134 -22.7954 -25.8716 -21.4845 -19.1923 -17.9268 \n-17.4657 -17.3888 -16.9999 -16.4006 -15.9175 -15.8319 -16.1705 -16.6967 -17.0734 \n\n\n-7.92685 -10.8266 -16.392 -12.4901 -13.0831 -17.7215 -17.5159 -14.1485 -12.9897 -12.0444   \n-11.8363 -12.6952 -12.9652 -14.3788 -13.8465 -17.529 -17.4747 -11.9521 -12.545 -13.8976 \n-12.4176 -15.3273 -14.8081 -19.4117 -17.9596 -16.2607 -16.7505 -15.8918 -16.5602 \n-17.2225 -16.9048 -15.1381 -17.37 -16.43 -14.9437 -14.9821\"\"\"\n#in your example raw_text = open(some_file).read()\nblocks = raw_text.split(\"\\n\\n\\n\")\nsplit_blicks = [[float(v) for v in block.split()] for block in blocks]\n",
    "lines=[]\nwith open('filename', \"r\") as f:\n    for i, line in enumerate(x.split('\\n')):\n        if i>=3 and i<=5:\n            lines.append([int(y) for y in line.split()])\n\nlines = np.array(lines)\nprint type(lines)\n",
    "boxes = [[1,2,20,20],[4,8,20,20],[8,10,40,40]]\nIDx = 1\npop_element = boxes.pop(IDx)\n",
    ">>> my_array[:, my_array[2,:]>15]\narray([[  1,   2,   3,   3],\n       [  3,   3,   1,   2],\n       [ 32,  63, 763,  23],\n       [  2,   2,   3,   1],\n       [  1,   1,   1,   1]])\n",
    "df1.query('label == 1').sample(2)\n",
    "import os \nfrom PIL import Image\nimport numpy as np\n\ndirname = 'tiff_folder_path'\nfinal = []\nfor fname in os.listdir(dirname):\n    im = Image.open(os.path.join(dirname, fname))\n    imarray = np.array(im)\n    final.append(imarray)\n\nfinal = np.asarray(final) # shape = (60000,28,28)\n",
    ">>> valeur <= 0.6\narray([ True, False, False, False], dtype=bool)\n\n>>> np.any(valeur <= 0.6)\nTrue\n>>> np.all(valeur <= 0.6)\nFalse\n",
    "file = open(\"file.txt\", \"r\")\nlines = file.readlines()\n\n# k, a counter to loop on the lines\nk = 1\n# Matrix_list is a list of the matrix (size i*j) like that [40*1, 36*1, ...]\nMatrix_list = []\nwhile k < len(lines):\n    if \"#\" in lines[k-1] and \"#\" not in lines[k]:\n        # Start a new matrix\n        row = []\n\n        # Loop to get all the lines of the current matrix\n        while \"#\" not in lines[k]:\n\n            if k > len(lines):\n                break\n\n            row.appends(lines[k])\n            k +=1\n\n        # At this point, row is a list of every row of your matrix\n        # First we get the matrix size i*j and create a matrix\n        i = len(row)\n        j = len(row[0].split())\n        Mat = np.zeros((i, j))\n\n        row_position = 0\n\n        for elt in row:\n            colum_position = 0\n            L = elt.split()\n            for data in L:\n                Mat[row_position, colum_position] = data\n                colum_position += 1\n            row_position +=1\n\n         # Once all the data you had was palced in the matrix : \n         Matrix_list.append(Mat)\n\n    else:\n        k += 1\n",
    "np.savetxt('output.txt', array, header=str(dimension), comments='')\n"
   ]
  },
  {
   "questions": [
    "Classification numpy: Hi classify indexes numpy array. function ? Something : = [[ , , ] , [ , ,4] , [5,6,7] ,[ , , ] ,[ , , ] , [ , ,4]] f( ) returns indexes [[ , ,4],[ ,5],[ ]] appreciate your solutions Something : = [[ , , ] , [ , ,4] , [5,6,7] ,[ , , ] ,[ , , ] , [ , ,4]] f( ) returns indexes [[ , ,4],[ ,5],[ ]] appreciate your solutions appreciate your solutions",
    "location numpy array location equal array: , locations numpy array appear numpy array, locations too. 's best 've been : Anybody anything faster, numpy specific, \"pythonic\"?",
    "Inplace join sub numpy array: numpy array indexes tuple ( , ). join sub- sub indexes place. final expected somewhat - After join, meaning indexes order. That , [ , ,5,6] may well come after [ ,4]. Also, sub representative, non uniform. using inbuilt numpy function(s)?",
    "Apply function numpy. : Assume array: Using np. ( < ) returns < apply function those ?",
    ": numpy array?: array: write function takes 63 input, tells array? : function( ) returns [ , ]; function(13) returns [5, ]",
    "Operations numpy array : Have numpy array created . : subtract np.mean() single entry array? advance!",
    "index array slice numpy array : vector indexes vector . index indexes vector efficiently produce numpy array reslts results needs contain previous index , indexed next . : indexes big takes too much . ?",
    "ascii numpy array: ascii numpy array. failing , returns 'NaN' numpy.genfromtxt. Then reading array: printed : numpy presumption ?",
    "ascii numpy array: ascii numpy array. failing , returns 'NaN' numpy.genfromtxt. Then reading array: printed : numpy presumption ?",
    "Finding indexes present array : ( , ) Input: Output: pythonic shortcut achieve iterating index ?"
   ],
   "code": [
    "def classify_rows(a):\n    sidx = np.lexsort(a.T)\n    b = a[sidx]\n    m = ~(b[1:] == b[:-1]).all(1)\n    return np.split(sidx, np.flatnonzero(m)+1)\n\ndef classify_rows_list(a):\n    sidx = np.lexsort(a.T)\n    b = a[sidx]\n    m = np.concatenate(( [True], ~(b[1:] == b[:-1]).all(1), [True]))\n    l = sidx.tolist()\n    idx = np.flatnonzero(m)\n    return [l[i:j] for i,j in zip(idx[:-1],idx[1:])]\n\nIn [78]: a\nOut[78]: \narray([[1, 2, 3],\n       [2, 3, 4],\n       [5, 6, 7],\n       [1, 2, 3],\n       [1, 2, 3],\n       [2, 3, 4]])\n\nIn [79]: classify_rows(a)\nOut[79]: [array([0, 3, 4]), array([1, 5]), array([2])]\n\nIn [80]: classify_rows_list(a)\nOut[80]: [[0, 3, 4], [1, 5], [2]]\n",
    "uniq, inv = np.unique(np.r_[a, b], return_inverse=True)\nmap = -np.ones((len(uniq),), dtype=int)\nmap[inv[:len(a)]] = np.arange(len(a))\nbina = map[inv[len(a):]]\ninds_in_b = np.where(bina != -1)[0]\nelements, inds_in_a = b[inds_in_b], bina[inds_in_b]\n\ninds = np.argsort(a)\naso = a[inds]\nbina = np.searchsorted(aso[:-1], b)\ninds_in_b = np.where(b == aso[bina])[0]\nelements, inds_in_a = b[inds_in_b], inds[bina[inds_in_b]]\n",
    "def joinSubs(lst, tpl):\n    lst[tpl[0]] += lst[tpl[1]]\n    lst.pop(tpl[1])\n    return lst\n\njoinSubs([[1,2], [3,4], [5,6]], (0,2))\n\n[[1, 2, 5, 6], [3, 4]]\n\n>>> a = np.array([[1,2], [3,4], [5,6]])\n>>> a.tolist()\n[[1, 2], [3, 4], [5, 6]]\n",
    "In [2]: a = np.asarray([1,2,3,4,0,-1,-2,3,4])\n\nIn [3]: a[a < 0]\nOut[3]: array([-1, -2])\n\nIn [4]: np.sin(a[a < 0])\nOut[4]: array([-0.84147098, -0.90929743])\n\nIn [5]: a[a < 0]**2\nOut[5]: array([1, 4])\n\nIn [6]: a < 0\nOut[6]: array([False, False, False, False, False,  True,  True, False, False], dtype=bool)\n",
    "np.argwhere(a==13)\n\narray([[1, 5]])\n",
    "a = array([[ 230.1,   37.8,   69.2],\n  [  44.5,   39.3,   45.1],\n  [  17.2,   45.9,   69.3],\n  [ 151.5,   41.3,   58.5],\n  [ 180.8,   10.8,   58.4]])\na -= a.mean()\n",
    "In [4]: idx = indexes[:, None] + np.arange(-1, 3)\n\nIn [5]: values[idx]\nOut[5]:\narray([[ 0.83609961,  0.47534985,  0.17330516,  0.15152753],\n       [ 0.10245308,  0.70428183,  0.36804107,  0.13074141],\n       [ 0.36804107,  0.13074141,  0.77377332,  0.11368238]])\n",
    "import numpy as np\nimport codecs\n\nwith codecs.open('myfile.asc', encoding='utf-8-sig') as f:\n    X = np.loadtxt(f)\n",
    "import numpy as np\nimport codecs\n\nwith codecs.open('myfile.asc', encoding='utf-8-sig') as f:\n    X = np.loadtxt(f)\n",
    ">>> import numpy as np\n>>> keys = np.array(['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck'])\n>>> indices = np.array([[4,2,8],[1,7,0]])\n>>> keys[indices]\narray([['deer', 'bird', 'ship'],\n       ['automobile', 'horse', 'airplane']], \n      dtype='<U10')\n"
   ]
  },
  {
   "questions": [
    "numpy filtering clubbing : 've numpy array : [[ , ] [ , ] [ , 30] [ , ] [ 4, 6] [ 5, 31] [ 6, 5] [ 7, 8] [ 8, 7] [ 9, 10] [10, 9] [11, 10] [12 , ] ] club common element found anywhere : achieve ?",
    "delete numpy: delete numpy array? matrix: [ ] [ ] [ 4 4] [ 4] [ 4 5] matrix : [ ] [ ] [4 4] [ 4] [ 4 5]",
    "turn numpy matrix?: turn array = [[[[ , , , 4], [5, 6, 7, 8]], [[9, 10, 11, 12], [13, 14, 15, 16]]]] numpy matrix form ? np.bmat( ) avail. When , 2x6 matrix.",
    "One Hot Encoding using numpy: input zero array - [ , , , , , , , , , ] 5- [ , , , , , , , , , ] wrote: np.put(np.zeros(10),5, ) did . , implemented .",
    "Numpy array, select satisfying multiple conditions?: Suppose numpy array = [5, , , , 4, 5], y = ['f', 'o', 'o', 'b', ' ', 'r']. select y corresponding greater less 5. . ?",
    "Numpy array, select satisfying multiple conditions?: Suppose numpy array = [5, , , , 4, 5], y = ['f', 'o', 'o', 'b', ' ', 'r']. select y corresponding greater less 5. . ?",
    "numpy intepretation: interpret numpy array , , = , j = , [ :, : 5, :4] suppose whole look : array [ :, : 5, :4] look ? really understand colon : mean, comma , here mean?",
    "Create numpy array indexes (fixed) : numpy array indexes e.g. [ , ,12]. create array indexes, non zero e.g. . case, input [ , ,12], [ , , , , , , , , , , , , ]. , short numpy function achieve ?",
    "Selecting n array: array 100 length, most Pythonic n . , wanted 5 array , b=[[ , , , ,4],[5,6,7,8,9],[10,11,12,13,14],...], element b sub array 5 ?",
    "Numpy splitting multidimensional : multidimensional numpy array split based particular . Ex. [[ , , , ],[ , , ,4],[ , ,4,5]] Say split array 2nd expression <= . Then [[ , , , ],[ , , ,4]] [[ , ,4,5]]. currently using statement, think correct."
   ],
   "code": [
    "input_list = [[0, 1], [1, 0], [2, 30], [3, 2], [4, 6], [5, 31], [6, 5], \n                [7, 8], [8, 7], [9, 10], [10, 9], [11, 10], [12 , 1]]\nresult = []\nfor i in range(len(input_list)):\n    if not result:\n        result.append(set(input_list[i]))\n    else:\n        flag = False\n        last_merged_index = -1\n        j = 0\n        while j < len(result):\n            if not set(input_list[i]).isdisjoint(result[j]):\n                result[j] |= set(input_list[i])\n                flag = True\n                if last_merged_index != -1:\n                    result[j] |= result[last_merged_index]\n                    result.pop(last_merged_index)\n                    last_merged_index = j-1\n                else:\n                    last_merged_index = j\n                    j += 1\n            else:\n                j += 1\n        if not flag:\n            result.append(set(input_list[i]))\n\nprint(result)\n\n[{0, 1, 12}, {2, 3, 30}, {4, 5, 6, 31}, {8, 7}, {9, 10, 11}]\n\ninput_list = [[0, 1], [1, 0], [2, 30], [3, 2], [4, 6], [5, 31], [6, 5], [7, 8], [8, 7], [9, 10], [10, 9], [11, 10], [12 , 1], \n[13, 14], [14, 16], [15, 16], [16, 14], [17, 18], [18, 17], [19, 20], [20, 21], [21, 23], [22, 26], [23, 21], [24, 23], [25, 24], \n[26, 27], [27, 26], [28, 29], [29, 28], [30, 2], [31, 2]]\n\n[{0, 1, 12}, {2, 3, 4, 5, 6, 30, 31}, {8, 7}, {9, 10, 11}, {16, 13, 14, 15}, {17, 18}, {19, 20, 21, 23, 24, 25}, {26, 27, 22}, {28, 29}]\n",
    "a[:, ~np.all(a[1:] == a[:-1], axis=0)]\n\n#array([[1, 3, 1],\n#       [2, 1, 0],\n#       [4, 3, 4],\n#       [1, 3, 4],\n#       [1, 4, 5]])\n",
    ">>> np.array([[[[1, 2, 3, 4], [5, 6, 7, 8]], [[9, 10, 11, 12], [13, 14, 15, 16]]]]).reshape((4,4))\narray([[ 1,  2,  3,  4],\n       [ 5,  6,  7,  8],\n       [ 9, 10, 11, 12],\n       [13, 14, 15, 16]])\n",
    "import numpy as np\nnb_classes = 6\ntargets = np.array([[2, 3, 4, 0]]).reshape(-1)\none_hot_targets = np.eye(nb_classes)[targets]\n\narray([[[ 0.,  0.,  1.,  0.,  0.,  0.],\n        [ 0.,  0.,  0.,  1.,  0.,  0.],\n        [ 0.,  0.,  0.,  0.,  1.,  0.],\n        [ 1.,  0.,  0.,  0.,  0.,  0.]]])\n",
    ">>> y[(1 < x) & (x < 5)]\narray(['o', 'o', 'a'], \n      dtype='|S1')\n",
    ">>> y[(1 < x) & (x < 5)]\narray(['o', 'o', 'a'], \n      dtype='|S1')\n",
    "In [568]: data=np.arange(2*6*5).reshape(2,6,5)\nIn [569]: data[:, 2:5, 1:4]\nOut[569]: \narray([[[11, 12, 13],\n        [16, 17, 18],\n        [21, 22, 23]],\n\n       [[41, 42, 43],\n        [46, 47, 48],\n        [51, 52, 53]]])\n",
    "a = [1,3,12]\nvector = numpy.zeros(shape=max(a) + 1)\nvector[a] = 1\n",
    ">>> arr = np.arange(100)\n>>> arr\narray([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])\n>>> arr.reshape(-1, 5)\narray([[ 0,  1,  2,  3,  4],\n       [ 5,  6,  7,  8,  9],\n       [10, 11, 12, 13, 14],\n       [15, 16, 17, 18, 19],\n       [20, 21, 22, 23, 24],\n       [25, 26, 27, 28, 29],\n       [30, 31, 32, 33, 34],\n       [35, 36, 37, 38, 39],\n       [40, 41, 42, 43, 44],\n       [45, 46, 47, 48, 49],\n       [50, 51, 52, 53, 54],\n       [55, 56, 57, 58, 59],\n       [60, 61, 62, 63, 64],\n       [65, 66, 67, 68, 69],\n       [70, 71, 72, 73, 74],\n       [75, 76, 77, 78, 79],\n       [80, 81, 82, 83, 84],\n       [85, 86, 87, 88, 89],\n       [90, 91, 92, 93, 94],\n       [95, 96, 97, 98, 99]])\n\n>>> arr.reshape(20, 5)\narray([[ 0,  1,  2,  3,  4],\n       [ 5,  6,  7,  8,  9],\n       [10, 11, 12, 13, 14],\n       [15, 16, 17, 18, 19],\n       [20, 21, 22, 23, 24],\n       [25, 26, 27, 28, 29],\n       [30, 31, 32, 33, 34],\n       [35, 36, 37, 38, 39],\n       [40, 41, 42, 43, 44],\n       [45, 46, 47, 48, 49],\n       [50, 51, 52, 53, 54],\n       [55, 56, 57, 58, 59],\n       [60, 61, 62, 63, 64],\n       [65, 66, 67, 68, 69],\n       [70, 71, 72, 73, 74],\n       [75, 76, 77, 78, 79],\n       [80, 81, 82, 83, 84],\n       [85, 86, 87, 88, 89],\n       [90, 91, 92, 93, 94],\n       [95, 96, 97, 98, 99]])\n",
    ">>> import numpy as np\n>>> a = np.asarray([[1,0,2,3],[1,2,3,4],[2,3,4,5]])\n>>> a\narray([[1, 0, 2, 3],\n       [1, 2, 3, 4],\n       [2, 3, 4, 5]])\n>>> split1 = a[a[:,1] <= 2, :]\narray([[1, 0, 2, 3],\n       [1, 2, 3, 4]])\n>>> split2 = a[a[:,1] > 2, :]\narray([[2, 3, 4, 5]])\n"
   ]
  },
  {
   "questions": [
    "Cant numpy.ndarray groupby create individual plots: purpose measurement (var1, var2,Timestamp) locations (ID) dataset. : However, shown, ( ) location ID varies (usually varies 30) To variables respective location, 'm unsure proceed: 've experienced far, similar : creates numpy ndarray np.reshape original let partition array individual locations irregular . subsequently, using Pands groupby: Instantly plots graphs var1, var2 location ID give opportunity iterate graph create settings labels / axis / limits etc. ( dont yet iterate groupby objects create manage individual plots) tldr: nice create np.ndarray irregular shaped ( shown ) based criteria ( ID)? iterate control dataframe.groupby object ( talking summarized mean/ min /max etc) variables ?"
   ],
   "code": [
    "axs = data_df.groupby('ID').plot('var1','var2')\nfor ax in axs.values():\n    ax.set_ylabel('whatever')\n    ...\n"
   ]
  },
  {
   "questions": [
    "Find closest ( .6) [closed]: element yrs closest 2013 (_tmp). 've comprehension throws NameError. else ? Perhaps numpy?",
    "numpy vs comprehension, faster? [closed]: ran speed test comparing numpy comprehension, apparently comprehension faster. correct?",
    "slice numpy using array 1d positions [duplicate]: already answer here: consider b slice using b ? comprehension wanted pure numpy",
    "Comparison string NumPy [closed]: NumPy string . compare array absent array. LIKE operator comparison. short ?",
    "vectorise numpy. : element np.array, its index np.array put constant (here, - ) element found latter ?",
    "- sort date & [closed]: dimensional array: sort array & , fast ? thanks advance andy",
    "Memory instantiating numpy array: 50,000 element array (102400) instantiating B. throws exception MemoryError. memory huge? avoid MemoryError ndarrays numpy ??",
    "Numpy Array Lists: create Numpy array, contains ( -) lists. When append element those lists, crashes. confusing thing uncomment 4th , fine. message : .5. numpy .10.4",
    "array numpy array? [closed]: Let's say dimensional array... np.array?",
    "append 2d series array [closed]: yearly series 10 NETCDF . Shape : array : appending yearly . used function did worked: highly appriciated."
   ],
   "code": [
    "yrs[np.abs(np.array(yrs) - _tmp).argmin()]\n",
    "In [39]: %timeit pythonsum(10)\n100000 loops, best of 3: 8.41 us per loop\n\nIn [40]: %timeit pythonsum(100)\n10000 loops, best of 3: 51.9 us per loop\n\nIn [41]: %timeit pythonsum(1000)\n1000 loops, best of 3: 451 us per loop\n\nIn [42]: %timeit pythonsum(10000)\n100 loops, best of 3: 17.9 ms per loop\n\nIn [43]: %timeit numpysum(10)\n100000 loops, best of 3: 13.4 us per loop\n\nIn [44]: %timeit numpysum(100)\n100000 loops, best of 3: 17 us per loop\n\nIn [45]: %timeit numpysum(1000)\n10000 loops, best of 3: 50.3 us per loop\n\nIn [46]: %timeit numpysum(10000)\n1000 loops, best of 3: 385 us per loop\n",
    ">>> a[np.arange(5), b]\narray([ 4,  7, 13, 15, 21])\n",
    ">>> s0 = np.array(['e', 'a','bc','e', 'd'])\n>>> s1 = np.array(['a','d'])\n>>> np.setdiff1d(s0,s1)\narray(['bc', 'e'], \n      dtype='|S2')\n",
    "idx = np.searchsorted(b,a)\nidx[b[idx] != a] =-1\n",
    "lst = sorted(arr, key=lambda x: (x[3].split('.')[::-1], x[-1]))\nprint(lst)\n\n[['Y', 'X', 'V', '11.05.2022', '12:06'],\n ['W', 'R', 'Q', '09.04.2025', '12:06'],\n ['A', 'B', 'C', '10.03.2030', '14:06'],\n ['Z', 'N', 'H', '10.03.2030', '14:06']]\n",
    "50000 * 102400 * 8 = 40960000000\n\n50000 * 102400 * 8 / 1024**3 = 38.14697265625 Gb\n",
    "import numpy as np\n\nlist0 = [0,0,0]\nlist1 = [1,1,1]\n\n# stack vertically\narray_v=np.vstack((list0,list1))\nprint array_v\n\n# stack horizontally\narray_h=np.hstack((list0,list1))\nprint array_h\n\n# stack more on to stacked array\narray_v2=np.vstack((array_v,list1))\nprint array_v2\n\n> python -i stackingArrays.py\n>>> [[0 0 0]\n    [1 1 1]]\n>>> [0 0 0 1 1 1]\n>>> [[0 0 0]\n    [1 1 1]\n    [1 1 1]]\n",
    "my_list = [1,2,3,4,5]\n\nimport numpy as np\n\nmy_array = np.array(my_list)\n",
    "def make_array(loc, shape = (365, 31, 25)):  \n    # loc is string, can have any number of files, can change shape of data\n    files = glob.glob(str(loc) + '/*.nc')    \n    time_series = np.empty((len(files),) + shape) # create an extra dimension for files, 'np.empty' doesn't waste time initializing\n    for i, j in enumerate(files): # enumerate gives you indices\n        yearly = Dataset(j, 'r')\n        time_series[i] = yearly.variables['AOD'][:, :, :]\n    return time_series.reshape(*((-1,) + shape[1:])) # -1 allows size to change\n"
   ]
  },
  {
   "questions": [
    "most efficient generate serie recurrence relation using numpy?: Using numpy, most efficient f1 function ?",
    "Efficient delimiter separated string numpy array: String follows : numpy array. most efficient .Since calling function 50 million times!",
    "Efficient fenceposting 1D ndarray: most efficient reshape fencepost numpy?",
    "equivalent functions numpy: working c conversion using numpy . numpy equivalent matlab functions?",
    "50% point after curve fitting using numpy: used numpy fit sigmoidal curve. vaue X y 50% point curve after fit curve",
    "most efficient sum 2d numpy array?: working opencv mats, numpy representing images. sum ,y coordinates frame ) most efficient ) most pythonic?",
    "Efficiently generate numpy array comprehension ?: efficient using numpy.asarray() generate array form ? appears copying everything memory, seem efficient . (Updated) Example:",
    "Fast replacement tzinfo .Series datetime: .Seriesof datetime replace tzinfo element . using apply function 's slow: ~16s 1M MacBookPro numpy ufunc function ?",
    "Finding largest eigenvalue sparse matrix: 'm using numpy scipy. sparse matrix largest eigenvalue sparse matrix. ?",
    "Entering D array : alternative perform task, using perhaps numpy function?"
   ],
   "code": [
    "import numba\n@numba.njit\ndef f1n(a,b):\n    c=np.empty_like(a)\n    c[0]=100\n    for i in range(1,len(a)):\n        c[i]=a[i]*b[i]+(1-a[i])*c[i-1]\n    return c\n\nIn [559]: %timeit f1n(df.a.values,df.b.values)\n52.9 \u00b5s \u00b1 1.24 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)\n\nIn [560]: %timeit f1(df)\n4.62 s \u00b1 13 ms per loop (mean \u00b1 std. dev. of 7 runs, 1 loop each)\n\nIn [563]: np.allclose(df.c,f1n(df.a.values,df.b.values))\nOut[563]: True\n",
    ">>> import numpy\n>>> data = \"1|234|4456|789\"\n>>> numpy.fromstring(data, dtype=int, sep=\"|\")\narray([   1,  234, 4456,  789])\n",
    ">>> from numpy.lib.stride_tricks import as_strided\n>>> fencepost = as_strided(data, shape=(data.shape[0]-1, 2),\n                           strides=(data.strides[0],)*2)\n>>> fencepost\narray([[1, 2],\n       [2, 3],\n       [3, 4],\n       [4, 5]])\n\nIn [11]: data = np.arange(10000000)\n\nIn [12]: %timeit as_strided(data, shape=(data.shape[0]-1, 2),\n...                         strides=(data.strides[0],)*2)\n100000 loops, best of 3: 12.2 us per loop\n\nIn [13]: %timeit as_strided(data, shape=(data.shape[0]-1, 2),\n...                         strides=(data.strides[0],)*2).copy()\n10 loops, best of 3: 183 ms per loop\n",
    "a = np.array([1.0, 2.0, 3.0])\n",
    "def sigmoid(x, x0, k, y0=0):\n   y = 1 / (1 + np.exp(-k*(x-x0))) + y0\n   return y\n\nfrom scipy.optimize import brentq\n\na = np.min(xdata)\nb = np.max(xdata)\nx0, k = popt\ny0 = -0.50\n\nsolution = brentq(sigmoid, a, b, args=(x0, k, y0))  # = 7.142\n\npopt, pcov = curve_fit(sigmoid, xdata, ydata, p0 = (1,1))\n",
    "np.sum(frame[:, :, 0])\n",
    "results = np.fromiter((np.amax(np.amax(np.where(a1 > element)) for element in a2), dtype=int, count=len(a2))\n\nIn [8]: %timeit np.asarray([np.amax(np.where(a1 > element)) for element in a2])                                 \n1000 loops, best of 3: 161 us per loop\n\nIn [10]: %timeit np.frompyfunc(lambda element: np.amax(np.where(a1 > element)),1,1)(a2,out=np.empty_like(a2))   \n10000 loops, best of 3: 123 us per loop\n\nIn [13]: %timeit np.fromiter((np.amax(np.where(a1 > element)) for element in a2),dtype=int, count=len(a2))\n10000 loops, best of 3: 111 us per loop\n",
    "In [33]:\nimport pytz\n%timeit s.dt.tz_localize(pytz.utc)\n%timeit s.apply(lambda x: x.replace(tzinfo=pytz.utc))\n\n10 loops, best of 3: 107 ms per loop\n1 loops, best of 3: 10.4 s per loop\n",
    "eigvals, eigvecs = eigsh(A, k=10, which='LM', sigma=1.)\n",
    "limit_1 = 4\nlimit_2 = 3\n\nimport numpy as np\na = np.zeros([limit_1, limit_2])\nb = np.array([1, -6, 7, 3])\nc = np.array([3, 2, -1])\n\nprint(\"Original:\")\nfor i in range(limit_1):\n    for j in range(limit_2):\n        a[i][j]=np.sqrt(np.absolute(b[i])**2+np.absolute(c[j])**2)\n\nprint(a)\n\nOriginal:\n[[ 3.16227766  2.23606798  1.41421356]\n [ 6.70820393  6.32455532  6.08276253]\n [ 7.61577311  7.28010989  7.07106781]\n [ 4.24264069  3.60555128  3.16227766]]\n\nprint(\"Improved:\")\na = np.sqrt(\n        np.tile(np.array([b]).transpose(), (1, limit_2)) ** 2 +\\\n        np.tile(np.array(c).transpose(), (limit_1, 1)) ** 2)\n\nprint(a)\n\nImproved:\n[[ 3.16227766  2.23606798  1.41421356]\n [ 6.70820393  6.32455532  6.08276253]\n [ 7.61577311  7.28010989  7.07106781]\n [ 4.24264069  3.60555128  3.16227766]]\n\n>>> np.tile(np.array([b]).transpose(), (1, limit_2))\narray([[ 1,  1,  1],\n       [-6, -6, -6],\n       [ 7,  7,  7],\n       [ 3,  3,  3]])\n\n>>> np.tile(np.array([b]).transpose(), (1, limit_2)) ** 2\narray([[ 1,  1,  1],\n       [36, 36, 36],\n       [49, 49, 49],\n       [ 9,  9,  9]])\n\n>>> np.tile(np.array(c).transpose(), (limit_1, 1))\narray([[ 3,  2, -1],\n       [ 3,  2, -1],\n       [ 3,  2, -1],\n       [ 3,  2, -1]])\n>>> np.tile(np.array(c).transpose(), (limit_1, 1)) ** 2\narray([[9, 4, 1],\n       [9, 4, 1],\n       [9, 4, 1],\n       [9, 4, 1]])\n"
   ]
  },
  {
   "questions": [
    "Get Elements based index array: numpy array -- .e. based index b. achieve using numpy vectorization .e. looping ?",
    "Convert zeros ones ones numpy array: Consider numpy array zeroes ones ones achieve ? numpy function achieve ?",
    "mask numpy based : Suppose numpy array: mask . That , using numpy masked operations? ? .",
    "(numpy): drop index: 've got numpy array remove based index. -built function elegant operation? Something :",
    "Adding index numpy : numpy array : add index inner : save array csv using numpy.savetxt. currently : giving Could someone please tell",
    "Sort numpy matrix ascending order: numpy matrix sort ascending order based 3rd . matrix actually . using numpy? appreciated. !",
    "Delete dimension array?: numpy array ( , 2000, 6). delete dimension s (2000,6). ?",
    "modify Numpy array specific indexes?: now achieve . As , used range function select . cleaner select ?",
    "Mask array index array: : mask based index b. That means :",
    "Index element Numpy array: we index array using .index() numpy array? When : Says numpy library support function. ? ."
   ],
   "code": [
    ">>> a = np.array([[0.1, 0.1, 0.1], [0.2, 0.2, 0.2]])\n# result: array([[ 0.1,  0.1,  0.1],\n#                [ 0.2,  0.2,  0.2]])\n\n>>> b = [0,0,0,1]\n>>> print(a[b])\narray([[ 0.1,  0.1,  0.1],\n       [ 0.1,  0.1,  0.1],\n       [ 0.1,  0.1,  0.1],\n       [ 0.2,  0.2,  0.2]])\n\n>>> (np.asarray(a)[b]).tolist()\n[[0.1, 0.1, 0.1], [0.1, 0.1, 0.1], [0.1, 0.1, 0.1], [0.2, 0.2, 0.2]]\n",
    "def fill_gaps(arr):\n    ma = np.maximum.accumulate\n    return ma(arr[:,::-1],axis=1)[:,::-1] & ma(arr,axis=1)\n\n# Sample #1\nIn [27]: print arr\n[[1 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 1 1]\n [1 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1]\n [0 0 0 0 0 1 0 1 1 1 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0]]\n\nIn [28]: print fill_gaps(arr)\n[[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n [0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0]]\n\n# Sample #2\nIn [42]: print arr\n[[1 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 1 1 1 1 1 1 1]\n [0 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0]\n [0 0 0 0 0 1 0 1 1 1 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0]]\n\nIn [43]: print fill_gaps(arr)\n[[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n [0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0]\n [0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0]]\n\ndef fill_gaps(arr, value=1):\n    ma = np.maximum.accumulate\n    mask = arr==value\n    mask_filled = ma(mask[:,::-1],axis=1)[:,::-1] & ma(mask,axis=1)\n    return np.where(mask_filled,value,0)\n\nIn [69]: print arr\n[[255   0 255   0 255   0 255   0   0   0   0 255   0   0   0   0   0   0\n    0 255   0   0 255 255 255 255 255 255 255 255]\n [  0   0   0 255   0 255   0 255   0 255   0 255   0 255   0 255   0 255\n    0 255   0 255   0 255   0 255   0 255   0   0]\n [  0   0   0   0   0 255   0 255 255 255 255 255   0   0   0 255 255 255\n    0   0   0   0   0   0   0   0   0   0   0   0]]\n\nIn [70]: print fill_gaps(arr, 255)\n[[255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255\n  255 255 255 255 255 255 255 255 255 255 255 255]\n [  0   0   0 255 255 255 255 255 255 255 255 255 255 255 255 255 255 255\n  255 255 255 255 255 255 255 255 255 255   0   0]\n [  0   0   0   0   0 255 255 255 255 255 255 255 255 255 255 255 255 255\n    0   0   0   0   0   0   0   0   0   0   0   0]]\n",
    "import numpy as np\n\na = np.array([[1, 5, 6],\n              [2, 4, 1],\n              [3, 1, 5]])\n\nnp.ma.MaskedArray(a, mask=(np.ones_like(a)*(a[:,0]==1)).T)\n\n# Returns: \nmasked_array(data =\n [[-- -- --]\n [2 4 1]\n [3 1 5]],\n             mask =\n [[ True  True  True]\n [False False False]\n [False False False]])\n",
    "import numpy as np\narr = np.array([234, 235, 23, 6, 3, 6, 23])\nelim = [3, 5, 6]\nnp.delete(arr, elim)\n",
    "fmt=['%d', '%1.1f', '%1.1f', '%1.1f']\n\nimport numpy as np\nprob_rf = [[1, 0.4, 0.4, 0.4],\n           [2, 0.5, 0.5, 0.5],\n           [3, 0.6, 0.6, 0.6]]\nnp.savetxt(\"foo.csv\", prob_rf, delimiter=\",\", fmt=['%d', '%1.1f', '%1.1f', '%1.1f'])\n\n1,0.4,0.4,0.4\n2,0.5,0.5,0.5\n3,0.6,0.6,0.6\n",
    ">>> arr\narray([[  3.05706500e+06,   4.98000000e+01,  -2.62500070e+01,\n         -9.38135544e+01],\n       [  3.05706600e+06,   4.98000000e+01,  -3.00000056e+01,\n         -9.38135544e+01],\n       [  3.05706700e+06,   4.98000000e+01,  -3.37500042e+01,\n         -9.38135544e+01],\n       [  3.05706800e+06,   4.98000000e+01,  -3.75000028e+01,\n         -9.38135544e+01]])\n\n>>> numpy.sort(arr,axis=0)\narray([[  3.05706500e+06,   4.98000000e+01,  -3.75000028e+01,\n         -9.38135544e+01],\n       [  3.05706600e+06,   4.98000000e+01,  -3.37500042e+01,\n         -9.38135544e+01],\n       [  3.05706700e+06,   4.98000000e+01,  -3.00000056e+01,\n         -9.38135544e+01],\n       [  3.05706800e+06,   4.98000000e+01,  -2.62500070e+01,\n         -9.38135544e+01]])\n>>> \n\n>>> arr[arr[:,2].argsort()]\narray([[  3.05706800e+06,   4.98000000e+01,  -3.75000028e+01,\n         -9.38135544e+01],\n       [  3.05706700e+06,   4.98000000e+01,  -3.37500042e+01,\n         -9.38135544e+01],\n       [  3.05706600e+06,   4.98000000e+01,  -3.00000056e+01,\n         -9.38135544e+01],\n       [  3.05706500e+06,   4.98000000e+01,  -2.62500070e+01,\n         -9.38135544e+01]])\n>>> \n",
    "output = numpy.delete(arrayName, [:], 0)\n",
    "a = np.eye(2)[[0,0,1]]\n",
    "In [524]: a=np.array([10, 31, 30, 11, 17, 12, 22, 25, 85, 17, 21, 43])\nIn [525]: b=np.array([0, 1, 4, 6])\n\nIn [526]: c=np.zeros(a.shape, bool)\nIn [527]: c[b]=True\n\nIn [528]: c\nOut[528]: \narray([ True,  True, False, False,  True, False,  True, False, False,\n       False, False, False], dtype=bool)\n\nIn [529]: a[c]\nOut[529]: array([10, 31, 17, 22])\n\nIn [530]: a[b]\nOut[530]: array([10, 31, 17, 22])\n\nnp.in1d(np.arange(a.shape[0]),b)\nnp.any(np.arange(a.shape[0])==b[:,None],0)\n\nIn [542]: np.ma.MaskedArray(a,c)\nOut[542]: \nmasked_array(data = [-- -- 30 11 -- 12 -- 25 85 17 21 43],\n             mask = [ True  True False False  True False  True False False False False False],\n       fill_value = 999999)\n",
    "i,j = np.where( a==value )\n\ni, = np.where( a==value )\n\nclass myarray(np.ndarray):\n    def __new__(cls, *args, **kwargs):\n        return np.array(*args, **kwargs).view(myarray)\n    def index(self, value):\n        return np.where(self==value)\n\na = myarray([1,2,3,4,4,4,5,6,4,4,4])\na.index(4)\n#(array([ 3,  4,  5,  8,  9, 10]),)\n"
   ]
  },
  {
   "questions": [
    "Changing filtered 2d comprehension while keeping reference original: 'm sure phrase here's 'm . filter arr_first three arr_second, resulting ... , filtered 2d , add 32 fourth element 2d array, : save original arr_first. currently using comprehension syntax: , slow sets. Therefore, filtering using numpy's in1d: changes longer saved arr_first, unlike comprehension arr_first longer pass reference filtered. wondering someone give guidance fix making changes filtered occur arr_first instead having appending filtered .",
    "polynomial fit fixed : been fitting using numpy ( uses least squares). wondering fit while forcing fixed ? library ( language link - eg c)? NOTE 's force fixed point moving origin forcing constant term zero, noted here, wondering generally fixed : http://www.physicsforums.com/showthread.php?t 523360"
   ],
   "code": [
    "import pandas as pd\n\ndf = pd.DataFrame(arr_first)\ninner_len = len(arr_first[0,:])\nupdate_amt = 32\nupdate_ix = 3\n\ndf.iloc[(df.groupby(list(range(inner_len)))\n           .apply(lambda x: x.sample().index.values[0]).values), \n        update_ix] += update_amt\n\narr_first\n[[ 0  0  0  0]\n [ 0  0  0 32]\n [ 1  1  1  0]\n [ 1  1  1 32]\n [ 1  1  1  0]\n [ 1  1  2 32]\n [ 1  1  2  0]\n [ 2  2  2 32]]\n",
    "def polyfit_with_fixed_points(n, x, y, xf, yf) :\n    mat = np.empty((n + 1 + len(xf),) * 2)\n    vec = np.empty((n + 1 + len(xf),))\n    x_n = x**np.arange(2 * n + 1)[:, None]\n    yx_n = np.sum(x_n[:n + 1] * y, axis=1)\n    x_n = np.sum(x_n, axis=1)\n    idx = np.arange(n + 1) + np.arange(n + 1)[:, None]\n    mat[:n + 1, :n + 1] = np.take(x_n, idx)\n    xf_n = xf**np.arange(n + 1)[:, None]\n    mat[:n + 1, n + 1:] = xf_n / 2\n    mat[n + 1:, :n + 1] = xf_n.T\n    mat[n + 1:, n + 1:] = 0\n    vec[:n + 1] = yx_n\n    vec[n + 1:] = yf\n    params = np.linalg.solve(mat, vec)\n    return params[:n + 1]\n\nn, d, f = 50, 8, 3\nx = np.random.rand(n)\nxf = np.random.rand(f)\npoly = np.polynomial.Polynomial(np.random.rand(d + 1))\ny = poly(x) + np.random.rand(n) - 0.5\nyf = np.random.uniform(np.min(y), np.max(y), size=(f,))\nparams = polyfit_with_fixed(d, x , y, xf, yf)\npoly = np.polynomial.Polynomial(params)\nxx = np.linspace(0, 1, 1000)\nplt.plot(x, y, 'bo')\nplt.plot(xf, yf, 'ro')\nplt.plot(xx, poly(xx), '-')\nplt.show()\n\n>>> yf\narray([ 1.03101335,  2.94879161,  2.87288739])\n>>> poly(xf)\narray([ 1.03101335,  2.94879161,  2.87288739])\n"
   ]
  },
  {
   "questions": [
    "numpy printing wrong random numbers: dont understand why print matrices, prints random ! insight great! thanks im",
    "To print lying within bin: wanted print condition satisfied empty array print next results Now : wanted results :",
    "numpy matrix assign : wondering why prints? shouldn't they ?",
    "Generating random numbers probably density function: specify probably density function distribution pick N random numbers distribution . go ?",
    "numpy subtraction, come?: Cannot quite understand why -y matrix? difference (4,) y (4, ), aren't they treated vectors?",
    "Adding (header) numpy matrix issue using np.vstack : numpy matrix : add matrix proceed : print matrix appears : As , digit printed, shows digit. explanation ?? greatly appreciated, thanks.",
    "Replacing imaginary array random: got possibility replace imaginary components random generated : resulting needs form .",
    "Why numpy. 'double' sliced ?: understand why 'double' slicing ? :",
    "printing numpy.ndarray : excel print content . print anything, , warnning... nothing... : thoughts??",
    "numpy log numpy : \u00b4d understand why : results array format apply numpy.log function: Why format array apply log function?"
   ],
   "code": [
    "In [936]: mat = np.empty([2,2,2], dtype=int)\nIn [937]: mat\nOut[937]: \narray([[[          0, -1231162112],\n        [-1222623584,   139401936]],\n\n       [[  139401936,   139401936],\n        [-1230408992, -1222184576]]])\nIn [938]: a = np.array([[1, 0],\n     ...:           [3, 3]])\n     ...: b = np.array([[1, 1],\n     ...:           [3, 3]])\n     ...:           \n\nIn [939]: np.append(mat,a)\nOut[939]: \narray([          0, -1231162112, -1222623584,   139401936,   139401936,\n         139401936, -1230408992, -1222184576,           1,           0,\n                 3,           3])\n\nIn [941]: alist = []\nIn [942]: alist.append(a)\nIn [943]: alist.append(b)\nIn [944]: alist\nOut[944]: \n[array([[1, 0],\n        [3, 3]]), array([[1, 1],\n        [3, 3]])]\nIn [945]: np.array(alist)\nOut[945]: \narray([[[1, 0],\n        [3, 3]],\n\n       [[1, 1],\n        [3, 3]]])\n\nIn [951]: mat = np.empty((2,2,2), int)\nIn [952]: mat[0,:,:]=a\nIn [953]: mat[1,:,:]=b\nIn [954]: mat\nOut[954]: \narray([[[1, 0],\n        [3, 3]],\n\n       [[1, 1],\n        [3, 3]]])\n",
    "# find the indices for the break points (0, 0.05, 0.10, .., 1.00)\nbpoints = np.searchsorted(r, np.arange(0, 1+.01, 0.05), side='left')\n\n# now the values 0.05 are at indices bpoints[0]..bpoints[1], etc.\n# the resulting vectors are collected into `bins`\nbins = [ r[bpoints[i]:bpoints[i+1]] for i in range(len(bpoints)-1) ]\n\n[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.000570290882095, 0.0107443912719, 0.0124509177244, 0.0125, 0.0125, 0.025, 0.025, 0.025, 0.025, 0.0256640229497, 0.030566379892, 0.031401430789, 0.0375, 0.0375, 0.0375, 0.0395298596851, 0.039780154486, 0.0438643740073, 0.0466295394557, 0.0480063782397], \n [0.05, 0.05, 0.068990534098, 0.0717060855612, 0.0737078626994, 0.0783505963591, 0.0875, 0.0875], \n [0.100794816139, 0.110492949738, 0.1125, 0.125, 0.125, 0.137197807346, 0.140625, 0.147676814534, 0.149311786297, 0.15, 0.15], \n [0.153789751195, 0.15653721735, 0.161158308383, 0.165614224138, 0.165804856115, 0.181477147577, 0.186858748434], \n [0.2], \n [], \n [], \n [], \n [], \n [], \n [], \n [], \n [], \n [], \n [], \n [], \n [], \n [], \n [], \n []]\n\nprint \"\\n\".join([ str(b) for b in bins if len(b) > 0 ])\n",
    "import numpy as np\n\nx = np.array([[1.5, 2], [2.4, 6]], dtype=np.float)\nk = 1 / (1 + np.exp(-x))\n",
    "import random\n\ndef sample(n):\n    return [ icdf(random.random()) for _ in range(n) ]\n\nimport numpy as np\n\ndef sample(n):\n    return icdf(np.random.random(n))\n",
    "In [70]: y\nOut[70]:\narray([[1],\n       [2],\n       [3],\n       [4]])\n\nIn [71]: x = np.array([x])\n\nIn [72]: x\nOut[72]: array([[1, 2, 3, 4]])\n\nIn [73]: x - y\nOut[73]:\narray([[ 0,  1,  2,  3],\n       [-1,  0,  1,  2],\n       [-2, -1,  0,  1],\n       [-3, -2, -1,  0]])\n\nIn [79]: y = np.array([[1,2,3,4],[5,6,7,8]])\n\nIn [80]: y.shape\nOut[80]: (2, 4)\n\nIn [81]: x = np.array([1,2])\n\nIn [82]: x.shape\nOut[82]: (2,)\n\nIn [83]: y - x\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n<ipython-input-83-4abb3bd0a148> in <module>()\n----> 1 y - x\n\nValueError: operands could not be broadcast together with shapes (2,4) (2,)\n\nIn [84]: y - x.reshape((2,1))\nOut[84]:\narray([[0, 1, 2, 3],\n       [3, 4, 5, 6]])\n",
    "In [1]: import numpy as np\n\nIn [2]: a = np.array(['hi','hello'])\n\nIn [3]: a.dtype\nOut[3]: dtype('|S5')\n\nIn [4]: a = np.array(['hi','hello'], dtype='S2')\n\nIn [5]: a\nOut[5]: \narray(['hi', 'he'], \n      dtype='|S2')\n",
    "import numpy as np\n\ndata = np.array([[ 0.01454911+0.j,  0.01392502+0.00095922j,\n         0.00343284+0.00036535j, 0.00094982+0.0019255j ,\n         0.00204887+0.0039264j , 0.00112154+0.00133549j,  0.00060697+0.j],\n       [ 0.02179418+0.j,  0.01010125-0.00062646j,\n         0.00086327+0.00495717j, 0.00204473-0.00584213j,\n         0.00159394-0.00678094j, 0.00121372-0.0043044j , 0.00040639+0.j]])\n\ndef setRandomImag(c):\n    c.imag = np.random.vonmises(mu, kappa, size=size)\n    return c\n\ndata = [ setRandomImag(i) for i in data]\n",
    "In [384]: t[:3]\nOut[384]: array([False,  True,  True], dtype=bool)\n        #        0       1      2\n\nIn [385]: np.where(t[:3])\nOut[385]: (array([1, 2]),)\n\nIn [386]: t[1:3]\nOut[386]: array([ True,  True], dtype=bool)\n        #         0      1\n\nIn [387]: np.where(t[1:3])\nOut[387]: (array([0, 1]),)\n\nIn [388]: t[0:3]\nOut[388]: array([False,  True,  True], dtype=bool)\n        #        0       1      2\n\nIn [389]: np.where(t[0:3])\nOut[389]: (array([1, 2]),)\n\nIn [390]: n = 1\n\nIn [391]: np.where(t[n:3])[0] + n\nOut[391]: array([1, 2])\n",
    "import pandas as pd\nimport numpy as np\n\nnp.set_printoptions(threshold=np.inf)\n\ndf = pd.read_excel('~/desktop/tmp.xlsx')\ndata = df.as_matrix()\ndata.itemsize\n\nprint 'read is done'\n",
    "In [1]: x = [1, 2, 3]  # `x` is a python list.\n\nIn [2]: print(x)\n[1, 2, 3]\n\nIn [3]: a = np.array(x)  # `a` is a numpy array.\n\nIn [4]: print(a)\n[1 2 3]\n\nIn [6]: print(repr(a))\narray([1, 2, 3])\n"
   ]
  },
  {
   "questions": [
    "Find matching numpy ok, matching numpy array ok: .6. / numpy .13. / ubuntu 17.10 'm numpy facing problems boolean indexing. test array: [ 5, 6, 7, 8, 9] , index matches. Now [4,9,14,29] : expected ( least ), since hope boolean : telling matching index 4. 's wrong guessing?",
    "Skip nth index numpy array: order K fold validation slice numpy view original array made nth element removed. : [ , , , , 4, 5, 6, 7, 8, 9] n = 4 [ , , 4, 5, 6, 8, 9] Note: numpy requirement due being used machine learning assignment dependencies fixed.",
    "flatten lists scalars: matrix, we methods numpy.flatten() [ , , ,4,5,6,7,8,9] wanted np.array([[ , , ],[4,5,6],7]) [ , , ,4,5,6,7]? existing function performs ?",
    "Using List Conditional Statements: 'm attempting keep lines 5, 6, 7, 8, 9 certain . \"fildir\" directory files . [:, ] range 15 said, keep lines 5 9. When : helpful hints?",
    "Find matching dimensional numpy array: index dimensional Numpy array matches . , array : index matches [ , ] index 15. When numpy. (vals == [ , ]) ... index array([ , 15]).",
    "Find matching dimensional numpy array: index dimensional Numpy array matches . , array : index matches [ , ] index 15. When numpy. (vals == [ , ]) ... index array([ , 15]).",
    "dataframe filtering groupby: , dataframe , b: expecting filtered dataframe: [5,6,7, , ,4,9, , ] Without using groupby function ( take too long dataframe, usable), filter last items group col. ?",
    "Finding index element nested lists : index element nested lists - [[ , b, c], [d, e, f], [g,h]] ( lists ). using returning empty , even though element present. idea 'm wrong?"
   ],
   "code": [
    "np.all(b.T==( 4,  9,  14,  19), axis=0)\n",
    "a[np.mod(np.arange(a.size),4)!=0]\n\nIn [255]: a\nOut[255]: array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n\nIn [256]: a[np.mod(np.arange(a.size),4)!=0]\nOut[256]: array([1, 2, 3, 5, 6, 7, 9])\n\n# Create mask\nmask = np.ones(a.size, dtype=bool)\nmask[::4] = 0\n\nIn [311]: mask.itemsize\nOut[311]: 1\n\nIn [312]: a.itemsize\nOut[312]: 8\n\nIn [313]: a\nOut[313]: array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n\nIn [314]: a[mask] = 10\n\nIn [315]: a\nOut[315]: array([ 0, 10, 10, 10,  4, 10, 10, 10,  8, 10])\n\ndef skipped_view(a, n):\n    s = a.strides[0]\n    strided = np.lib.stride_tricks.as_strided\n    return strided(a,shape=((a.size+n-1)//n,n),strides=(n*s,s))[:,1:]\n\nIn [50]: a = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]) # Input array\n\nIn [51]: a_out = skipped_view(a, 4)\n\nIn [52]: a_out\nOut[52]: \narray([[ 1,  2,  3],\n       [ 5,  6,  7],\n       [ 9, 10, 11]])\n\nIn [53]: a_out[:] = 100 # Let's prove output is a view indeed\n\nIn [54]: a\nOut[54]: array([  0, 100, 100, 100,   4, 100, 100, 100,   8, 100, 100, 100])\n",
    "In [96]: arr=np.array([[1,2,3],[4,5,6],7])\nIn [97]: arr\nOut[97]: array([[1, 2, 3], [4, 5, 6], 7], dtype=object)\nIn [98]: arr.sum()\n...\nTypeError: can only concatenate list (not \"int\") to list\n\nIn [99]: arr=np.array([[1,2,3],[4,5,6],[7]])\nIn [100]: arr.sum()\nOut[100]: [1, 2, 3, 4, 5, 6, 7]\n\nIn [104]: list(itertools.chain(*arr))\nOut[104]: [1, 2, 3, 4, 5, 6, 7]\n\nIn [178]: arr=np.array([[1,2,3],[4,5,6],7])\nIn [179]: np.concatenate(arr)\n...\nValueError: all the input arrays must have same number of dimensions\nIn [180]: np.hstack(arr)\nOut[180]: array([1, 2, 3, 4, 5, 6, 7])\n\nIn [170]: big1=arr.repeat(1000)\nIn [171]: timeit big1.sum()\n10 loops, best of 3: 31.6 ms per loop\nIn [172]: timeit list(itertools.chain(*big1))\n1000 loops, best of 3: 433 \u00b5s per loop\nIn [173]: timeit np.concatenate(big1)\n100 loops, best of 3: 5.05 ms per loop\n\nIn [174]: big1=arr.repeat(2000)\nIn [175]: timeit big1.sum()\n10 loops, best of 3: 128 ms per loop\nIn [176]: timeit list(itertools.chain(*big1))\n1000 loops, best of 3: 803 \u00b5s per loop\nIn [177]: timeit np.concatenate(big1)\n100 loops, best of 3: 9.93 ms per loop\nIn [182]: timeit np.hstack(big1)    # the extra iteration hurts hstack speed\n10 loops, best of 3: 43.1 ms per loop\n\nres=[]\nfor e in bigarr: \n   res += e\n",
    "if data[:,1] not in var:\n\n1 2 3 4 5 6 7 8\n9 10 11 12 13 14 16\n\n>> data[:,1]\narray([2., 10.])\n\nfrom glob import glob\nimport numpy as np\n\nvar = [5, 6, 7, 8, 9]\n\nfilname = glob('fildir/*')\n\n# get the desired rows from all files in folder\n# use int as dtype because float is default\n# I'm not an expert on numpy so I'll .tolist() the arrays\ndata = [np.genfromtxt(k, dtype=int, skip_header=6).tolist() for k in filname]\n\n# flatten the list to have all the rows file agnostic\ndata = [x for sl in data for x in sl]\n\n# filter the data and return all the desired rows\nfiltered_data = filter(lambda x: x[1] in var, data)\n",
    ">>> np.where((vals == (0, 1)).all(axis=1))\n(array([ 3, 15]),)\n\n>>> vals == (0, 1)\narray([[ True, False],\n       [False, False],\n       ...\n       [ True, False],\n       [False, False],\n       [False, False]], dtype=bool)\n\n>>> (vals == (0, 1)).all(axis=1)\narray([False, False, False,  True, False, False, False, False, False,\n       False, False, False, False, False, False,  True, False, False,\n       False, False, False, False, False, False], dtype=bool)\n\n>>> np.where((vals == (0, 1)).all(axis=1))\n(array([ 3, 15]),)\n\n>>> (vals[:, 0] == 0) & (vals[:, 1] == 1)\n",
    ">>> np.where((vals == (0, 1)).all(axis=1))\n(array([ 3, 15]),)\n\n>>> vals == (0, 1)\narray([[ True, False],\n       [False, False],\n       ...\n       [ True, False],\n       [False, False],\n       [False, False]], dtype=bool)\n\n>>> (vals == (0, 1)).all(axis=1)\narray([False, False, False,  True, False, False, False, False, False,\n       False, False, False, False, False, False,  True, False, False,\n       False, False, False, False, False, False], dtype=bool)\n\n>>> np.where((vals == (0, 1)).all(axis=1))\n(array([ 3, 15]),)\n\n>>> (vals[:, 0] == 0) & (vals[:, 1] == 1)\n",
    "In [89]: a = np.array([1,1,1,1,1,1,1,2,2,2,2,2,2,2,3,3,3,3,3,3,3])\n    ...: b = np.array([1,2,3,4,5,6,7,8,9,0,1,2,3,4,5,6,7,8,9,0,1])\n    ...: \n\nIn [90]: idx = np.append(np.nonzero(a[1:] > a[:-1])[0], a.size-1)[:,None] - [2,1,0]\n\nIn [91]: b[idx].ravel()\nOut[91]: array([5, 6, 7, 2, 3, 4, 9, 0, 1])\n\na = df.a.values\nb = df.b.values\n\nfrom scipy.ndimage.morphology import binary_dilation as imdilate\ndef filter_lastN(a, b, N):\n    mask = np.zeros(a.size,dtype=bool)\n    mask[np.append(np.nonzero(a[1:] > a[:-1])[0],b.size-1)] = 1\n    return b[imdilate(mask,np.ones(N),origin=(N-1)//2)]\n\nIn [198]: a\nOut[198]: array([1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3])\n\nIn [199]: b\nOut[199]: array([5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1])\n\nIn [200]: filter_lastN(a,b,3)\nOut[200]: array([5, 6, 7, 2, 3, 4, 9, 0, 1])\n\nIn [201]: filter_lastN(a,b,5)\nOut[201]: array([5, 6, 7, 0, 1, 2, 3, 4, 7, 8, 9, 0, 1])\n",
    "def find_in_list_of_list(mylist, char):\n    for sub_list in mylist:\n        if char in sub_list:\n            return (mylist.index(sub_list), sub_list.index(char))\n    raise ValueError(\"'{char}' is not in list\".format(char = char))\n\nexample_list = [['a', 'b', 'c'], ['d', 'e', 'f'], ['g', 'h']]\n\nfind_in_list_of_list(example_list, 'b')\n(0, 1)\n"
   ]
  },
  {
   "questions": [
    "Making decimal whole : take ( .25) multiply ten repeatedly until after decimal point. , .25 multiply ten repeatedly: .25 * 10 * 10 = 25 .5 .5 * 10 = 15 best ? ?",
    "Assigning identical once /Numpy: fast ( ) assign reoccuring array. desired using : When add Px,Py obviously ( . vs. . ): numpy? .",
    "efficiently prepare matrices ( d array) multiple arguments?: evaluate d array multiple arguments efficiently .e. - , : : Okay, d array below: obtain ?: Also, generally n d ?",
    "remove numpy based multiple conditions?: 4 thousands . remove whose items certain range. , : remove whose item 20 25 30 35. That means expect : ?",
    "informal complex formal amplitude : txt composed 90 groups carrier , separated . Each carrier composed 200 complex numbers, separated tab. 90*200 array, amplitude complex . ?",
    ": multiply colums nd- vector dimensions?: : y 10 matrix. Now multiply y. did z = [:, ] * y[:, ]. got z 10 instead 10 array. direct form 10 transpose ?",
    "Using numpy.take multidimensional ?: take multiple axes fancy indexing ? multidimensional fairly , hoping potentially speedup. :",
    "- multiple scalar: Refer mentioned link multiply individual floating point integer ? import numpy np; multiply flaoting stored updated . However, [[array([ 10.])] ..... Now remove array integer .",
    "Pandas dataframe multiplication: multiply, df's multiply using selected , store df1: df2: multiply , aapl df1 340.99 df2 , store transaction_amount.",
    "equivalent R series multiple repeated numbers: create vector many repeated . easy R: However, using numpy, quite thing: 's R equivalent ?"
   ],
   "code": [
    "x=.25\nwhile int(x) != x:\n    x=x*10\n",
    "# convert yourmulti-dim indices to flat indices\nflat_idx = np.ravel_multi_index((Px, Py), dims=a.shape)\n# extract the unique indices and their position\nunique_idx, idx_idx = np.unique(flat_idx, return_inverse=True)\n# Aggregate the repeated indices \ndeltas = np.bincount(idx_idx, weights=x)\n# Sum them to your array\na.flat[unique_idx] += deltas\n",
    "In [274]: arr = np.array([[2 + x, 2 - x,],\n                 [2 * x, 2 / x]])\n\nIn [275]: arr\nOut[275]: \narray([[[ 3.        ,  4.        ,  5.        ],\n        [ 1.        ,  0.        , -1.        ]],\n\n       [[ 2.        ,  4.        ,  6.        ],\n        [ 2.        ,  1.        ,  0.66666667]]])\n\nIn [276]: arr.shape\nOut[276]: (2, 2, 3)\n\narr.transpose([2,0,1])\n",
    "data = data[np.logical_not(np.logical_and(data[:,0] > 20, data[:,0] < 25))]\ndata = data[np.logical_not(np.logical_and(data[:,0] > 30, data[:,0] < 35))]\n\ndata = data[\n    np.logical_not(np.logical_or(\n        np.logical_and(data[:,0] > 20, data[:,0] < 25),\n        np.logical_and(data[:,0] > 30, data[:,0] < 35)\n    ))\n]\n",
    "result = []\nfile = open('yourfile.txt')\nfor line in file.readlines():\n    result.append(line.split())\n\nfile.close()\nprint(result)\n",
    ">>> x = np.random.randint(0, 10, size=(10, 2))\n>>> y = np.random.randint(0, 10, size=(10, 2))\n>>> x[:,1:2] * y[:,1:2]\narray([[36],\n       [ 0],\n       [ 0],\n       [45],\n       [ 5],\n       [28],\n       [ 5],\n       [12],\n       [56],\n       [ 6]])\n",
    "m = np.where(x>0.5)\nm = (m[0],m[1],m[2])\nresult = x[m]\n\nm = np.sum(x>0.5,-1)\nresult = x.reshape(-1,x.shape[-1]).repeat(w.ravel(), 0)\n\nm = np.any(x>0.5,-1)\nresult = x[m,:]\n",
    "import numpy as np\nP=2.45\nS=[22, 33, 45.6, 21.6, 51.8]\nSP = P*np.array(S)\nSP_LIST =list(SP)\n\n[x * P for x in S]\n",
    "transaction_amount = np.diag(df1.dot(df2.T))\n\ndf1.dot(df2)\n\ndf2.T\n",
    "np.repeat([1, 2, 3], [5, 4, 3])\n\narray([1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3])\n\npd.Series(np.repeat([1, 2, 3], [5, 4, 3]))\n\n0     1\n1     1\n2     1\n3     1\n4     1\n5     2\n6     2\n7     2\n8     2\n9     3\n10    3\n11    3\ndtype: int64\n\nnp.concatenate([np.repeat(1,5), np.repeat(2,4), np.repeat(3,3)])\n\narray([1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3])\n"
   ]
  },
  {
   "questions": [
    "creating lambda function integrating: existing function defined using lambda function. function represents PDF probability distribution. construct lambda function -liner represents CDF. wish separate function definition def keyword. Below portion 've been working : Note recently found piecewise definition needed restrict range returned array <ul case [ <ul] order correctly . last command includes: When let corresponding array integration endpoints. considered function integrate.quad suited take array integration endpoint, suitable alternative? using .6. ."
   ],
   "code": [
    "f_pdf = lambda x: np.piecewise(x, [x < ul, x >= ul], [lambda x: x, 0])\n\nf_cdf = lambda x: integrate.quad(f_pdf, 0, x)[0]\n\nf_cdf = np.vectorize(lambda x: integrate.quad(f_pdf,0,x)[0])\n\nprint(integrate.cumtrapz(f_pdf(X), X))\n\nintegrate.quad(f_pdf, 0, x)[0] if x < ul else integrate.quad(f_pdf, 0, x, points=[ul])[0]\n"
   ]
  },
  {
   "questions": [
    "Calculating standard deviation ignoring zeros using numpy: having pct_change. calculate std deviation ignoring zeros. below , working expected. Input : pct_change Code ignore zero calculate standard deviation.",
    "Adding alpha channel RGB using numpy: array RGB space add alpha channel zeros. Specifically, numpy array (205, 54, ) change (205, 54, 4) additional spot third dimension being . 's. Which numpy operation achieve ?",
    "Rearranging numpy array: expected answer : answer wrong. ?",
    "Set last non zero element zero - NumPy: : change last non zero write n*m numpy array? , S ;-)",
    "Print class using numpy array?: class build classification features, averaging word vectors vectors text print class screen save Thank",
    "transposing using numpy: tranposed numpy array Expected Result: np.transpose results:",
    "Calculating closest numbers numpy: 'm calculate closest numbers couldn't far. quite ; keep . . fix",
    "Replacing numpy.fft routines pyfftw, working expected: working making numpy.fft package, here snippet: rewrite pyfftw package. came , : , produce using numpy.fft package. See attached images.",
    "equivalent using numpy?: When copy linking object call . : equivalent numpy array advance",
    "Use array filter array: filter array non zero ? Expected : Thank"
   ],
   "code": [
    ">>> a\narray([     0.  ,      0.  ,      0.  ,  18523.94,  15501.94,  14437.03,\n        13402.43,  18986.14])\n>>> a[a!=0].std()\n2217.2329816471693\n",
    "numpy.dstack( ( your_input_array, numpy.zeros((25, 54)) ) )\n",
    "L = 3 # Cutting length\nout = a.reshape(-1,L,a.shape[1]).swapaxes(0,1).reshape(L,-1)\n\nout = a.reshape(-1,L,a.shape[1]).transpose(1,0,2).reshape(L,-1)\n",
    "A[np.arange(A.shape[0]),(A!=0).cumsum(1).argmax(1)] = 0\n\nIn [59]: A\nOut[59]: \narray([[2, 0, 3, 4],\n       [5, 6, 7, 0],\n       [8, 9, 0, 0]])\n\nIn [60]: A[np.arange(A.shape[0]),(A!=0).cumsum(1).argmax(1)] = 0\n\nIn [61]: A\nOut[61]: \narray([[2, 0, 3, 0],\n       [5, 6, 0, 0],\n       [8, 0, 0, 0]])\n\nA[np.arange(A.shape[0]),A.shape[1] - 1 - (A[:,::-1]!=0).argmax(1)] = 0\n\nIn [105]: A\nOut[105]: \narray([[2, 0, 3, 4],\n       [5, 6, 7, 0],\n       [8, 9, 0, 0]])\n\nIn [106]: (A!=0)\nOut[106]: \narray([[ True, False,  True,  True],\n       [ True,  True,  True, False],\n       [ True,  True, False, False]], dtype=bool)\n\nIn [107]: (A!=0).cumsum(1)\nOut[107]: \narray([[1, 1, 2, 3],\n       [1, 2, 3, 3],\n       [1, 2, 2, 2]])\n\nIn [108]: (A!=0).cumsum(1).argmax(1)\nOut[108]: array([3, 2, 1])\n",
    "import numpy as np\n\nclass MeanEmbeddingVectorizer(object):\n    def __init__(self, word2vec):\n        self.word2vec = word2vec\n        self.dim = len(word2vec.itervalues().next())\n\n    def fit(self, X, y):\n        return self\n\n    def transform(self, X):\n        return np.array([\n            np.mean([self.word2vec[w] for w in words if w in self.word2vec]\n                    or [np.zeros(self.dim)], axis=0)\n            for words in X\n        ])\nprint(MeanEmbeddingVectorizer.fit(\"X\", \"Y\", \"Z\"))\n\nX\nNone\n\nprint(MeanEmbeddingVectorizer.transform(\"X\", \"Y\"))\n\nAttributeError: 'str' object has no attribute 'word2vec'\n",
    "In [58]: samplelist.shape\nOut[58]: (2, 2, 3)\n\nIn [55]: samplelist.T\nOut[55]: \narray([[['Name-1', 'new_Name_1'],\n        ['Age-1', 'new_Age_1']],\n\n       [['Name-2', 'new_Name_2'],\n        ['Age-2', 'new_Age_2']],\n\n       [['Name-3', 'new_Name_3'],\n        ['Age-3', 'new_Age_3']]], \n      dtype='|S10')\n\nIn [57]: samplelist.swapaxes(0,2)\nOut[57]: \narray([[['Name-1', 'new_Name_1'],\n        ['Age-1', 'new_Age_1']],\n\n       [['Name-2', 'new_Name_2'],\n        ['Age-2', 'new_Age_2']],\n\n       [['Name-3', 'new_Name_3'],\n        ['Age-3', 'new_Age_3']]], \n      dtype='|S10')\n\nimport numpy as np\nsamplelist = np.array([\n    [ ['Name-1','Name-2','Name-3']            , ['Age-1','Age-2','Age-3'] ],\n    [ ['new_Name_1','new_Name_2','new_Name_3'], ['new_Age_1','new_Age_2','new_Age_3'] ]\n    ])\n\nprint(samplelist.swapaxes(1,2))\n# [[['Name-1' 'Age-1']\n#   ['Name-2' 'Age-2']\n#   ['Name-3' 'Age-3']]\n\n#  [['new_Name_1' 'new_Age_1']\n#   ['new_Name_2' 'new_Age_2']\n#   ['new_Name_3' 'new_Age_3']]]\n",
    "y = 0.0\nx = 0.1\nsmallest_x = x\n\nwhile (y + x > y):\n    smallest_x = x\n    x = x/2.0\nx*2\n\ny = 0.0\nx = 0.1\nwhile (y + x/2.0 > y):   //checking if the next division makes x to zero\n    x = x/2.0\nx*2\n\nx = 1.0\nwhile (x/2.0 != 0):\n    x = x/2.0\n",
    "psix_align = fftw.n_byte_align(psi0, fftw.simd_alignment, dtype='complex64')\npsik_align = fftw.n_byte_align(np.zeros_like(psi0), fftw.simd_alignment, dtype='complex64')\n",
    "b = a.copy()\n",
    ">>> import numpy as np\n>>> np.where(b, a, 0)\narray([[ 0,  0,  2,  0,  0],\n       [ 0,  0,  7,  0,  0],\n       [ 0,  0, 12,  0,  0],\n       [ 0,  0, 17,  0,  0],\n       [ 0,  0, 22,  0,  0]])\n\n>>> a[b == 0] = 0\n>>> a\narray([[ 0,  0,  2,  0,  0],\n       [ 0,  0,  7,  0,  0],\n       [ 0,  0, 12,  0,  0],\n       [ 0,  0, 17,  0,  0],\n       [ 0,  0, 22,  0,  0]])\n"
   ]
  },
  {
   "questions": [
    "normalize 4D array ( )?: 4D array (1948, 60, , ) tells difference end effector positions ( ,y,z) 60 steps. 1948 indicates samples, 60 steps, left_arm right_arm, denotes ,y,z positions. sample below: normalize tot rain neural netowrk. go normalizing 4D array intuition images. Can normalize normalization entire 4D array?",
    "matrix D array: B D array matrix turn D array. However array cell holds D array. fix ? CODE: However: Which advance",
    "multiply numpy array numpy 1D array?: : : , : multiply nD array 1D array, len(1D array) == len(nD array)?",
    "Reshaping multidimensional array D array : 4 D array . = (300, 300, 40, 193) reshape (40, 300*300*193). , after reshape, new_a[ ,:] equivalent [:,:, ,:].ravel() proper numpy.reshape ?",
    "efficiently 4D numpy array DataFrame ?: 4D numpy array (4, 155, 240, 240). create DataFrame element array, five : four , array. 'm using right now : efficiently, possibly using vectorized operations?",
    "Numpy , channels: 3D Image represented numpy format. Shape (60, 60, 15) , 60 width 60 height 15 frames deep. Now process further library. library requires argument \"channels\". https://keras.io/layers/convolutional/#conv3d many channels . Images 3D MRI images: slice:",
    "create array (N,N): create numpy array (120,120), 7 being .924 rest being .53. matrix matplotlib",
    "Multiplying NumPy scalars: NumPy array ( ,76020, ). Basically made containing 76020 , entries. multiply weight, say 5. : : thought multiply m* , instead: write multiplication?",
    "4D array 4D switched dimentions : 'm Image convolution layer TensorFlow. array : N , Width Height dimensions Channel index channel. 4D array : reason go cycle N Channel array bytes ech channel .",
    "NumPy Array grouping?: using NumPy , building 1D, now 3D array. wasn't sure why ndim thinks even though shows 3D array. grouping 3D array?"
   ],
   "code": [
    "# Get min, max value aming all elements for each column\nx_min = np.min(x, axis=tuple(range(x.ndim-1)), keepdims=1)\nx_max = np.max(x, axis=tuple(range(x.ndim-1)), keepdims=1)\n\n# Normalize with those min, max values leveraging broadcasting\nout = (x - x_min)/ (x_max - x_min)\n",
    "np.ravel(a)\n\nIn [40]: a\nOut[40]: \nmatrix([[ 1,  2, 19, 22],\n        [ 3,  4, 28, 11]])\n\nIn [41]: np.ravel(a)\nOut[41]: array([ 1,  2, 19, 22,  3,  4, 28, 11])\n",
    "import numpy\na = numpy.array([[2,3,2],[5,6,1]])\nb = numpy.array([3,5])\nc = a * b[:, None]\n",
    "a = np.rollaxis(a, 2, 0)\na = a.reshape((40, 300*300*193))\n\n>>> a = np.random.randn(30, 30, 40, 19)\n>>> b = np.rollaxis(a, 2, 0)\n>>> b = b.reshape((40, 30*30*19))\n>>> (b[0, :] == a[:, :, 0, :].ravel()).all()\nTrue\n",
    "import numpy as np\nimport pandas as pd\nimport functools\n\nim = np.array((4, 155, 240, 240))\nim = np.arange(im.prod()).reshape(im)\n\ndef cartesian_product_transpose(*arrays):\n    \"\"\"\n    http://stackoverflow.com/a/11146645/190597 (senderle)\n    \"\"\"\n    broadcastable = np.ix_(*arrays)\n    broadcasted = np.broadcast_arrays(*broadcastable)\n    dtype = np.find_common_type([arr.dtype for arr in broadcasted], [])\n    rows, cols = functools.reduce(np.multiply, broadcasted[0].shape), len(broadcasted)\n    out = np.empty(rows * cols, dtype=dtype)\n    start, end = 0, rows\n    for a in broadcasted:\n        out[start:end] = a.reshape(-1)\n        start, end = end, end + rows\n    return out.reshape(cols, rows).T\n\ndf = pd.DataFrame(cartesian_product_broadcasted(*[np.arange(i) for i in im.shape]),\n                  columns=['mode', 'x', 'y', 'z'])\ndf['val'] = im.ravel()\n",
    "input_shape=(128, 128, 3) # for RGB pictures\ninput_shape=(128, 128, 128, 1) #  for 128x128x128 volumes with a single channel\n",
    ">>> x = np.empty((120, 120))\n>>> x.fill(0.53)\n>>> x[0,:7] = 0.924\n>>> x\narray([[ 0.924,  0.924,  0.924, ...,  0.53 ,  0.53 ,  0.53 ],\n       [ 0.53 ,  0.53 ,  0.53 , ...,  0.53 ,  0.53 ,  0.53 ],\n       [ 0.53 ,  0.53 ,  0.53 , ...,  0.53 ,  0.53 ,  0.53 ],\n       ..., \n       [ 0.53 ,  0.53 ,  0.53 , ...,  0.53 ,  0.53 ,  0.53 ],\n       [ 0.53 ,  0.53 ,  0.53 , ...,  0.53 ,  0.53 ,  0.53 ],\n       [ 0.53 ,  0.53 ,  0.53 , ...,  0.53 ,  0.53 ,  0.53 ]])\n",
    "m = array(\n[[[3,4],[5,8]],\n[[1,2],[2,2]]])\na = array([3,5])\nprint(a[None,:,None].shape, m*a[None,:,None])\n\"\"\"\n(1, 2, 1)\n\n[[[ 9 12]\n  [25 40]]\n\n [[ 3  6]\n  [10 10]]]\n\"\"\"  \n",
    "image = tf.transpose(image, perm = [0, 3, 1, 2])\n",
    "A[i][j]    # This?\nA[i][j][k] # Or this?\n"
   ]
  },
  {
   "questions": [
    "division process condition avoiding infinites : handling basically: x1 day d x2 day d+ x3 calculating based previous When happens division : ( .5 )/ happens day 2017 09 010 POS_16_20_and 2017 09 011 infinite, . condition division dividing zero x3 x2 infinite replace last . : date frame: masks",
    "count distance previous zero series?: series (represented ): define series returns distance last zero. means : most efficient ?",
    "Adding background known corner coordinates: Say plotting background. 've used Lena : . : specify corner coordinates ? Let's say 'd bottom left corner , y = .5, . top right corner , y = 8. , 7. .",
    "TensorFlow - Ignore infinite calculating mean tensor: probably basic , 't : calculate mean tensor ignoring non finite . mean([ . , . , inf, 5. ]) .333 inf nor .5. sess. (tf.reduce_mean([ . , . , inf, 5. ])) returns inf."
   ],
   "code": [
    "waps_df2 = waps_df1.sub(waps_df1.shift(1)).fillna(0)\nprint (waps_df2)\n            POS_00_04  POS_04_08  POS_08_12  POS_12_16  POS_16_20  POS_20_24\ndatum_von                                                                   \n2017-09-09        0.0        0.0        0.0        0.0       0.00        0.0\n2017-09-10        0.0        0.0        0.0        0.0       0.00        0.0\n2017-09-11        0.0        0.0        0.0        0.0       0.05        0.0\n2017-09-12        0.0        0.0        0.0        0.0       0.01        0.0\n2017-09-13        0.0        0.0        0.0        0.0      -0.06        0.0\n\nwaps_x = waps_df2.div(waps_df1.shift(1))\nprint (waps_x)\n            POS_00_04  POS_04_08  POS_08_12  POS_12_16  POS_16_20  POS_20_24\ndatum_von                                                                   \n2017-09-09        NaN        NaN        NaN        NaN        NaN        NaN\n2017-09-10        NaN        NaN        NaN        NaN        NaN        NaN\n2017-09-11        NaN        NaN        NaN        NaN        inf        NaN\n2017-09-12        NaN        NaN        NaN        NaN   0.200000        NaN\n2017-09-13        NaN        NaN        NaN        NaN  -1.000000        NaN\n\nprint (np.isinf(waps_x))\n            POS_00_04  POS_04_08  POS_08_12  POS_12_16  POS_16_20  POS_20_24\ndatum_von                                                                   \n2017-09-09      False      False      False      False      False      False\n2017-09-10      False      False      False      False      False      False\n2017-09-11      False      False      False      False       True      False\n2017-09-12      False      False      False      False      False      False\n2017-09-13      False      False      False      False      False      False\n\nwaps_x = waps_x.mask(np.isinf(waps_x), waps_df1)\nprint (waps_x)\n            POS_00_04  POS_04_08  POS_08_12  POS_12_16  POS_16_20  POS_20_24\ndatum_von                                                                   \n2017-09-09        NaN        NaN        NaN        NaN        NaN        NaN\n2017-09-10        NaN        NaN        NaN        NaN        NaN        NaN\n2017-09-11        NaN        NaN        NaN        NaN       0.05        NaN\n2017-09-12        NaN        NaN        NaN        NaN       0.20        NaN\n2017-09-13        NaN        NaN        NaN        NaN      -1.00        NaN\n",
    ">>> izero = np.r_[-1, (ts == 0).nonzero()[0]]  # indices of zeros\n>>> idx = np.arange(len(ts))\n>>> idx - izero[np.searchsorted(izero - 1, idx) - 1]\narray([1, 2, 0, 1, 2, 3, 4, 0, 1, 2])\n",
    "import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.misc import imread\nimport matplotlib.cbook as cbook\n\nnp.random.seed(0)\nx = np.random.uniform(0.0,10.0,15)\ny = np.random.uniform(0.0,10.0,15)\n\ndatafile = cbook.get_sample_data('lena.jpg')\nimg = imread(datafile)\nplt.scatter(x,y,zorder=1)\nplt.imshow(img, zorder=0, extent=[0.5, 8.0, 1.0, 7.0])\nplt.show()\n",
    "import tensorflow as tf\n\nx = tf.constant([2, 3, float('Inf'), 5])\nmymean = tf.reduce_mean(tf.boolean_mask(x, tf.logical_not(tf.is_inf(x))))\n\nsess = tf.Session()\nsess.run(mymean)\n"
   ]
  },
  {
   "questions": [
    "Conditions df Numpy Timedelta: creating ['inc_cr_date_adjusted'] df based df, inc_cr_date_day inc_cr_date below 's working expected. Doesn't give 's working defined conditions conditions Saturday Sunday . conditions included hour & days summing (Timedelta(' days'). Other issue most dates assume last \"df['inc_cr_date'])\" change , thats appening . conditions based Day week hour & minute visible inc_cr_date. hour&minute 9 30 18 30 divided using &. Code : Output ( wrong): thanks lot your inputs."
   ],
   "code": [
    "#All the condtions can be reduced to one mask and result \ndays_one = ['Monday','Tuesday','Wednesday','Thursday']\ndays_two = days_one + ['Friday']\n\n# Returns a boolean mask \nm1 = df['inc_cr_date_day'].isin(days_one) & (df['inc_cr_date'].dt.hour > 18 ) & (df['inc_cr_date'].dt.minute > 30)\nm2 = df['inc_cr_date_day'].isin(days_two) & (df['inc_cr_date'].dt.hour < 9 ) & (df['inc_cr_date'].dt.minute < 30)\n\n# Repeated result can be stored in one variable \nr1 = (df['inc_cr_date']+pd.Timedelta('1 days')).dt.normalize() + pd.Timedelta('9 Hours 30 Minutes')\nr2 = (df['inc_cr_date']+pd.Timedelta('0 days')).dt.normalize() + pd.Timedelta('9 Hours 30 Minutes')\n\n\ndf['inc_cr_date_adjusted'] = np.select([\n                          m1, m2,      \n                          (df['inc_cr_date_day'] == 'Saturday'),\n                          (df['inc_cr_date_day'] == 'Sunday'),\n                          ((df['inc_cr_date_day'] == 'Friday')& (df['inc_cr_date'].dt.hour > 18 ) & df['inc_cr_date'].dt.minute > 30),\n                          ],\n                          [r1, r2,\n                          (df['inc_cr_date']+pd.Timedelta('2 days')).dt.normalize() + pd.Timedelta('9 Hours 30 Minutes'),\n                          (df['inc_cr_date']+pd.Timedelta('1 days')).dt.normalize() + pd.Timedelta('9 Hours 30 Minutes'),                           \n                          (df['inc_cr_date']+pd.Timedelta('3 days')).dt.normalize() + pd.Timedelta('9 Hours 30 Minutes')\n                          ],\n                          df['inc_cr_date'])\n\n\n               inc_cr_date inc_cr_date_day    inc_cr_date_adjusted\n0 2017-10-26 21:59:28.075        Thursday 2017-10-27 09:30:00.000\n1 2017-10-21 16:49:58.722        Saturday 2017-10-23 09:30:00.000\n2 2017-10-11 09:30:05.258       Wednesday 2017-10-11 09:30:05.258\n\n((df['inc_cr_date_day'] == 'Monday')& (df['inc_cr_date'].dt.hour > 18 ) & (df['inc_cr_date'].dt.minute > 30)) \n"
   ]
  },
  {
   "questions": [
    "Disparity map tutorial SADWindowSize float: been basic tutorial (https://docs.opencv.org/ . beta/doc/py_tutorials/py_calib3d/py_depthmap/py_depthmap.html#py depthmap) creating disparity map images, had several errors. using .7, OpenCV . . , matplotlib . , numpy .10. v1: corrected stereoBM function tutorial match latest openCV version cv2.createStereoBM cv2.StereoBM_create got . (-211) SADWindowSize must odd, within 5..255 larger width height function 2nd last (disparity=...). reducing block still , checked pathways correct both images . attempted StereoSGBM_create instead, v2 : However returns: TypeError: Image float. reason why errors maybe occurring?",
    "Both input images must CV_8UC1 function : plan stereo tutorial here, compiler reports errors cv2.createStereoBM, found OpenCV version. followed change cv2.createStereoBM cv2.StereoBM. well, : shows : Both input images must CV_8UC1 function cv::findStereoCorrespondenceBM Can anyone ? environment .7, OpenCV .4.11. :",
    "python3.5 OpenCV . . ,OpenCV function cv2.countNonZero(img) got [duplicate]: already answer here: : , numpy function ok: understand why.",
    "Add lines pyplot: sin function show , add cos function again, plots, sin sin AND cos. show() flushes , prevent flushing? jupyter notebook.",
    "put argument function numpy aply_along_axis: apply function matrix. function arguments , things ends . runnung produce TypeError: apply_along_axis() got unexpected keyword argument 'arg'"
   ],
   "code": [
    " imgL = cv2.imread(\"C:\\Python27\\tsukuba_l.png,0\")\n imgR = cv2.imread(\"C:\\Python27\\tsukuba_r.png,0\")\n\n imgL = cv2.imread(\"C:\\Python27\\tsukuba_l.png\",0)\n imgR = cv2.imread(\"C:\\Python27\\tsukuba_r.png\",0)\n\n imgL = cv2.imread(\"C:\\Python27\\tsukuba_l.png\",cv2.IMREAD_GRAYSCALE)\n imgR = cv2.imread(\"C:\\Python27\\tsukuba_r.png\",cv2.IMREAD_GRAYSCALE)\n",
    "disparity = stereo.compute(frame0_new, frame1_new)\n",
    "img = cv2.imread('temp.jpg',cv2.CV_LOAD_IMAGE_GRAYSCALE)\nz = cv2.countNonZero(img)\nprint(z)\n",
    "%matplotlib notebook\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport time\nf1 = lambda x: np.sin(x)\nf2 = lambda x: np.cos(x)\nx = np.linspace(1,7,100)\ny1 = f1(x)\ny2 = f2(x)\n\nf,ax = plt.subplots() # creating the plot and saving the reference in f and ax\n\nax.plot(x,y1)\nf.canvas.draw()\ntime.sleep(1) # delay for when to add the second line\nax.plot(x,y2)\nf.canvas.draw()\n",
    "def my_function_allong_axis(M, argument):\n    return np.apply_along_axis(my_function, 0, M, argument)\n"
   ]
  },
  {
   "questions": [
    "Numpy thresholding acceleration: construct np.array np. using conditional. , condition met, operation applied, otherwise . calculation written ugly due conversion back . Can improved terms speed, converting ?",
    "array : array. function asarray generate desired , conversion? ! : array:",
    "Efficient index Numpy array array: Given Numpy array , array integers y, equivalent : z = np.array( [ ] y) Numpy function/ efficiently converting back ?",
    "Merge 1d 2d numpy tuple: numpy here: 'd merge tuple 's vertical, : Could provide suggestions ?",
    "comparing numpy array: 2d numpy array bools, 'd many unique contains frequency . solve converting whole string comparison, surely must better . appreciated.",
    "Numpy Vector (N, ) dimension -> (N,) dimension conversion: regarding conversion (N,) dimension (N, ) dimension . , y ( ,) dimension. show y2 ( , ) dimension. most efficient converting y2 back y copying? , Tom",
    "Numpy Vector (N, ) dimension -> (N,) dimension conversion: regarding conversion (N,) dimension (N, ) dimension . , y ( ,) dimension. show y2 ( , ) dimension. most efficient converting y2 back y copying? , Tom",
    "Numpy inplace dtype conversion: 16Gb machine memory . doubt conversion really place. -place memory conversion? type preserve . .0f becomes integer . -place type conversion NumPy array",
    "numpy ndarray element wise mean: 'd calculate element wise average numpy ndarray. : -built function operation, vectorized sum dividing?",
    "Numpy - asarray , dimension automatically vector: numbers numpy vector dimensions vec faster, shorter dimension ?"
   ],
   "code": [
    "np.where(x < THR, THR_REZ, 1.0/x**2) # x is input array\n\nIn [267]: x = np.array([3,7,2,1,8])\n\nIn [268]: THR, THR_REZ = 5, 0\n\nIn [269]: np.where(x < THR, THR_REZ, 1.0/x**2)\nOut[269]: array([ 0.        ,  0.02040816,  0.        ,  0.        ,  0.015625  ])\n\nIn [270]: def thresholded_function(x, THR, THR_REZ):\n     ...:   if x < THR:\n     ...:     return THR_REZ\n     ...:   else:\n     ...:     return 1.0 / x**2\n\nIn [272]: [thresholded_function(i,THR, THR_REZ) for i in x]\nOut[272]: [0, 0.02040816326530612, 0, 0, 0.015625]\n",
    "In [50]: import itertools as IT\n\nIn [51]: seq = [[1,2],[4,5,6]]\n\nIn [52]: np.array(zip(*(IT.izip_longest(*seq, fillvalue=''))), dtype='O')\nOut[52]: \narray([[1, 2, ''],\n       [4, 5, 6]], dtype=object)\n\nIn [56]: np.array(zip(*(IT.izip_longest(*seq, fillvalue=-1))))\nOut[56]: \narray([[ 1,  2, -1],\n       [ 4,  5,  6]])\n\nIn [68]: np.ma.masked_less(zip(*(IT.izip_longest(*seq, fillvalue=-1))), 0)\nOut[68]: \nmasked_array(data =\n [[1 2 --]\n [4 5 6]],\n             mask =\n [[False False  True]\n [False False False]],\n       fill_value = 999999)\n\nIn [71]: print(arr.mean(axis=0))\n[2.5 3.5 6.0]\n",
    "z = x[y]\n\n>>> import numpy as np\n>>> x = np.arange(100)\n>>> y = np.array([1, 27, 36, 98])\n>>> x[y]\narray([ 1, 27, 36, 98])\n",
    ">>> a = np.array([1,2])\n>>> b = np.array([(1,2,3),(4,5,6)])\n>>> zip(a,b)\n[(1, array([1, 2, 3])), (2, array([4, 5, 6]))]\n",
    "import numpy as np\nx = (np.random.random(100) * 5).astype(np.int)\nunique_vals, indicies = np.unique(x, return_inverse=True)\ncounts = np.bincount(indicies)\n\nprint unique_vals, counts\n\nimport numpy as np\nnumrows, numcols = 10,3\nx = np.random.random((numrows, numcols)) > 0.5\nx = x.view(','.join(numcols * ['i1'])) # <- View the rows as a 1D structured array...\n\nunique_vals, indicies = np.unique(x, return_inverse=True)\ncounts = np.bincount(indicies)\n\nprint unique_vals, counts\n\ndef unique_rows(data):\n    unique = dict()\n    for row in data:\n        row = tuple(row)\n        if row in unique:\n            unique[row] += 1\n        else:\n            unique[row] = 1\n    return unique\n\nfrom collections import defaultdict\ndef unique_rows(data):\n    unique = defaultdict(int)\n    for row in data:\n        unique[tuple(row)] += 1\n    return unique\n",
    "a  = np.arange(3)        # a.shape  = (3,)\nb  = a.reshape((3,1))    # b.shape  = (3,1)\nb2 = a.reshape((-1,1))   # b2.shape = (3,1)\nc  = b.reshape((3,))     # c.shape  = (3,)\nc2 = b.reshape((-1,))    # c2.shape = (3,)\n\na.__array_interface__['data']   # (22356720, False)\nb.__array_interface__['data']   # (22356720, False)\nc.__array_interface__['data']   # (22356720, False)\n",
    "a  = np.arange(3)        # a.shape  = (3,)\nb  = a.reshape((3,1))    # b.shape  = (3,1)\nb2 = a.reshape((-1,1))   # b2.shape = (3,1)\nc  = b.reshape((3,))     # c.shape  = (3,)\nc2 = b.reshape((-1,))    # c2.shape = (3,)\n\na.__array_interface__['data']   # (22356720, False)\nb.__array_interface__['data']   # (22356720, False)\nc.__array_interface__['data']   # (22356720, False)\n",
    "In [540]: x=np.arange(10)\nIn [542]: x.dtype\nOut[542]: dtype('int32')\nIn [543]: z=x.astype('float32',copy=False)\nIn [544]: z\nOut[544]: array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.], dtype=float32)\nIn [545]: x.__array_interface__\nOut[545]: \n{'data': (188221848, False),\n 'descr': [('', '<i4')],\n 'shape': (10,),\n 'strides': None,\n 'typestr': '<i4',\n 'version': 3}\nIn [546]: z.__array_interface__\nOut[546]: \n{'data': (191273640, False),\n 'descr': [('', '<f4')],\n 'shape': (10,),\n 'strides': None,\n 'typestr': '<f4',\n 'version': 3}\n\nIn [549]: z=x.view('float32')\nIn [550]: z[:]=x\nIn [551]: z\nOut[551]: array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.], dtype=float32)\nIn [552]: x\nOut[552]: \narray([         0, 1065353216, 1073741824, 1077936128, 1082130432,\n       1084227584, 1086324736, 1088421888, 1090519040, 1091567616])\nIn [553]: z\nOut[553]: array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.], dtype=float32)\nIn [555]: x.__array_interface__\nOut[555]: \n{'data': (188221848, False),\n 'descr': [('', '<i4')],\n 'shape': (10,),\n 'strides': None,\n 'typestr': '<i4',\n 'version': 3}\nIn [556]: z.__array_interface__\nOut[556]: \n{'data': (188221848, False),\n 'descr': [('', '<f4')],\n 'shape': (10,),\n 'strides': None,\n 'typestr': '<f4',\n 'version': 3}\n\nIn [594]: np.array(1, 'int32').tobytes()\nOut[594]: b'\\x01\\x00\\x00\\x00'\nIn [595]: np.array(1, 'float32').tobytes()\nOut[595]: b'\\x00\\x00\\x80?'\n",
    ">>> np.mean([a, b, c], axis=0)\narray([ 30.,  20.,  30.])\n",
    ">>> vec = np.asarray(l).reshape((1,-1)) \n>>> vec.shape\n(1, 3)\n"
   ]
  },
  {
   "questions": [
    ": Array group Sum : Many topics exist sum based indexes couldn't looking . array [ , , , , , , , , , ,4] indexes sum until now greater equal 4. : [ , 5, 9, 10] : indexes element sum fulfilled. looking efficiently numpy .",
    "Selecting indexes common property : numpy array obtain indexes verify common property. , suppose array np.array([ , , , , , , , , , , , , , , ]), indexes equal , [ , 4, 5, 8, 10, 14]. defined procedure \"pythonesque\" ? More specifically, wondering similar boolean indexing: indexes rather themselves.",
    "Sum identical based their indicies: elegant summing 's based their ? array = [ ] Then found their positions array y = (array([ , , , 4, 5, 6, 7, 10, 12, 13, 16]) numpy calculate sum based y.",
    "Get part plus element numpy ( pythonic ): numpy array ( changing original) array, item places end. Since using lot looking clean . , original array [ , , ,4] , array [4, , , ] modifying original array. found : However, looking pythonic . Basically : However, course . better using append() function?",
    "Deleting Chained Duplicates: Lets say : become [ , , , , , , , , 4, 5, , , , ] (Delete duplicates, chain duplicates. Going huge HDF5 , , numpy. Would rather iterating . modification ?",
    "Copy array 3D: Suppose Numpy array, . build 3D B depth 100 <= < 100, we B[:,:, ] == . efficient /Numpy?",
    "Numpy matching : 2xn smaller 2xn B. All B found . 'm looking matching B. , answer 'm looking [ ,6,14]. Interested efficient rather looping. !",
    "Rearrange array [ , , , 4, 5, 6] [ , , 5, , 4, 6]: 'm looking royal road rearrange array variable length : length array always dividable . array : turned : real look : turn : An array empty array remain unmodified. ?",
    "Slicing based boolean array : slice array xyz coordinates based conditions boolean array ( boolean array 1D). boolean array [ , , , , , , , , , , , , , , ] slice produce index : [ , , , , 6, 7, 10, 11, 12] ([:- ] True ) ultimate desired array xyz coordinates those : [xyz[ ], xyz[ ], xyz[ ] xyz[ ], xyz[6] xyz[7], xyz[10] xyz[11], xyz[12]] slices ( similar desired outputs) follows: [ , , , 4, 7, 8, 11, 12, 13] ([ :- ] True ) [ , , 4, 5, 8, 9, 12, 13, 14] ([ :] True ) pythonic comprehension? Thank !",
    "sum identical array: sum array? e.g array [ , ],[ , ],[ , ],[ ,5],[ ,6]. [ , ],[ , ],[ ,11]. case 'm using numpy array, makes difference."
   ],
   "code": [
    "import numpy as np\n\nli = [1,1,1,1,2,2,3,0,0,1,4]\n\nprint(np.where(np.cumsum(li) % 4 == 0))\n# (array([ 3,  5,  9, 10], dtype=int32),)\n",
    "  import numpy as np\n  x = np.array(np.array([1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1])\n  indices, = np.where(x == 1)\n  print(indices)\n",
    ">>> np.sum(x[np.where(x==2)[0]]) \n22\n",
    "def simple_roll(x):\n    res = np.empty_like(x)\n    res[0] = x[-1]\n    res[1:] = x[:-1]\n    return res\n\nIn [90]: np.roll(np.arange(1,5),1)\nOut[90]: array([4, 1, 2, 3])\nIn [91]: simple_roll(np.arange(1,5))\nOut[91]: array([4, 1, 2, 3])\n\nIn [92]: timeit np.roll(np.arange(1001),1)\n36.8 \u00b5s \u00b1 1.28 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)\nIn [93]: timeit simple_roll(np.arange(1001))\n5.54 \u00b5s \u00b1 24.5 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\n\ndef simple_roll1(x):\n    idx = np.r_[-1,0:x.shape[0]-1]\n    return x[idx]\nIn [101]: timeit simple_roll1(np.arange(1001))\n34.2 \u00b5s \u00b1 133 ns per loop (mean \u00b1 std. dev. of 7 runs, 10000 loops each)\n",
    ">>> df=pd.DataFrame({ 'lits':lits })\n\n>>> df[ (df.lits != df.lits.shift(1)) | (df.lits != df.lits.shift(-1)) ]\n\n    lits\n0      1\n2      1\n3      2\n4      0\n7      0\n8      3\n9      3\n10     1\n11     4\n12     5\n13     2\n15     2\n16     0\n18     0\n",
    "In [13]:\n\nA = np.array([[1,2,3],[4,5,6]])\nIn [14]:\n\nC = np.zeros(shape=(A.shape[0], A.shape[1], 100), dtype=A.dtype))\nIn [15]:\n\nB = C+A[...,...,np.newaxis]\nIn [16]:\n\nB[:,:,1]\nOut[16]:\narray([[ 1,  2,  3],\n       [ 4,  5,  6]])\nIn [17]:\n\nB[:,:,2]\nOut[17]:\narray([[ 1,  2,  3],\n       [ 4,  5,  6]])\n",
    "AA = np.ascontiguousarray(A.T)\nBB = np.ascontiguousarray(B.T)\n\ndt = np.dtype((np.void, AA.dtype.itemsize * AA.shape[1]))\nAA = AA.view(dt).ravel()\nBB = BB.view(dt).ravel()\n\nindices = np.argmax(AA == BB[:, None], axis = 1)\n\nsorter = np.argsort(AA)\nsorted_indices = np.searchsorted(AA, BB, sorter=sorter)\nindices = sorter[sorted_indices]\n",
    "a.reshape(3, -1).ravel('f')\n\n>>> a = np.array([1, 2, 3, 4, 5, 6])\n>>> a.reshape(3, -1).ravel('f')\narray([1, 3, 5, 2, 4, 6])\n\n>>> b = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])\n>>> b.reshape(3, -1).ravel('f')\narray([1, 4, 7, 2, 5, 8, 3, 6, 9])\n",
    "a = np.asarray([1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1])\nprint(a.nonzero())\n\narray([ 0,  5,  6,  9, 10, 14])\n",
    "import numpy as np\n\na = np.array([[0, 1],\n              [1, 1],\n              [1, 2],\n              [2, 5],\n              [2, 6]])\n\nd = {}\nfor k, v in a:\n    d[k] = d.get(k, 0) + v\n\nb = np.array(d.items())\n\nb = np.array([[ 0,  1],\n              [ 1,  3],\n              [ 2, 11]])\n\nfrom collections import Counter\nb = np.array(sum((Counter({k:v}) for k,v in a), Counter()).items())\n"
   ]
  },
  {
   "questions": [
    "finding mean entries: Simple : speed ? address + th -th element sweep?",
    "ranking multiple numpy : numpy compare p1 p2,p3 p4, etc. instance element among lowest",
    "Slicing D using D array: Assume we matrices: access element using idx, : neat ?",
    "merging : dataframes : top_ten_movies: movies: merge based movieId, : Both statements throwing . Can someone ...?",
    "Expanding numpy array matrices zeros: 's most efficient pad array matrices zeros? : add / zeros matrix element :",
    "Indexing numpy matrix: Suppose, : Now, manually show ids scores those students whose score 4. . routine ? Error",
    "take matrix, keep ?: take -th matrix best ?",
    "half lists lists?: single , 'd write resulting containing element lists f. element per ? returned lists inner composed ith element .",
    "Choose numpy matrix depending : matrix numpy choose thirds element 4. working.",
    "Appending matrix matrix B: Say matrices B. , append B?"
   ],
   "code": [
    "bins_mean = (bins[1:]-bins[:-1])/2 +bins[:-1]\n",
    "import numpy as np\np1  = np.array([140,142,145])\np2  = np.array([130,144,147])\np3  = np.array([150,141,147])\np4  = np.array([150,141,148])\nP = np.row_stack([p1,p2,p3,p4])\n\nresult = np.argpartition(P, 2, axis=0) < 2\nprint(result)\n\n[[ True False  True]\n [ True False  True]\n [False  True False]\n [False  True False]]\n\nIn [302]: P <= P[np.argpartition(P, 2, axis=0), np.arange(P.shape[1])][1]\nOut[302]: \narray([[ True, False,  True],\n       [ True, False,  True],\n       [False,  True,  True],\n       [False,  True, False]], dtype=bool)\n\nIn [5]: P[np.argpartition(P, 2, axis=0), np.arange(P.shape[1])]\nOut[5]: \narray([[130, 141, 145],\n       [140, 141, 147],\n       [150, 142, 147],\n       [150, 144, 148]])\n\nIn [6]: P[np.argpartition(P, 2, axis=0), np.arange(P.shape[1])][1]\nOut[6]: array([140, 141, 147])\n",
    "x[np.array([0,1]).reshape(idx.shape[0], -1), \n  np.array([0,1,2]).reshape(-1,idx.shape[1]),\n  idx]\nOut[29]: \narray([[ 0.10786251,  0.2527514 ,  0.11305823],\n       [ 0.67264076,  0.80958292,  0.07703623]])\n",
    "out = pd.merge(top_ten_movies.reset_index(), movies.reset_index())\nprint(out)\n   movieId  count      mean                 genres      title\n0        1    247  3.872470              Adventure  Toy Story\n1        2    107  3.401869       Children|Fantasy    Jumanji\n2        6    104  3.884615  Action|Crime|Thriller       Heat\n\nprint(top_ten_movies.join(movies))\n         count      mean                 genres      title\nmovieId\n1          247  3.872470              Adventure  Toy Story\n2          107  3.401869       Children|Fantasy    Jumanji\n6          104  3.884615  Action|Crime|Thriller       Heat\n10         122  3.450820                    NaN        NaN\n25         101  3.742574                    NaN        NaN\n32         196  3.923469                    NaN        NaN\n34         148  3.601351                    NaN        NaN\n36         104  3.937500                    NaN        NaN\n39         120  3.550000                    NaN        NaN\n47         201  4.034826                    NaN        NaN\nprint(top_ten_movies.join(movies, how='inner'))\n         count      mean                 genres      title\nmovieId\n1          247  3.872470              Adventure  Toy Story\n2          107  3.401869       Children|Fantasy    Jumanji\n6          104  3.884615  Action|Crime|Thriller       Heat\n",
    "In [408]: M=np.arange(2*3*4).reshape((2,3,4))    \nIn [409]: M\nOut[409]: \narray([[[ 0,  1,  2,  3],\n        [ 4,  5,  6,  7],\n        [ 8,  9, 10, 11]],\n\n       [[12, 13, 14, 15],\n        [16, 17, 18, 19],\n        [20, 21, 22, 23]]])\n\nIn [410]: M1=np.zeros((2,4,5),M.dtype)\n\nIn [411]: M1[:,:-1,:-1]=M\nIn [412]: M1\nOut[412]: \narray([[[ 0,  1,  2,  3,  0],\n        [ 4,  5,  6,  7,  0],\n        [ 8,  9, 10, 11,  0],\n        [ 0,  0,  0,  0,  0]],\n\n       [[12, 13, 14, 15,  0],\n        [16, 17, 18, 19,  0],\n        [20, 21, 22, 23,  0],\n        [ 0,  0,  0,  0,  0]]])\n",
    "#you need to convert Boolean list to an array to be used when selecting elements.\nprint(students_mat[np.asarray([False, True, False, False, False])])\n[[ 2.          4.32400937]]\n",
    "x[:,[i]]\nx[:, i, np.newaxis] # or use None in place of np.newaxis\nnp.atleast_2d(x[:,i]).T\nx[:,i].reshape(-1,1)\n\nIn [178]: x = np.random.rand(3,4)\n\nIn [180]: np.shares_memory(x, x[:,[2]] )\nOut[180]: False\n\nIn [181]: np.shares_memory(x, x[:, 2, np.newaxis] )\nOut[181]: True\n\nIn [182]: np.shares_memory(x, np.atleast_2d(x[:,2]).T )\nOut[182]: True\n\nIn [199]: np.shares_memory(x,x[:,2].reshape(-1,1))\nOut[199]: True\n\nIn [200]: x = np.random.rand(10000000,10)\n\nIn [201]: i = 5\n\nIn [202]: a = np.random.rand(x.shape[0],1)\n\nIn [203]: %timeit a + x[:,[i]]\n     ...: %timeit a + x[:, i, np.newaxis]\n     ...: %timeit a + np.atleast_2d(x[:,i]).T\n     ...: %timeit a + x[:,i].reshape(-1,1)\n     ...: \n10 loops, best of 3: 97.6 ms per loop\n10 loops, best of 3: 68.7 ms per loop\n10 loops, best of 3: 68.5 ms per loop\n10 loops, best of 3: 68.5 ms per loop\n",
    "a = [sub[1:19] for sub in f]\n\na = [sub[len(sub) // 2:] for sub in f]\n\na = [sub[(len(sub) + 1) // 2:] for sub in f]\n",
    "l1 = np.array([1, 2])\nl2 = np.array([2, 4])\nresult = a[np.in1d(a[:,0], l1) & np.in1d(a[:,1], l2)]\n\nresult\n#matrix([[1, 2, 5],\n#        [2, 4, 5]])\n",
    ">>> import numpy as np\n>>> a = np.zeros((5, 5))\n>>> b = np.eye(5)\n>>> np.hstack((a, b))\narray([[ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n       [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.],\n       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.]])\n\n>>> np.vstack((a, b))\narray([[ 0.,  0.,  0.,  0.,  0.],\n       [ 0.,  0.,  0.,  0.,  0.],\n       [ 0.,  0.,  0.,  0.,  0.],\n       [ 0.,  0.,  0.,  0.,  0.],\n       [ 0.,  0.,  0.,  0.,  0.],\n       [ 1.,  0.,  0.,  0.,  0.],\n       [ 0.,  1.,  0.,  0.,  0.],\n       [ 0.,  0.,  1.,  0.,  0.],\n       [ 0.,  0.,  0.,  1.,  0.],\n       [ 0.,  0.,  0.,  0.,  1.]])\n"
   ]
  },
  {
   "questions": [
    "import scripts [duplicate]: already answer here: When enter shell import numpy tensorflow, , script imports numpy throws : tensorflow: earlier. 'm working windows 10 x64, .5. . ubuntu 17, case. Also enter shell after executing script, importing until restart, case, powershell.",
    "import csv numpy.array ? [duplicate]: already answer here: say csv .csv format: import numpy.array third : using python2.7 Ubuntu. Thx ahead!",
    "create sliding window 50% overlap numpy array? [duplicate]: already answer here: Say array : change window 4, step . function?",
    "Numpy Array Set Difference [duplicate]: already answer here: numpy overlapping : You assume : array contains b. .e.,: Considering b , , most efficient solving ?",
    "Convert array lists [duplicate]: already answer here: 'm confused converting numpy array lists ?",
    "NumPy print trailing 0s? [duplicate]: already answer here: When printing , Numpy replaces trailing 0s s, e.g. fix print 0s?",
    "select change dataframe [duplicate]: already answer here: Using : dataframe select dog strings ? iv : unfortunately did",
    "Convert matrix [duplicate]: already answer here: 'm working numpy using matrix 1x3. : Exists matrix tuple contains matrix order? , matrix",
    "Find element equals , numpy array [duplicate]: already answer here: numpy array lists: filter numpy array keeping lists 5th element 'Back':",
    "nice check numpy array within range? [duplicate]: already answer here: write: numpy array, . 's nice write ?"
   ],
   "code": [
    "  File \"C:\\Python3\\lib\\site-packages\\numpy\\core\\numeric.py\", line 37, in \n    import pickle\n  File \"C:\\Python3\\lib\\pickle.py\", line 93, in \n    from org.python.core import PyStringMap\n  File \"C:\\Users\\Jakub\\desktop\\Nowy\\workspace\\python\\org.py\", line 2, in <module>\n    from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\ncsv = np.genfromtxt ('file.csv', delimiter=\",\")\nsecond = csv[:,1]\nthird = csv[:,2]\n\n>>> second\nOut[1]: array([ 432.,  300.,  432.])\n\n>>> third\nOut[2]: array([ 1.,  1.,  0.])\n",
    "def window(a, w = 4, o = 2, copy = False):\n    sh = (a.size - w + 1, w)\n    st = a.strides * 2\n    view = np.lib.stride_tricks.as_strided(a, strides = st, shape = sh)[0::o]\n    if copy:\n        return view.copy()\n    else:\n        return view\n\nOut[]: \narray([[ 1,  2,  3,  4],\n       [ 3,  4,  5,  6],\n       [ 5,  6,  7,  8],\n       [ 7,  8,  9, 10]])\n",
    "import numpy as np\n\na = np.array([[1, 2], [3, 4], [3, 5], [4, 1], [4, 6]])\nb = np.array([[3, 4], [4, 6]])\n\na1_rows = a.view([('', a.dtype)] * a.shape[1])\na2_rows = b.view([('', b.dtype)] * b.shape[1])\nc = np.setdiff1d(a1_rows, a2_rows).view(a.dtype).reshape(-1, a.shape[1])\nprint c\n",
    "x = np.array([[0, 0]]).tolist()\n",
    "np.set_printoptions(formatter={'float': '{: 0.3f}'.format})\n",
    "df.replace({'dog':0})\n\ndf['animal'].replace('dog', 0)\n",
    ">>> A = matrix([[1,2,3]])\n>>> B = A.tolist()\n>>> B\n[[1, 2, 3]]\n>>> B = A.tolist()[0]\n>>> B\n[1, 2, 3]\n\n>>> B = tuple(A.tolist()[0])\n>>> B\n(1, 2, 3)\n",
    ">>> ar = np.array([[26, 6, 2, 4, 'Bridge',  1.,  8, '2015-02-02'],\n... [23, 6, 1, 4, 'Bridge',  1.,  8, '2015-02-02'],\n... [12, 6, 2, 4, 'Back',  1.,  8, '2015-02-02'],\n... [23, 6, 3, 4, 'Back',  1.,  8, '2015-02-02']])\n>>> check = np.array([a[4]=='Back' for a in ar])\n>>> check\narray([False, False,  True,  True], dtype=bool)\n>>> ar[check]\narray([['12', '6', '2', '4', 'Back', '1.0', '8', '2015-02-02'],\n       ['23', '6', '3', '4', 'Back', '1.0', '8', '2015-02-02']],\n       dtype='|S11')\n>>>\n",
    ">>> a = np.repeat(1, 10)\n>>> np.logical_and(a > 0, a < 2).all()\nTrue\n\n>>> ((0 < a) & (a < 2)).all()\nTrue\n"
   ]
  },
  {
   "questions": [
    ": Transpose create record month dates: dataset below: transpose record month dates e.g. already dataframe. Dates datestamps format YYYY MM DD",
    "copy numpy 2d array 2d dataframe: dataframe structure below: numpy below: copy numpy dataframe define index dataframe. both dataframe numpy array .",
    "Create DataFrame DataFrames: many DataFrames DataFrames . ? Example: dataframe characters B,B,B ( B dataframes)",
    "Average median dataframes: looking best take average median frames ( name). let's say dataframes list_df. write required . interested looking we eliminate",
    "draw graph: text consists . far draw coordinates: draw those coordinates 2rd . Please .",
    "Add insert specific according defined intervall : add dataframe insert <=W1, <=W2 >W2 ? case:",
    "PySpark: Cannot create dataframe : Hi tuples containing string numpy float 64 . change spark dataframe. errors. show below. :",
    "Removing duplicated lines /NumPy: removing both duplicated lines. text : text exactly . Please remove both duplicated lines stays: your guys.",
    "Convert numpy.datetime64 string object : having trouble converting datetime64 object string. : Into: already datetime64 object datetime long string, seem :",
    "Keep spline interpolation: wrote performs spline interpolation: dataset generated new_x new_y original eliminated, last kept. keep original ."
   ],
   "code": [
    "pd.DataFrame(\n    [[c, d] for c, d1, d2 in df.itertuples(index=False)\n     for d in pd.date_range(d1, d2, freq='MS')],\n    columns=['Category', 'Date']\n)\n\n  Category       Date\n0        a 2017-01-01\n1        a 2017-02-01\n2        a 2017-03-01\n3        a 2017-04-01\n4        a 2017-05-01\n5        a 2017-06-01\n6        a 2017-07-01\n7        a 2017-08-01\n\npd.DataFrame(\n    [[c, d] for c, d1, d2, *_ in df.itertuples(index=False)\n     for d in pd.date_range(d1, d2, freq='MS')],\n    columns=['Category', 'Date']\n)\n\npd.DataFrame(\n    [[t[0], d] for t in df.itertuples(index=False)\n     for d in pd.date_range(t[1], t[2], freq='MS')],\n    columns=['Category', 'Date']\n)\n",
    "print raster_arr_df\n     a    b    c    d\n1  NaN  NaN  NaN  NaN\n2  NaN  NaN  NaN  NaN\n3  NaN  NaN  NaN  NaN\n\nprint raster_arr\n[[1 1 3 0]\n [4 2 6 0]\n [4 3 9 5]]\n\nprint pd.DataFrame(data=raster_arr, index=raster_arr_df.index, columns=raster_arr_df.columns)\n   a  b  c  d\n1  1  1  3  0\n2  4  2  6  0\n3  4  3  9  5\n",
    "In [39]:\n\ndf=pd.DataFrame({'a':['A','B','V','D']})\ndf1=pd.DataFrame({'a':['D','C','B']})\ndf2=pd.DataFrame({'a':['A','B']})\ndf[df.a.isin(df1[df1.a.isin(df2.a)].a)]\nOut[39]:\n   a\n1  B\n\nIn [46]:\n\nnp.intersect1d(df2.a.unique(), np.intersect1d(df.a.unique(), df1.a.unique()))\nOut[46]:\narray(['B'], dtype=object)\n\nIn [47]:\n\ndf.merge(df1, on='a').merge(df2, on='a')\nOut[47]:\n   a\n0  B\n\nIn [48]:\n\n%timeit df[df.a.isin(df1[df1.a.isin(df2.a)].a)]\n1000 loops, best of 3: 1.51 ms per loop\nIn [49]:\n\n%timeit np.intersect1d(df2.a.unique(), np.intersect1d(df.a.unique(), df1.a.unique()))\n1000 loops, best of 3: 360 \u00b5s per loop\nIn [50]:\n\n%timeit df.merge(df1, on='a').merge(df2, on='a')\n100 loops, best of 3: 4.76 ms per loop\n",
    "np.random.seed([3,1415])\ndf1 = pd.DataFrame(dict(col_name=np.random.randint(10, size=10)))\ndf2 = pd.DataFrame(dict(col_name=np.random.randint(10, size=10)))\ndf3 = pd.DataFrame(dict(col_name=np.random.randint(10, size=10)))\n\nlist_df = [df1, df2, df3]\n\npd.concat([d['col_name'] for d in list_df], axis=1).median().mean()\n\n3.8333333333333335\n\nnp.median([d['col_name'].values for d in list_df], 1).mean()\n\n3.8333333333333335\n",
    "   import matplotlib.pyplot as plt\n   import numpy as np\n\n   f = np.loadtxt('coordinates.txt',delimiter=' ',skiprows=1)\n\n   f = f[f[:,2] == 1]\n   x = f[:,0]\n   y = f[:,1]\n   plt.plot([x], [y], 'ro')\n   plt.show()\n",
    "W1=3\nW2=6\n\ndf['d'] = np.where(df['column1'] <= W1, 1, \n          np.where(df['column1'] <= W2, 2, 3))\nprint (df)\n   column1  number  d\n0        2       1  1\n1        1       1  1\n2        5       2  2\n3        6       2  2\n4        7       3  3\n5        8       3  3\n6        3       1  1\n\nbins = [-np.inf, W1, W2, np.inf]\nlabels=[1,2,3]\ndf['d1'] = pd.cut(df['column1'], bins=bins, labels=labels)\nprint (df)\n\n   column1  number  d d1\n0        2       1  1  1\n1        1       1  1  1\n2        5       2  2  2\n3        6       2  2  2\n4        7       3  3  3\n5        8       3  3  3\n6        3       1  1  1\n",
    "import numpy as np\n\ndata = [\n    (np.unicode('100912strategy_id'), np.float64(-2.1412)),\n    (np.unicode('10exchange_ud'), np.float64(-1.2412))]\n\ndf = (sc.parallelize(data)\n    .map(lambda x: (str(x[0]), float(x[1])))\n    .toDF([\"key\",\"value\"]))\ndf.show()\n\n+-----------------+-------+\n|              key|  value|\n+-----------------+-------+\n|100912strategy_id|-2.1412|\n|    10exchange_ud|-1.2412|\n+-----------------+-------+\n",
    "import collections\n\nwith open('lines.txt', 'r') as f:\n    for k,c in collections.Counter(f.read().splitlines()).items():\n        if c == 1:\n            print(k)\n\n192.168.1.18 --- B8:27:EB:48:C3:B6\n192.168.1.9 --- DC:4A:3E:DF:22:06\n",
    "import pandas as pd \nts = pd.to_datetime(str(date)) \nd = ts.strftime('%Y.%m.%d')\n",
    "# Interpolate the data using a cubic spline to \"new_length\" samples\nnew_length = 50\ninterpolated_x = np.linspace(x.min(), x.max(), new_length - len(x) + 2)\nnew_x = np.sort(np.append(interpolated_x, x[1:-1]))  # include the original points\nnew_y = sp.interpolate.interp1d(x, y, kind='cubic')(new_x)\n"
   ]
  },
  {
   "questions": [
    "Replace NumPy based dictionary avoid overlap keys: replace numpy based dictionary : cells numpy array match replace corresponding region . issue replacing = 12 region = 16 next , cells 16 (including ones got assigned 16) replaced 17. prevent ?",
    "Replace based occurrence array: replace Numpy based condition element appears replacement array : repl changed - , expect main : However ValueError raised while inside condition replacement ValueError: truth array element ambiguous. Use . () . ()",
    "Replace numpy using old : replace numpy using old . See below (replace_old requested ). must both int, float string . ?",
    "Replace based condition : replace based condition. replace iteratively [255, 255, 255] [255, 255, 255] [255, 255, 255] look :",
    "Replace NaNs masked numpy array: replace NaNs array . . However, : *** IndexError: Index cannot multidimensional fix ?",
    "Align numpy based keys: wondering potentially align numpy based array 's \"key\", NLP ( realize probably done much easier NLTK, 'm implementation). Example, say defined : : Would ?",
    "Replace numpy array condition random : replace numpy based condition random . function adds random 50% : call numpy function, replaces matching random generated: , add_noise() runs once, replaces . noise . \"iterate\" element numpy array, check condition ( == .) generate noise add_noise() . going , anyone efficient manner ?",
    "Fill Nan based group: fill NaN based ' mean. Example: suggestions ? !",
    "Convert 3D array based dictionary: color grayscale based dictionary mapping dictionary : pythonic ?",
    "Ignore NaN numpy bincount : 1D array numpy bincount create histogram. OK, ignore NaN . ? your !"
   ],
   "code": [
    "def replace_with_dict(ar, dic):\n    # Extract out keys and values\n    k = np.array(list(dic.keys()))\n    v = np.array(list(dic.values()))\n\n    # Get argsort indices\n    sidx = k.argsort()\n\n    # Drop the magic bomb with searchsorted to get the corresponding\n    # places for a in keys (using sorter since a is not necessarily sorted).\n    # Then trace it back to original order with indexing into sidx\n    # Finally index into values for desired output.\n    return v[sidx[np.searchsorted(k,ar,sorter=sidx)]]\n\nIn [82]: dic ={334:0, 4:22, 8:31, 12:16, 16:17, 24:27, 28:18, 32:21, 36:1}\n    ...: \n    ...: np.random.seed(0)\n    ...: a = np.random.choice(dic.keys(), 20)\n    ...: \n\nIn [83]: a\nOut[83]: \narray([ 28,  16,  32,  32, 334,  32,  28,   4,   8, 334,  12,  36,  36,\n        24,  12, 334, 334,  36,  24,  28])\n\nIn [84]: replace_with_dict(a, dic)\nOut[84]: \narray([18, 17, 21, 21,  0, 21, 18, 22, 31,  0, 16,  1,  1, 27, 16,  0,  0,\n        1, 27, 18])\n\ndef replace_with_dict2(ar, dic):\n    # Extract out keys and values\n    k = np.array(list(dic.keys()))\n    v = np.array(list(dic.values()))\n\n    # Get argsort indices\n    sidx = k.argsort()\n\n    ks = k[sidx]\n    vs = v[sidx]\n    return vs[np.searchsorted(ks,ar)]\n\nIn [91]: dic ={334:0, 4:22, 8:31, 12:16, 16:17, 24:27, 28:18, 32:21, 36:1}\n    ...: \n    ...: np.random.seed(0)\n    ...: a = np.random.choice(dic.keys(), 20000)\n\nIn [92]: out1 = replace_with_dict(a, dic)\n    ...: out2 = replace_with_dict2(a, dic)\n    ...: print np.allclose(out1, out2)\nTrue\n\nIn [93]: %timeit replace_with_dict(a, dic)\n1000 loops, best of 3: 453 \u00b5s per loop\n\nIn [95]: %timeit replace_with_dict2(a, dic)\n1000 loops, best of 3: 341 \u00b5s per loop\n\ndef replace_with_dict2_generic(ar, dic, assume_all_present=True):\n    # Extract out keys and values\n    k = np.array(list(dic.keys()))\n    v = np.array(list(dic.values()))\n\n    # Get argsort indices\n    sidx = k.argsort()\n\n    ks = k[sidx]\n    vs = v[sidx]\n    idx = np.searchsorted(ks,ar)\n\n    if assume_all_present==0:\n        idx[idx==len(vs)] = 0\n        mask = ks[idx] == ar\n        return np.where(mask, vs[idx], ar)\n    else:\n        return vs[idx]\n\nIn [163]: dic ={334:0, 4:22, 8:31, 12:16, 16:17, 24:27, 28:18, 32:21, 36:1}\n     ...: \n     ...: np.random.seed(0)\n     ...: a = np.random.choice(dic.keys(), (20))\n     ...: a[-1] = 400\n\nIn [165]: a\nOut[165]: \narray([ 28,  16,  32,  32, 334,  32,  28,   4,   8, 334,  12,  36,  36,\n        24,  12, 334, 334,  36,  24, 400])\n\nIn [166]: replace_with_dict2_generic(a, dic, assume_all_present=False)\nOut[166]: \narray([ 18,  17,  21,  21,   0,  21,  18,  22,  31,   0,  16,   1,   1,\n        27,  16,   0,   0,   1,  27, 400])\n",
    "main.ravel()[np.in1d(main, repl)] = -1\n\nnp.putmask(main, np.in1d(main, repl), -1)\n",
    ">>> np.place(dat,np.in1d(dat,old_val),new_val)\n>>> dat\narray([ 1, 11,  3,  4, 57,  6,  7,  8,  1, 11,  3])\n\n>>> dat2 = np.array([1, 2, 1, 2])\n>>> old_val = [1, 2]\n>>> new_val = [33, 66]\n\n>>> z=np.array((old_val,new_val)).T\n>>> for i,j in z:\n...    np.place(dat2,dat2==i,j)\n... \n>>> dat2\narray([33, 66, 33, 66])\n",
    "import numpy as np\n\n#create a matrix similar to yours:\nimg = np.zeros((100,100))\nreplace_line = np.transpose(np.random.randint(100,size=100))\n#replace random lines to have a shape like yours\nimg[40,:] = replace_line\nimg[87,:] = replace_line\n\n\"\"\"\nnow img should be like that:\n 0 0 0 0 0 ...\n .\n .\n x y z ..\n 0 0 0 0 0 ...\n 0 0 0 0 0 ...\n x y z ..\n .\n .\n\"\"\"\n\n#now the actual replacement\n#with the condition I take the indexes to start the replacement\n#I assume that the rows are always equal so I can take the first column\n#as representative of the entire row\n\nnon_zero_indexes = img[:,0] >0\nnon_zero_indexes = np.nonzero(non_zero_indexes)[0]\n\nimg[non_zero_indexes[0]:non_zero_indexes[1],:] = replace_line\n",
    "In [25]: arr = np.array([[10, 20], [np.nan, 30], [np.nan, -10]])\n\nIn [26]: arr\nOut[26]: \narray([[ 10.,  20.],\n       [ nan,  30.],\n       [ nan, -10.]])\n\nIn [27]: np.nan_to_num(arr)\nOut[27]: \narray([[ 10.,  20.],\n       [  0.,  30.],\n       [  0., -10.]])\n\nIn [33]: mx = ma.masked_array([np.nan, 2, 3, 4], mask=[0, 0, 1, 0])\n\nIn [34]: mx.compressed()\nOut[34]: array([ nan,   2.,   4.])\n\nIn [36]: np.nan_to_num(ma.masked_array([np.nan, 2, 3, 4], mask=[0, 0, 1, 0])).compressed()\nOut[36]: array([ 0.,  2.,  4.])\n",
    ">>> all_keys=np.unique(np.array((array1,array2)).T[0])\n>>> dict1=dict(array1)\n>>> dict2=dict(array2)\n\n>>> array1=np.array([[i,dict1.get(i,0)] for i in all_keys])\n>>> array1\narray([['amet', '1'],\n       ['dolor', '5'],\n       ['scripsit', '0'],\n       ['sit', '3']], \n      dtype='|S8')\n>>> array2=np.array([[i,dict2.get(i,0)] for i in all_keys])\n>>> array2\narray([['amet', '1'],\n       ['dolor', '0'],\n       ['scripsit', '10'],\n       ['sit', '1']], \n      dtype='|S8')\n",
    "noise_factor = 0.5 # Input param\n\n# Get mask of zero places and the count of it. Also compute threshold\nmask = X==0\nc = np.count_nonzero(mask)\nthreshold_prob = noise_factor * 100.\n\n# Generate noise numbers for count number of times. \n# This is where vectorization comes into the play.\nnums = np.random.randint(1,100, c)\n\n# Finally piece of the vectorization comes through replacing that IF-ELSE\n# with np,where that does the same op of choosing but in a vectorized way\nvals = np.where(nums <= threshold_prob, np.random.randint(1,100, c) , 0)\n\n# Assign back into X\nX[mask] = vals\n\nnums = np.random.randint(1,100, (2,c))\nvals = np.where(nums[0] <= threshold_prob, nums[1] , 0)\n",
    "df = df.assign(Temp=df.groupby('Groups')['Temp'].transform(lambda x: x.fillna(x.mean())))\nprint(df)\n\n   Temp\n0  27.0\n1  23.0\n2  25.0\n3   NaN\n",
    "In [11]: dct = {3:40, 2:30, 1:20, 0:10}\n\nIn [9]: arr = np.array([10,20,30,40])\n\nIn [12]: arr[3]\nOut[12]: 40\n\nIn [13]: dct[3]\nOut[13]: 40\n\nIn [8]: index = np.array([3,2,1,0])\n\nIn [10]: arr[index]\nOut[10]: array([40, 30, 20, 10])\n\nIn [17]: [dct[i] for i in index]\nOut[17]: [40, 30, 20, 10]\n\nIn [19]: %timeit arr[index]\n1000000 loops, best of 3: 201 ns per loop\n\nIn [20]: %timeit [dct[i] for i in index]\n1000000 loops, best of 3: 1.63 \u00b5s per loop\n\nimport numpy as np\n\ncolor = np.array([\n    [  0,   0,   0],\n    [128,   0, 128],\n    [  0, 128, 128],\n    [  0,   0, 128],\n    [  0, 128,   0],\n    [128, 128,   0],\n    [128, 128, 128],\n    [128,   0,   0],], dtype='uint8').reshape(-1,2,3)\n\ncolor2ind = {(128, 128, 128): 6, \n             (0, 128, 128): 2, \n             (128, 0, 128): 1, \n             (128, 0, 0): 7, \n             (128, 128, 0): 5, \n             (0, 0, 128): 3, \n             (0, 128, 0): 4, \n             (0, 0, 0): 0}\n\ndef rgb2int(arr):\n    \"\"\"\n    Convert (N,...M,3)-array of dtype uint8 to a (N,...,M)-array of dtype int32\n    \"\"\"\n    return arr[...,0]*(256**2)+arr[...,1]*256+arr[...,2]\n\ndef rgb2vals(color, color2ind):\n    int_colors = rgb2int(color)\n    int_keys = rgb2int(np.array(color2ind.keys(), dtype='uint8'))\n    int_array = np.r_[int_colors.ravel(), int_keys]\n    uniq, index = np.unique(int_array, return_inverse=True)\n    color_labels = index[:int_colors.size]\n    key_labels = index[-len(color2ind):]\n\n    colormap = np.empty_like(int_keys, dtype='uint32')\n    colormap[key_labels] = color2ind.values()\n    out = colormap[color_labels].reshape(color.shape[:2])\n    return out\n\nprint(rgb2vals(color, color2ind))\n\n[[0 1]\n [2 3]\n [4 5]\n [6 7]]\n\ndef using_loops(color, color2ind):\n    M, N = color.shape[:2]\n    out = np.zeros((M, N))\n    for i in range(M):\n        for j in range(N):\n            out[i][j] = color2ind[tuple(color[i,j,:])]\n    return out\n\nIn [295]: color = np.tile(color, (100,100,1))\n\nIn [296]: (rgb2vals(color, color2ind) == using_loops(color, color2ind)).all()\nOut[296]: True\n\nIn [297]: %timeit rgb2vals(color, color2ind)\n100 loops, best of 3: 6.74 ms per loop\n\nIn [298]: %timeit using_loops(color, color2ind)\n1 loops, best of 3: 751 ms per loop\n\nIn [270]: int_colors = rgb2int(color)\nIn [270]: int_colors\nOut[270]: \narray([[      0, 8388736],\n       [  32896,     128],\n       [  32768, 8421376],\n       [8421504, 8388608]], dtype=uint32)\n\nIn [271]: int_keys = rgb2int(np.array(color2ind.keys(), dtype='uint8'))\nIn [271]: int_keys\nOut[271]: \narray([8388608, 8421504, 8388736, 8421376,     128,       0,   32768,\n         32896], dtype=uint32)\n\nIn [283]: int_array = np.r_[int_colors.ravel(), int_keys]\n\nIn [284]: uniq, index = np.unique(int_array, return_inverse=True)\n\nIn [285]: index\nOut[285]: array([0, 5, 3, 1, 2, 6, 7, 4, 4, 7, 5, 6, 1, 0, 2, 3])\n\nIn [286]: uniq\nOut[286]: \narray([      0,     128,   32768,   32896, 8388608, 8388736, 8421376,\n       8421504], dtype=uint32)\n\nIn [265]: (uniq[index] == int_array).all()\nOut[265]: True\n\ncolor_labels = index[:int_colors.size]\nkey_labels = index[-len(color2ind):]\n\ncolormap[key_labels] = color2ind.values()\n\nout = colormap[color_labels].reshape(color.shape[:2])\n\nIn [267]: out\nOut[267]: \narray([[7, 6],\n       [1, 5],\n       [3, 0],\n       [4, 2]], dtype=uint32)\n",
    "import numpy\n\nw = numpy.array([0.3, float(\"nan\"), 0.2, 0.7, 1., -0.6]) # weights\nx = numpy.array([0, 1, 1, 2, 2, 2])\nnumpy.bincount(x,  weights=w)\n#>>> array([ 0.3,  nan,  1.1])\n\nkeep = ~numpy.isnan(w)\nnumpy.bincount(x[keep],  weights=w[keep])\n#>>> array([ 0.3,  0.2,  1.1])\n"
   ]
  },
  {
   "questions": [
    "execute foo = fun(foo) many variables numpy: related reading MATLAB . scipy.io many variables MATLAB n* *m. Suppose variables names foo1, foo2, foo3, ... apply foo = np.squeeze(foo) variables. deal apply spueeze function variable explicitly? advance.",
    "Numpy: stack array last dimension: Suppose numpy , b, c, , say Now 'd create dimensional array (7,9, ), say , \"pythonic\" (perhaps )? advance!",
    "equivalent MATLAB statement (B== )= C: three numpy follows: replace their equivalent B equal . : MATLAB, : Do equivalent (preferably B multidimensional too)? advance.",
    "checking whether tuple : Suppose variables follows: obtain vector , truth presence variable inside . , say P.S. using np.in1d :",
    "NumPy array: equivalent MATLAB command Numpy? MATLAB, ,",
    "Numpy: placing - -n based array: Suppose we had : , e.g. array([ . , .4, .6]), (let's say, array([ , , ])) Our expected put bigger array, \"addressed\" , we loops, nice, fast ?",
    "Numpy matrix operations: compute j: using Numpy ( ) explicit ? !",
    "Confusion operation numpy: generally MATLAB Octave, recently switching numpy. numpy define array great array MATLAB extract entire ( ,), ? expect ( , ). Perhaps misunderstood basic concept. Can anyone clear ??",
    "Extracting selected datafile using : copy selected . Suppose copy 1st, 2nd 6th , look formatted text initially written programming . ?",
    "Construct matrix using : calculated 9 matrix named sij, j being variables ( ,j = [ , , ]). , denotes j . Suppose 3x3 matrix consists matrix s11, s12, ... s32, s33 (nine total). loops construct matrix ? Like : matrix ."
   ],
   "code": [
    "In [854]: data = loadmat('test.mat')\nIn [855]: data\nOut[855]: \n{'__globals__': [],\n '__header__': b'MATLAB 5.0 MAT-file, written by Octave 4.0.0, 2017-11-08 02:28:22 UTC',\n '__version__': '1.0',\n 'x': array([[  1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.]]),\n 'y': array([[ 1.,  3.,  6.,  4.,  6.]]),\n 'z': array([[ 1.,  2.],\n        [ 3.,  4.]])}\n\nIn [856]: data['x'].shape\nOut[856]: (1, 10)\nIn [857]: np.squeeze(data['x']).shape\nOut[857]: (10,)\n\nIn [861]: data = loadmat('test.mat', squeeze_me=True)\nIn [862]: data\nOut[862]: \n{'__globals__': [],\n '__header__': b'MATLAB 5.0 MAT-file, written by Octave 4.0.0, 2017-11-08 02:28:22 UTC',\n '__version__': '1.0',\n 'x': array([  1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.]),\n 'y': array([ 1.,  3.,  6.,  4.,  6.]),\n 'z': array([[ 1.,  2.],\n        [ 3.,  4.]])}\n\nIn [866]: for key in ['x','y']:\n     ...:     data[key] = np.squeeze(data[key])\n     ...:     \nIn [867]: data\nOut[867]: \n{'__globals__': [],\n '__header__': b'MATLAB 5.0 MAT-file, written by Octave 4.0.0, 2017-11-08 02:28:22 UTC',\n '__version__': '1.0',\n 'x': array([  1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.]),\n 'y': array([ 1.,  3.,  6.,  4.,  6.]),\n 'z': array([[ 1.,  2.],\n        [ 3.,  4.]])}\n",
    "In [10]: import numpy as np\n\nIn [11]: a = np.ones((7, 9))\n\nIn [12]: b = a * 2\n\nIn [13]: c = a * 3\n\nIn [15]: x = np.dstack((a, b, c))\n\nIn [16]: x.shape\nOut[16]: (7, 9, 3)\n\nIn [17]: (x[:, :, 0] == a).all()\nOut[17]: True\n\nIn [18]: (x[:, :, 1] == b).all()\nOut[18]: True\n\nIn [19]: (x[:, :, 2] == c).all()\nOut[19]: True\n",
    ">>> import numpy as np\n>>> A = np.array([1, 2, 3, 4, 5])\n>>> B = np.array([0, 1, 0, 0, 1])\n>>> C = np.array([30, 40])\n>>> A[B==1] = C\n>>> A\narray([ 1, 30,  3,  4, 40])\n",
    ">>> v=[('d', 0), ('i', 0), ('g', 0)]\n>>> g=[('t', 0), ('g', 0),('d',0)]\n>>> [i in g for i in v]\n[True, False, True]\n",
    ">>> a = zeros((2, 5))\n>>> a.shape\n(2, 5)\n",
    "a = zeros((3,3))\nb = array([0, 2, 1])\nvals = array([1.2, 1.4, 1.6])\n\n>>> a[r_[:len(b)], b] = vals\n\n\narray([[ 1.2,  0. ,  0. ],\n       [ 0. ,  0. ,  1.4],\n       [ 0. ,  1.6,  0. ]])\n",
    "import numpy as np\nfrom numpy import newaxis\n\ndef explicit(a):\n    n = a.shape[0]\n    m = np.zeros_like(a)\n    for k in range(n):\n        for i in range(n):\n            for j in range(n):\n                m[k,i] += a[i,j] - a[i,k] - a[k,j] + a[k,k]\n    return m\n\ndef implicit(a):\n    n = a.shape[0]\n    m = np.zeros_like(a)\n    for k in range(n):\n        for i in range(n):\n            for j in range(n):\n                m[k,i] += a[i,j] - a[i,k] - a[k,j] + a[k,k]\n    return m\n\na = np.random.randn(10,10)\nassert np.allclose(explicit(a), implicit(a), atol=1e-10, rtol=0.)\n\ndef implicit(a):\n    n = a.shape[0]\n    m = np.zeros_like(a)\n    for k in range(n):\n        for i in range(n):\n            m[k,i] = (a[i,:] - a[k,:]).sum() - n*a[i,k] + n*a[k,k]\n    return m\n\ndef implicit(a):\n    n = a.shape[0]\n    m = np.zeros_like(a)\n    m = - n*a.T + n*np.diag(a)[:,newaxis]\n    for k in range(n):\n        for i in range(n):\n            m[k,i] += (a[i,:] - a[k,:]).sum()\n    return m\n\ndef implicit(a):\n    n = a.shape[0]\n    m = np.zeros_like(a)\n    m = - n*a.T + n*np.diag(a)[:,newaxis]\n    m += (a.T[newaxis,...] - a[...,newaxis]).sum(1)\n    return m\n",
    "a = np.zeros(5,)\nprint(a.shape)\n# (5,)\n\n# explicitly reshape to (5, 1)\nprint(a.reshape(5, 1).shape)\n# (5, 1)\n\n# or use -1 in the first dimension, so that its size in that dimension is \n# inferred from its total length\nprint(a.reshape(-1, 1).shape)\n# (5, 1)\n\na = np.zeros((3, 4, 5))\nprint(a[np.newaxis, :, np.newaxis, ..., np.newaxis].shape)\n# (1, 3, 1, 4, 5, 1)\n\na = np.matrix([[2, 3], [4, 5]])\nprint(a[:, 0].shape)\n# (2, 1)\n",
    "COLS=0,1,5  # the columns you want. The first is numbered zero.\n            # NB its a tuple: COLS=0, for one column, mandatory trailing comma\n\nSEP = ', '  # the string you want to separate the columns in the output\n\nINFILE='t.txt'      # file to read from\nOUTFILE='out.txt'   # file to write to\n\nf = open( INFILE, 'r')\ng = open( OUTFILE, 'w')\n\nfor line in f.readlines():\n   x = line.split()\n   if x != []:  # ignore blank lines\n\n       y = [ x[i] for i in COLS ]\n       outline = SEP.join( '{}'.format(q) for q in y )\n       g.write( outline+'\\n')\n",
    "s[1][1] = 1\ns[1][2] = 2\ns[1][3] = 3\n(...)\ns[3][3] = 9\n\nmatrix = [[s11, s12, s13], [s21, s22, s23], [s31, s32, s33]]\n\nfor i in (1,4):\n   for j in (1,4):\n"
   ]
  },
  {
   "questions": [
    "Variable name defined: basically 'm sub directories files (images), sub directory contains images, starts word , starts word . sub directory assign starts variable img1, starts img2. 's got: path = '/my_path/' When however, : wrong? .",
    "fill multiple named fields using structured : take information fields write variable using . write 1st 2nd fields 1st var2. : : achieve perform: order perform higher lists avoiding ?",
    "Defining function variables array initialization class: written , tells : input P2 = FourVector(ct 99.9, r=[ , , ])",
    "- New Variable inidcator: indicator variable dataframe (df), Basically \"Splits\" unless field (AssetClass) \"Future\" case indicator \"NotSplit\" im using moment : far variable call \"Split\" skip next . Can anyone problems here?",
    "Reading txt [closed]: 'm text named testfile.txt. NumPy function genfromtext, however Index : Too many . textfile consists 6 numbers: :",
    "Change inside based logic - : array (called 'img') modify. change array they below 200 255 they equal 200: However, : ?",
    "Getting last non na across dataframe: dataframe (40,500). Each dataframe numerical till variable k, entries after nan. last non nan . looping dataframe? Sample Dataframe: Reqd",
    ": 'm using syntax: However, stack trace: : fix ?",
    "Broadcasting Pandas: dataframe ( ) , subtract (b), -wise: expect operation : However . operation , inelegant. correct ?",
    "dummy float variables: create dummy location : lapse around 5.4 seconds.. faster ? ,"
   ],
   "code": [
    "#Your code\nif file.startswith('first'):\n        img1 = numpy.asarray(Image.open(root + '/' + file))\n",
    "In [139]: var1[myList]\nOut[139]: \narray([(1, 2), (11, 22), (111, 222)], \n      dtype=[('field1', '<i4'), ('field2', '<i4')])\n\nIn [138]: var2[myList]= var1[myList]\n---------------------------------------------------------------------------\nIndexError                                Traceback (most recent call last)\n<ipython-input-138-570d16e71a2e> in <module>()\n----> 1 var2[myList]= var1[myList]\n\nIndexError: unsupported iterator index\n\nfor name in myList:\n    var2[name] = var1[name][0]     \n\nIn [160]: var2.view(int)[:2] = var1[myList][0].tolist()\n\nvar2.view(int)[:2]=var1.view(int).reshape((3,4))[0,:2]\n\nvar1.view(int).reshape((3,4))  # or \nvar1.view(int).reshape((-1,4))\n\nvar1.view((int,4))\n",
    "import numpy as np\nclass FourVector:\n    def __init__(self,ct=0,a=0,b=0,c=0):\n        r=np.array([a,b,c])\n        self.t=ct\n        self.s=r\n\nP2 = FourVector(99.9,1,2,3)\n",
    "df['Category'] = 'NotSplit' if df.AssetClass == 'Future' else 'Split'\n\ndf['Category'] = 'Split'\ndf[True] = 'NotSplit'\n\ndf['Category'] = 'Split'\nif df.AssetClass == 'Future':\n    df['Category'] = 'NotSplit'\n",
    "table = numpy.genfromtxt('testfile.txt', comments=\"%\")\n\n# etc.\n",
    "np.where(img<200, 0, 255)\n\nnp.where(img<245, 0, 255)\nOut[4]: \narray([[[  0,   0,   0],\n        [255, 255, 255],\n        [255, 255, 255]]])\n",
    "def f(x):\n    if x.last_valid_index() is None:\n        return np.nan\n    else:\n        return x[x.last_valid_index()]\n\ndf['status'] = df.apply(f, axis=1)\nprint (df)\n                1      2      3      4      5      6      7      8      9  \\\n0                                                                           \n2016-06-02  7.080  7.079  7.079  7.079  7.079  7.079    NaN    NaN    NaN   \n2016-06-08  7.053  7.053  7.053  7.053  7.053  7.054    NaN    NaN    NaN   \n2016-06-09  7.061  7.061  7.060  7.060  7.060  7.060    NaN    NaN    NaN   \n2016-06-14    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n2016-06-15  7.066  7.066  7.066  7.066    NaN    NaN    NaN    NaN    NaN   \n2016-06-16  7.067  7.067  7.067  7.067  7.067  7.067  7.068  7.068    NaN   \n2016-06-21  7.053  7.053  7.052    NaN    NaN    NaN    NaN    NaN    NaN   \n2016-06-22  7.049  7.049    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n2016-06-28  7.058  7.058  7.059  7.059  7.059  7.059  7.059  7.059  7.059   \n\n            status  \n0                   \n2016-06-02   7.079  \n2016-06-08   7.054  \n2016-06-09   7.060  \n2016-06-14     NaN  \n2016-06-15   7.066  \n2016-06-16   7.068  \n2016-06-21   7.052  \n2016-06-22   7.049  \n2016-06-28   7.059  \n\ndf['status'] = df.ffill(axis=1).iloc[:, -1]\nprint (df)\n            status  \n0                   \n2016-06-02   7.079  \n2016-06-08   7.054  \n2016-06-09   7.060  \n2016-06-14     NaN  \n2016-06-15   7.066  \n2016-06-16   7.068  \n2016-06-21   7.052  \n2016-06-22   7.049  \n2016-06-28   7.059  \n",
    ">>> lst = [[[1, 2]], [[2, 1]]]\n\n>>> len(lst)\n2\n>>> lst[0]\n[[1, 2]]\n>>> len(lst[0])\n1\n\n>>> [l[0] for l in lst]\n[[1, 2], [2, 1]]\n\n>>> a = np.array(lst)\n>>> a.shape\n(2, 1, 2)\n>>> a.squeeze()\narray([[1, 2],\n       [2, 1]])\n>>> b = a.squeeze()\n>>> b.shape\n(2, 2)\n>>> b.tolist()\n[[1, 2], [2, 1]]\n",
    ">>> a = pd.DataFrame(np.arange(0,20).reshape(5,4))\n>>> b = [1,2,3,4,5]\n>>> a.sub(b, axis=0)\n    0   1   2   3\n0  -1   0   1   2\n1   2   3   4   5\n2   5   6   7   8\n3   8   9  10  11\n4  11  12  13  14\n\n[5 rows x 4 columns]\n>>> np.allclose(a.sub(b,axis=0), (a.T-b).T)\nTrue\n",
    "get_num = np.random.random_integers\nlat = np.random.choice([-1, 1])*round(get_num(0,90000000-1)/1000000.0,6)\nlon = np.random.choice([-1, 1])*round(get_num(0,180000000-1)/1000000.0,6)\n\nIn [5]: %timeit np.random.choice([-1, 1])*round(get_num(0,90000000-1)/1000000.0,6)\n100000 loops, best of 3: 10.7 \u00b5s per loop\n\nIn [6]: %timeit np.random.choice([-1, 1])*round(get_num(0,180000000-1)/1000000.0,6)\n100000 loops, best of 3: 10.8 \u00b5s per loop\n"
   ]
  },
  {
   "questions": [
    "List List List slicing : simulated 10000 scenarios 4 variables during 120 months. Hence, scenarios lists lists element scenarios[ ][ ][ ], , give float. slice , dividing . Which means keep 10000 scenarios 4 variables 60 months. go ? intuition tell . Instead cutting , cuts . wrong? Example: case, Q=",
    "Reading ALL variables .mat h5py: 'm pull variables '.mat' v7. , turn NumPy . generically, preferably needing specify variable names? present variable names h5py.File, check their dimensions? Ex.",
    "Multivariable multiplication : No idea multiply polynomials variable. Below running IPython. Expected polynomial variable y below .",
    "efficient shuffle numpy matrix: shuffle numpy matrix. current copy X variable Xt. inefficient. speed ? EDIT: Example Given expected : Only shuffled . All original matrix",
    "Pythonic handling: require threes separate variables knew write three lines . However, Pythonic using examples below: HERE name answers resulted class0,class1,class2???",
    "Abstract matrix multiplication variables: ability matrix multiplications. Unfortunately abstractly? definite numbers variables. Example: define ,c d, matrix multiplication ?",
    "variables - closest zero: variables - Value1 Value2 using previous functions . select variable closest zero. variables change decimal integer format positive/negative . seen examples using lambda numpy 'm 'm unsure implement correctly. Examples seen array mine separate variables."
   ],
   "code": [
    "early_scenarios = [x[:60] for x in scenarios]\n",
    "import numpy as np\nimport h5py\n\nf = h5py.File('simdata_020_01.mat','r')\nvariables = f.items()\n\nfor var in variables:\n    name = var[0]\n    data = var[1]\n    print \"Name \", name  # Name\n    if type(data) is h5py.Dataset:\n        # If DataSet pull the associated Data\n        # If not a dataset, you may need to access the element sub-items\n        value = data.value\n        print \"Value\", value  # NumPy Array / Value\n",
    "from sympy import Poly\nfrom sympy.abc import x, y\n\nm1 = Poly((1, 0, 0, 1), x)\nm2 = Poly((1,0), y)\nm1, m2\n\nm1 * m2\n",
    "import numpy as np\nX = np.arange(25).reshape(5,5).transpose()\nprint X\nnp.random.shuffle(X[:,2])  # here, X[:,2] is a just a view onto this column of X\nprint X\n\n[[ 0  1  2  3  4]  # the original\n [ 5  6  7  8  9]\n [10 11 12 13 14]\n [15 16 17 18 19]\n [20 21 22 23 24]]\n\n[[ 0  1  2  3  4]  # note that the middle column is shuffled here\n [ 5  6 12  8  9]\n [10 11 22 13 14]\n [15 16 17 18 19]\n [20 21  7 23 24]]\n\ndef sc(x):\n    p = X.shape[1]\n    for i in range(p):\n        hold = np.array(x[:,i])\n        np.random.shuffle(x[:,i])\n        yield x\n        x[:,i] = hold\n\nfor i in sc(X):\n    print i\n\n[[ 2  5 11 15 20]    # #0 column shuffled\n [ 3  6 10 16 21]\n [ 0  7 14 17 22]\n [ 4  8 13 18 23]\n [ 1  9 12 19 24]]\n\n[[ 0  5 11 15 20]    # #1 column shuffled\n [ 1  8 10 16 21]\n [ 2  9 14 17 22]\n [ 3  7 13 18 23]\n [ 4  6 12 19 24]]\n\n#  etc\n",
    "classes = ['class0', 'class1', 'class2']\nvalues =[0,1,2]\noutput = {} #create a dictionary instance\n\nfor x, y in zip(classes, values):\n    output[x] = np.where(data == y) #use the class name as the dictionary key\n",
    ">>> from sympy import *\n>>> var('a c d A B')\n(a, c, d, A, B)\n>>> A = Matrix([[1, 0], [a, c]])\n>>> A\nMatrix([\n[1, 0],\n[a, c]])\n>>> B = Matrix([[1, d], [0, 1]])\n>>> B\nMatrix([\n[1, d],\n[0, 1]])\n>>> M = A.multiply(B)\n>>> M\nMatrix([\n[1,       d],\n[a, a*d + c]])\n",
    "a = -4\nb = 3\n\nmin(a, b, key=abs)\n\n# 3\n"
   ]
  },
  {
   "questions": [
    "Weird behavior class attribute, __iadd__ (+=) numpy.random.randn(): been modelling stochastic process Numpy witnessing weird behavior : array 10 identical random numbers opposed 10 random numbers expected. Eliminating object.__iadd__ operator / replacing np.random.randn(.) constant solve issue. Anybody idea root ?",
    "Weird behavior squaring numpy array: numpy ( , 250000): create numpy whose square root sum squares b, correct : Am missing here?",
    "select n dimensional array: been perform operation, 't seem using Numpy functions creating unnecessary copies array. Suppose we dimensional array : array : select , , last dimension whose index corresponding element y. words, : now using dimension y, follows : avoiding here, using numpy functions fancy indexing? !",
    "numpy.savetxt saving element ?: syntax store around 10,000 text notice being stored . load text using numpy.loadtxt, instead matrix. numpy.reshape loaded array matrix application won't known user who loads . solve issue?",
    "concatenating 2d : There lot concatenating/appending found nothing inbuild : Input: Output: dont solve efficient ( inbuild? )",
    "Ruby NArray.to_na() numpy.array(): Suppose string. mimic behavior using numpy.array? , did . Then bytes, did either. resolve ?",
    "-axis appears once, : 'm , playing around 's plotting capability. wanted Y1 Y2 X go 10 100 steps 10, 100 10 steps -10. using Excel. X Y we using matplotlib numpy?",
    "Round plotting: array : When : expect straight meaningful y axis. cause behavior?",
    "Odd behavior to_dict: 'm building fuzzy search program, using FuzzyWuzzy, matching names dataset. DataFrame 10378 len(df['Full name']) 10378, expected. len(choices) 1695. 'm running .7.10 .17. , IPython Notebook. As probably tell, 'm index choices dict df_ind, had assumed index main dataframe. 'm fairly certain issue , to_dict() function, len(df['Full name'].astype(str)results 10378 len(df['Full name'].to_dict()) results 1695.",
    "Numpy 's Decimal arguments: little . program, . , made decimal ( ): mean using Numpy. wrote: got : wrong ?"
   ],
   "code": [
    "In [27]: np.random.randn(1)\nOut[27]: array([-1.90409169])\n\nself.x += np.random.randn(1)\n",
    "In [7]: a = np.array([[0, 254, 1, 255, 0, 1]], dtype=np.uint8)\n\nIn [8]: np.square(a)\nOut[8]: array([[0, 4, 1, 1, 0, 1]], dtype=uint8)\n\nIn [9]: b = np.array([[1, 0, 252, 0, 255, 255]], dtype=np.uint8)\n\nIn [10]: np.square(a) + np.square(b)\nOut[10]: array([[ 1,  4, 17,  1,  1,  2]], dtype=uint8)\n\nIn [11]: np.sqrt(np.square(a) + np.square(b))\nOut[11]: \narray([[ 1.        ,  2.        ,  4.12310553,  1.        ,  1.        ,\n         1.41421354]], dtype=float32)\n\nIn [15]: np.sqrt(np.square(a, dtype=np.float64) + np.square(b, dtype=np.float64))\nOut[15]: \narray([[   1.        ,  254.        ,  252.00198412,  255.        ,\n         255.        ,  255.00196078]])\n\nIn [16]: np.hypot(a, b)\nOut[16]: array([[   1.,  254.,  252.,  255.,  255.,  255.]], dtype=float16)\n\nIn [17]: np.hypot(a, b, dtype=np.float64)\nOut[17]: \narray([[   1.        ,  254.        ,  252.00198412,  255.        ,\n         255.        ,  255.00196078]])\n",
    ">>> x[np.arange(x.shape[0]), :, y]\narray([[ 0,  2,  4],\n       [ 7,  9, 11],\n       [13, 15, 17],\n       [18, 20, 22]])\n",
    "x = np.arange(5)\nnp.savetxt('test.txt', x[np.newaxis], fmt='%d', delimiter=',')\n\nnp.savetxt('test.txt', x, fmt='%d', newline=' ', delimiter=',')\n\n0 1 2 3 4\n",
    "In [127]: C = list(map(list, zip(A, B)))\n\nIn [128]: C\nOut[128]: [[[0, 0], [0]], \n           [[0, 1], [1]], \n           [[1, 0], [1]], \n           [[1, 1], [0]]]\n",
    "import numpy as np\n\nline = \"#!/usr/bin/ruby\\n#\\n#  Gen\"\narray = np.fromstring(line, dtype=float)\nprint array\n\n[  9.05457127e+164   3.30197767e-258   6.15310337e+223]\n",
    "import matplotlib.pyplot as plt\n\nX  = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 100, 90, 80, 70, 60, 50, 40, 30, 20, 10]\nY1 = [0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 900, 800, 700, 600, 500, 400, 300, 200, 100, 0]\nY2 = [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1000, 900, 800, 700, 600, 500, 400, 300, 200, 100]\n\nfig = plt.figure()\nax1=plt.subplot(211)\nax2=plt.subplot(212)\n\n# First example: overlap repeated X values\nax1.plot(X,Y1,'ro')\nax1.plot(X,Y2,'bo')\nax1.set_title('ax.plot')\n\n# Second example: keep all X values in sequential order\nax2.scatter(range(len(Y1)),Y1,color='r')\nax2.scatter(range(len(Y2)),Y2,c='b')\nax2.set_title('ax.scatter')\nax2.set_xlim(0,len(Y1)-1)\nax2.set_xticks(range(len(Y1)))\nax2.set_xticklabels(X)\n\nplt.show()\n",
    "In [53]: round(data,7)\nOut[53]: array([  9.95000000e-05,   9.95000000e-05,   9.95000000e-05,\n         ... \n         ...\n         ])\n\nIn [54]: plot(round(data,7))\n",
    "In [36]: df = pd.DataFrame([[1],[2]],index=[1,1],columns=['A'])\n\nIn [37]: df\nOut[37]:\n   A\n1  1\n1  2\n\nIn [38]: df['A'].to_dict()\nOut[38]: {1: 2}\n\nchoices = df.reset_index()['Full name'].astype(str).to_dict()\n\nIn [40]: df.reset_index()['A'].to_dict()\nOut[40]: {0: 1, 1: 2}\n",
    ">>> sum(x)/len(x)\nDecimal('651.3333333333333333333333333')\n\n>>> np.array(x).mean()\nDecimal('651.3333333333333333333333333')\n"
   ]
  },
  {
   "questions": [
    "Create empty 3D numpy array append : feel easy , 'm too familiar Numpy yet couldn't anything library fitting needs. feel obvious thing, couldn't similar regarding StackOverflow. Basically, create dimensional empty array. : matrix = np. None, ndmin ). now variable append dimension matrix chose variable. ? played around np.append() np.insert() couldn't come .",
    "Error using rot90 3D numpy array arguments: .7.10; Numpy .8. While going examples matrix rotation here keep . : : TypeError: rot90() takes most arguments ( ) copy pasting, typing , , joy. understand text , why, especially since direct SciPy site. issue?",
    "Creating block matrix numpy: sets 3D numpy create matrix vector representations follows: usage : matrix now (30, 12). 30 ( per point) 12 . matrix 30 long case. achieve writing explicit ?",
    ".7 appending 2d array: , y: z matrix, : z = [y[ ], , y[ ], y[ ]]: made : saving matrix. resulting z last operation: save changes made matrix? numpy.append() , message:",
    "-Using Numpy, .txt \ufb01le assign variables: ` sample long text they . asking separate assigning variables ? keep whenever .txt float type right now reading",
    "Numpy spare matrix, dense: spase matrix called X. sparse , etc... , 100 . ? sparse format.",
    "- numpy: divide items themselves: matrix: matrix : soution divide multiply items using numpy?",
    "Reshaping 1D bytes object 3D numpy array: 'm using FFmpeg decode video, piping RGB24 raw . format binary : (640, 360, ) numpy array, wondering reshape , especially, .",
    "Pandas conditional statement NaT: , dataframe many variables. index uid variables dates. create flag variables certain NaT 't correct statement. : easily?",
    "Create distance matrix using lists: : From build matrix dataframe: efficient ?"
   ],
   "code": [
    "np.empty((10, 10, 10))\n\nmatrix[x,y,z] = newElement\nx += 1\n\nfinalMatrix = matrix[:x,:y,:z]\n",
    "def rot90(m, k=1, axes=(0,1)):\n    axes = tuple(axes)\n    if len(axes) != 2:\n        raise ValueError(\"len(axes) must be 2.\")\n\n    m = asanyarray(m)\n\n    if axes[0] == axes[1] or absolute(axes[0] - axes[1]) == m.ndim:\n        raise ValueError(\"Axes must be different.\")\n\n    if (axes[0] >= m.ndim or axes[0] < -m.ndim\n        or axes[1] >= m.ndim or axes[1] < -m.ndim):\n        raise ValueError(\"Axes={} out of range for array of ndim={}.\"\n            .format(axes, m.ndim))\n\n    k %= 4\n\n    if k == 0:\n        return m[:]\n    if k == 2:\n        return flip(flip(m, axes[0]), axes[1])\n\n    axes_list = arange(0, m.ndim)\n    (axes_list[axes[0]], axes_list[axes[1]]) = (axes_list[axes[1]],\n                                                axes_list[axes[0]])\n\n    if k == 1:\n        return transpose(flip(m,axes[1]), axes_list)\n    else:\n        # k == 3\n        return flip(transpose(m, axes_list), axes[1])\n\ndef flip(m, axis):\n    if not hasattr(m, 'ndim'):\n        m = asarray(m)\n    indexer = [slice(None)] * m.ndim\n    try:\n        indexer[axis] = slice(None, None, -1)\n    except IndexError:\n        raise ValueError(\"axis=%i is invalid for the %i-dimensional input array\"\n                         % (axis, m.ndim))\n    return m[tuple(indexer)]\n",
    "import numpy as np\n\npts = np.arange(1, 31).reshape(10, 3)\n\nn, d = pts.shape\nI = np.eye(d, dtype=pts.dtype)\n\n# the first d**2 columns of xyz values\nxyzcols = np.kron(I, pts[:, None]).reshape(-1, d * d)\n\n# the final d columns of ones\neyecols = np.tile(I, n).T\n\n# concatenate\nout = np.hstack([xyzcols, eyecols])\n\nprint(repr(out[:6]))\n# array([[1, 2, 3, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n#        [0, 0, 0, 1, 2, 3, 0, 0, 0, 0, 1, 0],\n#        [0, 0, 0, 0, 0, 0, 1, 2, 3, 0, 0, 1],\n#        [4, 5, 6, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n#        [0, 0, 0, 4, 5, 6, 0, 0, 0, 0, 1, 0],\n#        [0, 0, 0, 0, 0, 0, 4, 5, 6, 0, 0, 1]])\n",
    "np.c_[np.array(y)[0],np.asanyarray(x),np.array(y)[1],np.array(y)[2]]\nOut[536]: \narray([[1, 1, 2, ..., 4, 0, 0],\n       [0, 5, 6, ..., 8, 1, 0],\n       [0, 9, 0, ..., 6, 0, 1]])\n\nnp.roll(np.c_[np.array(x),np.roll(np.array(y),-1,axis=1)],1,axis=1)\nOut[549]: \narray([[1, 1, 2, ..., 4, 0, 0],\n       [0, 5, 6, ..., 8, 1, 0],\n       [0, 9, 0, ..., 6, 0, 1]])\n",
    "a, b = np.loadtxt(\"data_.txt\", skiprows=1).T\n\nskiprows=1  ->  skip the first row (because it doesn't contain numbers)\n.T          ->  take transpose. numpy is [row-major](https://en.wikipedia.org/wiki/Row-_and_column-major_order) meaning that when splitting up the data it will first cut up the columns and leave the rows as whole\na, b        ->  assigning to a tuple of variables triggers the splitting up of the right-hand-side\n",
    "for row in X:\n    do_stuff(row)\n\nfor i, row in enumerate(X):\n    do_other_stuff(i, row)\n",
    "b/a * c/b \n\nresult = arr[:,2] / arr[:,0]\n",
    "np.array(rgb).reshape(640, 360, 3)\n\n>>> import random\n>>> import numpy as np\n>>> bytearray(random.getrandbits(8) for _ in range(3 * 4 * 4))\nbytearray(b'{)jg\\xba\\xbe&\\xd1\\xb9\\xdd\\xf9@\\xadL?GV\\xca\\x19\\xfb\\xbd\\xad\\xc2C\\xa8,+\\x8aEGpo\\x04\\x89=e\\xc3\\xef\\x17H@\\x90]\\xd5^\\x94~/')\n>>> rgb = bytearray(random.getrandbits(8) for _ in range(3 * 4 * 4))\n>>> np.array(rgb)\narray([112,  68,   7,  41, 175, 109, 124, 111, 116,   6, 124, 168, 146,\n        60, 125, 133,   1,  74, 251, 194,  79,  14,  72, 236, 188,  56,\n        52, 145, 125, 236,  86, 108, 235,   9, 215,  49, 190,  16,  90,\n         9, 114,  43, 214,  65, 132, 128, 145, 214], dtype=uint8)\n>>> np.array(rgb).reshape(4,4,3)\narray([[[112,  68,   7],\n        [ 41, 175, 109],\n        [124, 111, 116],\n        [  6, 124, 168]],\n\n       [[146,  60, 125],\n        [133,   1,  74],\n        [251, 194,  79],\n        [ 14,  72, 236]],\n\n       [[188,  56,  52],\n        [145, 125, 236],\n        [ 86, 108, 235],\n        [  9, 215,  49]],\n\n       [[190,  16,  90],\n        [  9, 114,  43],\n        [214,  65, 132],\n        [128, 145, 214]]], dtype=uint8)\n",
    "auxData['flagInvited'] = auxData['invited'].notnull().astype(int)\n\nauxData = pd.DataFrame({'invited':[np.nan, '2017-01-01','2017-03-03']})\nauxData.invited = pd.to_datetime(auxData.invited, dayfirst=True)\nprint (auxData)\n     invited\n0        NaT\n1 2017-01-01\n2 2017-03-03\n\nprint (auxData['invited'].notnull())\n0    False\n1     True\n2     True\nName: invited, dtype: bool\n\nauxData['flagInvited'] = auxData['invited'].notnull().astype(int)\nprint (auxData)\n     invited  flagInvited\n0        NaT            0\n1 2017-01-01            1\n2 2017-03-03            1\n",
    "lst = [[], [0.0333, 'Gene 1', 'Gene 2'], [], [0.72, 'Gene 3', 'Gene 4', 0.49, 'Gene 5', 'Gene 6']]\ngenes = ['Gene {}'.format(i) for i in range(1, 7)]\n\ndf = pd.DataFrame(np.concatenate(lst).reshape(-1, 3)[:, ::-1], columns=['A', 'B', 'Dist'])\n\nout = df.pivot('B', 'A', 'Dist').fillna(0).reindex(genes, genes, fill_value=0)  \nprint(out)\n\nA      Gene 1  Gene 2 Gene 3 Gene 4 Gene 5 Gene 6\nB                                                \nGene 1      0  0.0333      0      0      0      0\nGene 2      0       0      0      0      0      0\nGene 3      0       0      0   0.72      0      0\nGene 4      0       0      0      0      0      0\nGene 5      0       0      0      0      0   0.49\nGene 6      0       0      0      0      0      0\n"
   ]
  },
  {
   "questions": [
    "Converting numpy array 3D looping: array (t*40,6) 3D array (t,40,5) LSTM's input layer. description conversion desired shown figure below. , F1..5 5 input features, T1...40 steps LSTM C1...t various training examples. Basically, unique \"Ct\", \"T X F\" array, concatenate along 3rd dimension. mind losing \"Ct\" long Ct dimension. looping unique Ct, appending \"T X F\" 3rd dimension. However, ,800,000 Ct's makes quite slow unique Ct. Looking suggestions operation faster. EDIT: original posted. Updating additional : T1...40 steps highest steps = 40, less 40 well. rest 'np.nan' 40 slots available.",
    "2d numpy array 3d array?: 2d array ( , y) 3d array ( , y, ). nice Pythonic ?",
    "dict 3D numpy array?: dict n_keys array (dim1,dim2). transfer 3D numpy array (dim1,dim2,n_keys). fast lot nested loops? EDIT: Example:",
    "Converting numpy array: , print numpy array numpy array. However : rid dtype=\"|S3\" parts leave:",
    "Converting numpy array integers: currently showing .00+e09 array (type float64). show 1000000000 instead. ?"
   ],
   "code": [
    "t=5\nCFt=randint(0,t,(40*t,6)).astype(float) # 2D data\ndf= pd.DataFrame(CFt)\ndf2=df.set_index([df[0],df.groupby(0).cumcount()]).sort_index()\ndf3=df2.to_panel()\n",
    ">>> from numpy import zeros, newaxis\n>>> a = zeros((6, 8))\n>>> a.shape\n(6, 8)\n>>> b = a[:, :, newaxis]\n>>> b.shape\n(6, 8, 1)\n\n>>> b = a[..., newaxis]\n>>> b.shape\n(6, 8, 1)\n",
    ">>> somedict = dict(a = np.arange(4).reshape(2,2),\n                    b = np.arange(4).reshape(2,2) + 10,\n                    c = np.arange(4).reshape(2,2) + 100,\n                    d = np.arange(4).reshape(2,2) + 1000)\n\n>>> array3d = np.dstack(somedict.values())\n>>> array3d.shape\n(2, 2, 4)\n>>> array3d # unordered because of dict unorderedness, order depends for all practical purposes on chance\narray([[[  10,    0, 1000,  100],\n        [  11,    1, 1001,  101]],\n\n       [[  12,    2, 1002,  102],\n        [  13,    3, 1003,  103]]])\n\n>>> array3d = np.dstack((somedict[i] for i in sorted(somedict.keys())))\n>>> array3d    # sorted by the keys!\narray([[[   0,   10,  100, 1000],\n        [   1,   11,  101, 1001]],\n\n       [[   2,   12,  102, 1002],\n        [   3,   13,  103, 1003]]])\n",
    "array1 = numpy.genfromtxt('path_to_my_file.txt', usecols=0)\narray2 = numpy.genfromtxt('path_to_my_file.txt', usecols=1)\n",
    "In [206]: x=np.array([1e9, 2e10, 1e6])\nIn [207]: x\nOut[207]: array([  1.00000000e+09,   2.00000000e+10,   1.00000000e+06])\n\nIn [208]: x.astype(int)\nOut[208]: array([ 1000000000, -2147483648,     1000000])\n\nIn [212]: x.astype(np.int64)\nOut[212]: array([ 1000000000, 20000000000,     1000000], dtype=int64)\n\nIn [213]: np.savetxt('text.txt',x)\nIn [214]: cat text.txt\n1.000000000000000000e+09\n2.000000000000000000e+10\n1.000000000000000000e+06\n\nIn [215]: np.savetxt('text.txt',x, fmt='%d')\nIn [216]: cat text.txt\n1000000000\n20000000000\n1000000\n"
   ]
  },
  {
   "questions": [
    "enumerate ND hardcoding dimensions?: dimensions, say, , hardcode nested loops: dimensions? Can still enumerate array knowing ?",
    "Mask 3d array 2d mask numpy: dimensional array mask using dimensional array dimensions rightmost dimensional array. writing ?",
    "Numpy slice preserving dimensions: Why preserve dimensions conditioned slice ? , array dimension . logic behind slice, returns 1d array? 's best practice (11,300) returned ?",
    "Index n th element along dimension N dimensional numpy array: dimension : obtain: efficient N dimensions? , : obtain third element along dimension?",
    "Howto numpy 1D array congiuous - - copying : dimensional array dimensional array equivalent",
    "Numpy Array dimension uniform: dimensional array 15 dimension variable length dimension dimensions uniform either using numpy skikit sparse array. hog features .",
    "Iterating multidimensional array : created multidimensional array : Now iterate twodimensional array, care order. achieve ?",
    "reduction operation across dimensions : Boolean numpy array multiple dimensions, e.g., now operation across dimension last retrieve array . awfully slow long last dimension. hints vectorize ?",
    "numpy, fastest multiply dimension dimensional array dimensional array?: You array ( ,b,c) multiply dimension array (b) , better ? Ex.",
    "Reverse arbitrary dimension ndarray: 'm working n dimensional array, 'd reverse numbered dimension. rather 'd write similar. 't seem examples rely former syntax."
   ],
   "code": [
    "B = numpy.fromfunction(some_formula, A.shape, dtype=int)\n\nB = numpy.fromfunction(numpy.vectorize(some_formula), A.shape, dtype=int)\n",
    "field3d_mask[:,:,:] = field2d[np.newaxis,:,:] > 0.3\n\nfield3d_mask_1 = np.zeros(field3d.shape, dtype=bool)\nfield3d_mask_2 = np.zeros(field3d.shape, dtype=bool)\n\nfor t in range(nt):\n    field3d_mask_1[t,:,:] = field2d > 0.3\n\nfield3d_mask_2[:,:,:] = field2d[np.newaxis,:,:] > 0.3\n\nprint((field3d_mask_1 == field3d_mask_2).all())\n",
    "In [284]: arr1 =np.random.randint(0,10,(4,5))\nIn [285]: arr1\nOut[285]: \narray([[4, 6, 5, 8, 8],\n       [4, 0, 4, 8, 1],\n       [3, 9, 0, 3, 2],\n       [8, 8, 7, 5, 7]])\nIn [286]: mask = arr1<4\nIn [287]: mask\nOut[287]: \narray([[False, False, False, False, False],\n       [False,  True, False, False,  True],\n       [ True, False,  True,  True,  True],\n       [False, False, False, False, False]], dtype=bool)\nIn [288]: arr1[mask]\nOut[288]: array([0, 1, 3, 0, 3, 2])\nIn [289]: arrM=np.ma.MaskedArray(arr1,~mask)\nIn [290]: arrM\nOut[290]: \nmasked_array(data =\n [[-- -- -- -- --]\n [-- 0 -- -- 1]\n [3 -- 0 3 2]\n [-- -- -- -- --]],\n             mask =\n [[ True  True  True  True  True]\n [ True False  True  True False]\n [False  True False False False]\n [ True  True  True  True  True]],\n       fill_value = 999999)\n",
    "a = np.random.random((10, 15, 20))\n\na[::3,::3,::3].shape\n# (4, 5, 7)\n\na.shape\n# (10, 15, 20)\n\na[[slice(None,None,3)] * a.ndim].shape\n# (4, 5, 7)\n",
    "import numpy as np\n\na = np.array([1,2,3])\n\na = a[np.newaxis].T\n\nprint(a)\n# [[1]\n#  [2]\n#  [3]]\n",
    "max_len = max([abc[i].size() for for i in range(abc.size())])\n\nimport numpy as np\n\nfor i in range(abc.size()):\n    abc[i] = np.append(abc[i], np.zeros(max_len - abc[i].size())\n",
    "for cell in self.cells.flat:\n    do_somethin(cell)\n",
    "a.all(axis=(0,1))\n\ndef numpy_all_except_one(a, axis=-1):\n    axes = np.arange(a.ndim)\n    axes = np.delete(axes, axis)\n    return np.all(a, axis=tuple(axes))\n\nIn [90]: a = numpy.random.rand(7, 7, 3) < 0.99\n\nIn [91]: a.all(axis=(0,1))\nOut[91]: array([False, False,  True], dtype=bool)\n\nIn [92]: numpy_all_except_one(a) # By default skips last axis\nOut[92]: array([False, False,  True], dtype=bool)\n\nIn [93]: a.all(axis=(0,2))\nOut[93]: array([ True, False,  True,  True,  True,  True,  True], dtype=bool)\n\nIn [94]: numpy_all_except_one(a, axis=1)\nOut[94]: array([ True, False,  True,  True,  True,  True,  True], dtype=bool)\n\nIn [95]: a.all(axis=(1,2))\nOut[95]: array([False,  True,  True, False,  True,  True,  True], dtype=bool)\n\nIn [96]: numpy_all_except_one(a, axis=0)\nOut[96]: array([False,  True,  True, False,  True,  True,  True], dtype=bool)\n",
    "A*B[:,np.newaxis]\n\nIn [47]: A=np.arange(24).reshape(2,3,4)\n\nIn [48]: B=np.arange(3)\n\nIn [49]: A*B[:,np.newaxis]\nOut[49]: \narray([[[ 0,  0,  0,  0],\n        [ 4,  5,  6,  7],\n        [16, 18, 20, 22]],\n\n       [[ 0,  0,  0,  0],\n        [16, 17, 18, 19],\n        [40, 42, 44, 46]]])\n",
    "import numpy as np\ndef rev(a, axis = -1):\n    a = np.asarray(a).swapaxes(axis, 0)\n    a = a[::-1,...]\n    a = a.swapaxes(0, axis)\n    return a\n\na = np.arange(24).reshape(2,3,4)\n\nprint(rev(a, axis = 2))\n\n[[[ 3  2  1  0]\n  [ 7  6  5  4]\n  [11 10  9  8]]\n\n [[15 14 13 12]\n  [19 18 17 16]\n  [23 22 21 20]]]\n"
   ]
  }
 ]
}